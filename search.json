[
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "Proyecto 5",
    "section": "",
    "text": "Proyecto 5\nInformación sobre el Proyecto 5. Puedes expandir esta página con subsecciones."
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Proyecto 3",
    "section": "",
    "text": "Proyecto 3\nDetalles del Proyecto 3. Puedes añadir imágenes, gráficos o texto adicional."
  },
  {
    "objectID": "project1.html",
    "href": "project1.html",
    "title": "Proyecto 1",
    "section": "",
    "text": "En la era digital actual, el big data ha emergido como un recurso valioso para las organizaciones, permitiéndoles extraer, procesar y analizar datos significativos. El big data se caracteriza por sus cuatro V: volumen, velocidad, variedad y veracidad. El volumen se refiere a la gran cantidad de datos generados y almacenados; la velocidad, a la rapidez con la que se generan y procesan; la variedad, a los diferentes tipos de datos (estructurados y no estructurados); y la veracidad, a la calidad y precisión de dichos datos. La capacidad de manejar y analizar estos grandes volúmenes de información de manera eficiente es crucial para aprovechar al máximo el potencial del big data (Müller et al., 2016).\nEl análisis de big data permite a las organizaciones identificar patrones, predecir tendencias y optimizar procesos, lo que puede resultar en mejoras significativas en la eficiencia operativa y en la toma de decisiones estratégicas. Sin embargo, la manipulación de grandes volúmenes de datos presenta desafíos importantes en términos de infraestructura, almacenamiento, procesamiento y análisis. Los algoritmos eficientes son fundamentales para enfrentar estos desafíos y garantizar que los sistemas de big data funcionen de manera óptima (Manyika et al., 2011).\nEste reporte se enfoca en comparar diferentes órdenes de crecimiento mediante simulaciones en un entorno de Jupyter. Se analizarán los siguientes casos: \\(O(1)\\) vs \\(O(\\log n)\\), \\(O(n)\\) vs \\(O(n \\log n)\\), \\(O(n^2)\\) vs \\(O(n^3)\\), \\(O(a^n)\\) vs \\(O(n!)\\) y \\(O(n!)\\) vs \\(O(n^n)\\). Para cada comparación, se seleccionarán rangos adecuados de \\(n\\) que permitan visualizar claramente las diferencias entre estos órdenes. Se generarán gráficas para cada caso y se discutirán las observaciones correspondientes. Además, se incluirá una tabla con tiempos de ejecución simulados para algoritmos ficticios asociados a los órdenes de crecimiento mencionados, utilizando distintos tamaños de entrada \\(n\\). Este análisis proporciona una visión clara de cómo los diferentes órdenes de crecimiento afectan el rendimiento y la eficiencia de los algoritmos.\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\n\n\n\ndef constant(n): return 1\ndef logarithmic(n): return np.log(n)\ndef linear(n): return n\ndef linear_logarithmic(n): return n * np.log(n)\ndef quadratic(n): return n**2\ndef cubic(n): return n**3\ndef exponential(n, a=2): return a**n\ndef factorial(n): return math.factorial(n)\ndef double_exponential(n): return n**n\n\n\n\ndef plot_comparison(funcs, labels, title, x_range):\n    plt.figure(figsize=(7, 5))\n    for func, label in zip(funcs, labels):\n        plt.plot(x_range, [func(x) / 1e9 for x in x_range], label=label)\n    plt.xlabel('n')\n    plt.ylabel('Tiempo (s)')\n    plt.title(title)\n    plt.legend()\n    plt.yscale('log')\n    plt.xscale('log')\n    plt.grid(True)\n    plt.show()\n\n\n\nx_range_small = np.arange(1, 10)\nx_range_medium = np.arange(1, 100)\n\n# Comparación 1: O(1) vs O(log n)\nplot_comparison([constant, logarithmic], ['O(1)', 'O(log n)'], 'Figura 1 - Comparación de O(1) con O(log n)', x_range_small)\n\n# Comparación 2: O(n) vs O(n log n)\nplot_comparison([linear, linear_logarithmic], ['O(n)', 'O(n log n)'], 'Figura 2 - Comparación de O(n) con O(n log n)', x_range_medium)\n\n# Comparación 3: O(n^2) vs O(n^3)\nplot_comparison([quadratic, cubic], ['O(n^2)', 'O(n^3)'], 'Figura 3 - Comparación de O(n^2) con O(n^3)', x_range_medium)\n\n# Comparación 4: O(2^n) vs O(n!)\nplot_comparison([lambda n: exponential(n, 2), factorial], ['O(2^n)', 'O(n!)'], 'Figura 4 - Comparación de O(2^n) con O(n!)', x_range_small)\n\n# Comparación 5: O(n!) vs O(n^n)\nplot_comparison([factorial, double_exponential], ['O(n!)', 'O(n^n)'], 'Figura 5 - Comparación de O(n!) con O(n^n)', x_range_small)\n\n\n\nNota: Se creó una tabla con tiempos de ejecución simulados para algoritmos ficticios con los órdenes de crecimiento mencionados.\n# Tamaños de entrada\nn_values = [100, 1000, 10000, 100000]\n\n# Funciones de costo\ncost_functions = {\n    'O(1)': constant,\n    'O(log n)': logarithmic,\n    'O(n)': linear,\n    'O(n log n)': linear_logarithmic,\n    'O(n^2)': quadratic,\n    'O(n^3)': cubic,\n    'O(2^n)': lambda n: exponential(n, 2),\n    'O(n!)': factorial,\n    'O(n^n)': double_exponential\n}\n\n# Elaboración de la tabla\nresults = []\nfor n in n_values:\n    row = {'n': n}\n    for label, func in cost_functions.items():\n        try:\n            row[label] = func(n) / 1e9  # Conversión a segundos\n        except OverflowError:\n            row[label] = 'Overflow'\n    results.append(row)\n\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.set_index('n', inplace=True)\ndf\n\n\n\n\n\n\n\n\n\nasd\n\n\n\nsda\n\n\n\nsd\n\n\n\nasd\n\n\n\nasd\n\n\n\n\n\nA continuación se presenta una tabla comparativa de los tiempos simulados para diferentes órdenes de crecimiento, utilizando distintos tamaños de entrada \\(n\\). Los resultados se expresan en segundos. En algunos casos, se muestra “Overflow” cuando el valor resultante excede los límites de representación.\nTabla 1. Tiempos simulados para diferentes órdenes de crecimiento de O(1), O(log n), O(n), O(n log n), O(n²)\n\n\n\n\n\n\n\n\n\n\n\nn\nO(1)\nO(log n)\nO(n)\nO(n log n)\nO(n²)\n\n\n\n\n100\n1.00e-09\n4.61e-09\n1.00e-07\n4.61e-07\n1.00e-05\n\n\n1000\n1.00e-09\n6.91e-09\n1.00e-06\n6.91e-06\n1.00e-03\n\n\n10000\n1.00e-09\n9.21e-09\n1.00e-05\n9.21e-05\n1.00e-01\n\n\n100000\n1.00e-09\n1.15e-08\n1.00e-04\n1.15e-03\n1.00e+01\n\n\n\nTabla 2. Tiempos simulados para diferentes órdenes de crecimiento de O(n³), O(2ⁿ)\n\n\n\nn\nO(n³)\nO(2ⁿ)\n\n\n\n\n100\n1.00e-03\n1.27e+21\n\n\n1000\n1.00e+00\nOverflow\n\n\n10000\n1.00e+03\nOverflow\n\n\n100000\n1.00e+06\nOverflow\n\n\n\nTabla 3. Tiempos simulados para diferentes órdenes de crecimiento de O(n!), O(nⁿ)\n\n\n\nn\nO(n!)\nO(nⁿ)\n\n\n\n\n100\nOverflow\nOverflow\n\n\n1000\nOverflow\nOverflow\n\n\n10000\nOverflow\nOverflow\n\n\n100000\nOverflow\nOverflow\n\n\n\n\nNota: Algunos valores como O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de \\(n\\) generan cantidades inmanejables por el sistema, resultando en Overflow. Esto refleja la inviabilidad práctica de algoritmos con estas complejidades cuando se trabaja con grandes volúmenes de datos.\n\nComo se muestra en la tabla, el tiempo de ejecución de O(1) no depende del tamaño de n. Este mantiene un mismo valor, lo que indica que su tiempo de ejecución es constante. Por otro lado, los valores de O(log n) aumentan lentamente a medida que n crece, lo cual es consistente con su comportamiento logarítmico. En el caso de O(n), los valores aumentan de forma lineal conforme n se incrementa. Los valores de O(n log n) aumentan más rápido que los de O(n), pero no tan aceleradamente como los de O(n²). Por su parte, O(n²) crece rápidamente a medida que n aumenta, y O(n³) lo hace de forma aún más acelerada, incluso con valores pequeños de entrada.\nDurante la ejecución del código, algunos resultados aparecen como “Overflow”. Esto se debe a que las funciones O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de n (como 10,000 o 100,000) generan números extremadamente grandes, lo que excede la capacidad de representación y manejo numérico en Python.\n\n\n\n\nLa manipulación de grandes volúmenes de información presenta importantes desafíos debido a los costos de cómputo. Estos costos se relacionan con el gasto monetario, los recursos computacionales requeridos, el tiempo de procesamiento, el uso de memoria, el almacenamiento y el consumo energético. A continuación se presentan algunas de las implicaciones más relevantes:\n\nInfraestructura: Manipular grandes volúmenes de datos requiere una infraestructura robusta, que incluye servidores potentes, almacenamiento masivo y redes de alta velocidad. Esto representa costos elevados en hardware, mantenimiento y consumo energético (Armbrust et al., 2010).\nEnergía: Los centros de datos que procesan grandes cantidades de información consumen enormes cantidades de energía, lo cual incrementa los costos operativos y contribuye al impacto ambiental debido a las emisiones de carbono (Baliga et al., 2011).\nAlmacenamiento: El almacenamiento de grandes volúmenes de datos requiere soluciones escalables y eficientes. Este aspecto representa un costo considerable, ya que también debe garantizarse la recuperación oportuna de la información.\nProcesamiento: Procesar datos en tiempo real o en tiempo cercano al real implica el uso de algoritmos eficientes y de recursos de cómputo significativos. Estos costos pueden incrementarse especialmente al utilizar tecnologías como el aprendizaje automático y la inteligencia artificial (Wang et al., 2015).\n\nEn conjunto, la gestión de grandes volúmenes de información conlleva costos considerables en términos de infraestructura, energía, almacenamiento, procesamiento, seguridad y mantenimiento. Estos aspectos deben ser cuidadosamente planeados y gestionados para asegurar soluciones de big data eficientes y sostenibles.\n\n\n\n\nEn las simulaciones realizadas se observó que los órdenes de crecimiento más bajos, como O(1), O(log n) y O(n), resultan altamente eficientes. Son ideales para tareas que demandan rendimiento óptimo y tiempos de respuesta reducidos.\nPor otro lado, los órdenes de crecimiento O(n log n) y O(n²) demostraron ser prácticas y ampliamente aplicables, al ofrecer un buen equilibrio entre eficiencia y capacidad de procesamiento.\nEn contraste, las funciones con órdenes de crecimiento elevados como O(2ⁿ), O(n!) y O(nⁿ) resultaron ineficientes, generando tiempos de ejecución excesivos o incluso errores de memoria.\nLa tabla de tiempos de ejecución simulados confirma cómo el crecimiento del orden afecta directamente el rendimiento de los algoritmos. A mayor orden, mayor consumo de recursos y tiempo; a menor orden, mayor eficiencia en la ejecución.\n\n\n\n\nMüller, V. C., Schal, J. M., Meyer-Lindenberg, A. (2016). Machine Learning for Brain Imaging. Cambridge University Press.\nManyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C., & Byers, A. H. (2011). Big data: The next frontier for innovation, competition, and productivity. McKinsey Global Institute. https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/big-data-the-next-frontier-for-innovation\nArmbrust, M., Fox, A., Griffith, R., Joseph, A. D., Katz, R. H., Konwinski, A., et al. (2010). A View of Cloud Computing. Communications of the ACM, 53(4), 50–58. https://doi.org/10.1145/1721654.1721672\nBaliga, J., Ayre, R., Hinton, K., & Tucker, R. S. (2011). Energy-Efficient Telecommunications.\nWang, L., Chen, Y., & Liu, Q. (2015). Big Data Processing: A Survey. Springer."
  },
  {
    "objectID": "project1.html#introducción",
    "href": "project1.html#introducción",
    "title": "Proyecto 1",
    "section": "",
    "text": "En la era digital actual, el big data ha emergido como un recurso valioso para las organizaciones, permitiéndoles extraer, procesar y analizar datos significativos. El big data se caracteriza por sus cuatro V: volumen, velocidad, variedad y veracidad. El volumen se refiere a la gran cantidad de datos generados y almacenados; la velocidad, a la rapidez con la que se generan y procesan; la variedad, a los diferentes tipos de datos (estructurados y no estructurados); y la veracidad, a la calidad y precisión de dichos datos. La capacidad de manejar y analizar estos grandes volúmenes de información de manera eficiente es crucial para aprovechar al máximo el potencial del big data (Müller et al., 2016).\nEl análisis de big data permite a las organizaciones identificar patrones, predecir tendencias y optimizar procesos, lo que puede resultar en mejoras significativas en la eficiencia operativa y en la toma de decisiones estratégicas. Sin embargo, la manipulación de grandes volúmenes de datos presenta desafíos importantes en términos de infraestructura, almacenamiento, procesamiento y análisis. Los algoritmos eficientes son fundamentales para enfrentar estos desafíos y garantizar que los sistemas de big data funcionen de manera óptima (Manyika et al., 2011).\nEste reporte se enfoca en comparar diferentes órdenes de crecimiento mediante simulaciones en un entorno de Jupyter. Se analizarán los siguientes casos: \\(O(1)\\) vs \\(O(\\log n)\\), \\(O(n)\\) vs \\(O(n \\log n)\\), \\(O(n^2)\\) vs \\(O(n^3)\\), \\(O(a^n)\\) vs \\(O(n!)\\) y \\(O(n!)\\) vs \\(O(n^n)\\). Para cada comparación, se seleccionarán rangos adecuados de \\(n\\) que permitan visualizar claramente las diferencias entre estos órdenes. Se generarán gráficas para cada caso y se discutirán las observaciones correspondientes. Además, se incluirá una tabla con tiempos de ejecución simulados para algoritmos ficticios asociados a los órdenes de crecimiento mencionados, utilizando distintos tamaños de entrada \\(n\\). Este análisis proporciona una visión clara de cómo los diferentes órdenes de crecimiento afectan el rendimiento y la eficiencia de los algoritmos."
  },
  {
    "objectID": "project1.html#desarrollo",
    "href": "project1.html#desarrollo",
    "title": "Proyecto 1",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\n\n\n\ndef constant(n): return 1\ndef logarithmic(n): return np.log(n)\ndef linear(n): return n\ndef linear_logarithmic(n): return n * np.log(n)\ndef quadratic(n): return n**2\ndef cubic(n): return n**3\ndef exponential(n, a=2): return a**n\ndef factorial(n): return math.factorial(n)\ndef double_exponential(n): return n**n\n\n\n\ndef plot_comparison(funcs, labels, title, x_range):\n    plt.figure(figsize=(7, 5))\n    for func, label in zip(funcs, labels):\n        plt.plot(x_range, [func(x) / 1e9 for x in x_range], label=label)\n    plt.xlabel('n')\n    plt.ylabel('Tiempo (s)')\n    plt.title(title)\n    plt.legend()\n    plt.yscale('log')\n    plt.xscale('log')\n    plt.grid(True)\n    plt.show()\n\n\n\nx_range_small = np.arange(1, 10)\nx_range_medium = np.arange(1, 100)\n\n# Comparación 1: O(1) vs O(log n)\nplot_comparison([constant, logarithmic], ['O(1)', 'O(log n)'], 'Figura 1 - Comparación de O(1) con O(log n)', x_range_small)\n\n# Comparación 2: O(n) vs O(n log n)\nplot_comparison([linear, linear_logarithmic], ['O(n)', 'O(n log n)'], 'Figura 2 - Comparación de O(n) con O(n log n)', x_range_medium)\n\n# Comparación 3: O(n^2) vs O(n^3)\nplot_comparison([quadratic, cubic], ['O(n^2)', 'O(n^3)'], 'Figura 3 - Comparación de O(n^2) con O(n^3)', x_range_medium)\n\n# Comparación 4: O(2^n) vs O(n!)\nplot_comparison([lambda n: exponential(n, 2), factorial], ['O(2^n)', 'O(n!)'], 'Figura 4 - Comparación de O(2^n) con O(n!)', x_range_small)\n\n# Comparación 5: O(n!) vs O(n^n)\nplot_comparison([factorial, double_exponential], ['O(n!)', 'O(n^n)'], 'Figura 5 - Comparación de O(n!) con O(n^n)', x_range_small)\n\n\n\nNota: Se creó una tabla con tiempos de ejecución simulados para algoritmos ficticios con los órdenes de crecimiento mencionados.\n# Tamaños de entrada\nn_values = [100, 1000, 10000, 100000]\n\n# Funciones de costo\ncost_functions = {\n    'O(1)': constant,\n    'O(log n)': logarithmic,\n    'O(n)': linear,\n    'O(n log n)': linear_logarithmic,\n    'O(n^2)': quadratic,\n    'O(n^3)': cubic,\n    'O(2^n)': lambda n: exponential(n, 2),\n    'O(n!)': factorial,\n    'O(n^n)': double_exponential\n}\n\n# Elaboración de la tabla\nresults = []\nfor n in n_values:\n    row = {'n': n}\n    for label, func in cost_functions.items():\n        try:\n            row[label] = func(n) / 1e9  # Conversión a segundos\n        except OverflowError:\n            row[label] = 'Overflow'\n    results.append(row)\n\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.set_index('n', inplace=True)\ndf"
  },
  {
    "objectID": "project1.html#análisis-de-resultados",
    "href": "project1.html#análisis-de-resultados",
    "title": "Proyecto 1",
    "section": "",
    "text": "asd\n\n\n\nsda\n\n\n\nsd\n\n\n\nasd\n\n\n\nasd\n\n\n\n\n\nA continuación se presenta una tabla comparativa de los tiempos simulados para diferentes órdenes de crecimiento, utilizando distintos tamaños de entrada \\(n\\). Los resultados se expresan en segundos. En algunos casos, se muestra “Overflow” cuando el valor resultante excede los límites de representación.\nTabla 1. Tiempos simulados para diferentes órdenes de crecimiento de O(1), O(log n), O(n), O(n log n), O(n²)\n\n\n\n\n\n\n\n\n\n\n\nn\nO(1)\nO(log n)\nO(n)\nO(n log n)\nO(n²)\n\n\n\n\n100\n1.00e-09\n4.61e-09\n1.00e-07\n4.61e-07\n1.00e-05\n\n\n1000\n1.00e-09\n6.91e-09\n1.00e-06\n6.91e-06\n1.00e-03\n\n\n10000\n1.00e-09\n9.21e-09\n1.00e-05\n9.21e-05\n1.00e-01\n\n\n100000\n1.00e-09\n1.15e-08\n1.00e-04\n1.15e-03\n1.00e+01\n\n\n\nTabla 2. Tiempos simulados para diferentes órdenes de crecimiento de O(n³), O(2ⁿ)\n\n\n\nn\nO(n³)\nO(2ⁿ)\n\n\n\n\n100\n1.00e-03\n1.27e+21\n\n\n1000\n1.00e+00\nOverflow\n\n\n10000\n1.00e+03\nOverflow\n\n\n100000\n1.00e+06\nOverflow\n\n\n\nTabla 3. Tiempos simulados para diferentes órdenes de crecimiento de O(n!), O(nⁿ)\n\n\n\nn\nO(n!)\nO(nⁿ)\n\n\n\n\n100\nOverflow\nOverflow\n\n\n1000\nOverflow\nOverflow\n\n\n10000\nOverflow\nOverflow\n\n\n100000\nOverflow\nOverflow\n\n\n\n\nNota: Algunos valores como O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de \\(n\\) generan cantidades inmanejables por el sistema, resultando en Overflow. Esto refleja la inviabilidad práctica de algoritmos con estas complejidades cuando se trabaja con grandes volúmenes de datos.\n\nComo se muestra en la tabla, el tiempo de ejecución de O(1) no depende del tamaño de n. Este mantiene un mismo valor, lo que indica que su tiempo de ejecución es constante. Por otro lado, los valores de O(log n) aumentan lentamente a medida que n crece, lo cual es consistente con su comportamiento logarítmico. En el caso de O(n), los valores aumentan de forma lineal conforme n se incrementa. Los valores de O(n log n) aumentan más rápido que los de O(n), pero no tan aceleradamente como los de O(n²). Por su parte, O(n²) crece rápidamente a medida que n aumenta, y O(n³) lo hace de forma aún más acelerada, incluso con valores pequeños de entrada.\nDurante la ejecución del código, algunos resultados aparecen como “Overflow”. Esto se debe a que las funciones O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de n (como 10,000 o 100,000) generan números extremadamente grandes, lo que excede la capacidad de representación y manejo numérico en Python.\n\n\n\n\nLa manipulación de grandes volúmenes de información presenta importantes desafíos debido a los costos de cómputo. Estos costos se relacionan con el gasto monetario, los recursos computacionales requeridos, el tiempo de procesamiento, el uso de memoria, el almacenamiento y el consumo energético. A continuación se presentan algunas de las implicaciones más relevantes:\n\nInfraestructura: Manipular grandes volúmenes de datos requiere una infraestructura robusta, que incluye servidores potentes, almacenamiento masivo y redes de alta velocidad. Esto representa costos elevados en hardware, mantenimiento y consumo energético (Armbrust et al., 2010).\nEnergía: Los centros de datos que procesan grandes cantidades de información consumen enormes cantidades de energía, lo cual incrementa los costos operativos y contribuye al impacto ambiental debido a las emisiones de carbono (Baliga et al., 2011).\nAlmacenamiento: El almacenamiento de grandes volúmenes de datos requiere soluciones escalables y eficientes. Este aspecto representa un costo considerable, ya que también debe garantizarse la recuperación oportuna de la información.\nProcesamiento: Procesar datos en tiempo real o en tiempo cercano al real implica el uso de algoritmos eficientes y de recursos de cómputo significativos. Estos costos pueden incrementarse especialmente al utilizar tecnologías como el aprendizaje automático y la inteligencia artificial (Wang et al., 2015).\n\nEn conjunto, la gestión de grandes volúmenes de información conlleva costos considerables en términos de infraestructura, energía, almacenamiento, procesamiento, seguridad y mantenimiento. Estos aspectos deben ser cuidadosamente planeados y gestionados para asegurar soluciones de big data eficientes y sostenibles."
  },
  {
    "objectID": "project1.html#conclusiones",
    "href": "project1.html#conclusiones",
    "title": "Proyecto 1",
    "section": "",
    "text": "En las simulaciones realizadas se observó que los órdenes de crecimiento más bajos, como O(1), O(log n) y O(n), resultan altamente eficientes. Son ideales para tareas que demandan rendimiento óptimo y tiempos de respuesta reducidos.\nPor otro lado, los órdenes de crecimiento O(n log n) y O(n²) demostraron ser prácticas y ampliamente aplicables, al ofrecer un buen equilibrio entre eficiencia y capacidad de procesamiento.\nEn contraste, las funciones con órdenes de crecimiento elevados como O(2ⁿ), O(n!) y O(nⁿ) resultaron ineficientes, generando tiempos de ejecución excesivos o incluso errores de memoria.\nLa tabla de tiempos de ejecución simulados confirma cómo el crecimiento del orden afecta directamente el rendimiento de los algoritmos. A mayor orden, mayor consumo de recursos y tiempo; a menor orden, mayor eficiencia en la ejecución."
  },
  {
    "objectID": "project1.html#referencias",
    "href": "project1.html#referencias",
    "title": "Proyecto 1",
    "section": "",
    "text": "Müller, V. C., Schal, J. M., Meyer-Lindenberg, A. (2016). Machine Learning for Brain Imaging. Cambridge University Press.\nManyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C., & Byers, A. H. (2011). Big data: The next frontier for innovation, competition, and productivity. McKinsey Global Institute. https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/big-data-the-next-frontier-for-innovation\nArmbrust, M., Fox, A., Griffith, R., Joseph, A. D., Katz, R. H., Konwinski, A., et al. (2010). A View of Cloud Computing. Communications of the ACM, 53(4), 50–58. https://doi.org/10.1145/1721654.1721672\nBaliga, J., Ayre, R., Hinton, K., & Tucker, R. S. (2011). Energy-Efficient Telecommunications.\nWang, L., Chen, Y., & Liu, Q. (2015). Big Data Processing: A Survey. Springer."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre Mí",
    "section": "",
    "text": "📍 Aguascalientes, México\n✉️ juan2javm@gmail.com / jvelasquez1800@alumno.ipn.mx\n📱 +52 322 353 4081\n🔗 GitHub: juan21javm\n🔗 LinkedIn: antonio-martínez-776788179\n\n\n\nMe considero una persona profundamente comprometida con el crecimiento intelectual, la lectura reflexiva y el bienestar de mi entorno cercano. Disfruto de los momentos al aire libre, donde encuentro inspiración en la naturaleza y la tranquilidad necesaria para mantener un equilibrio emocional. Valoro profundamente el tiempo con mi familia, ya que es el motor que impulsa mi disciplina, responsabilidad y deseo de superación constante. Asimismo, tengo una gran pasión por la programación y un genuino entusiasmo por la ciencia de datos, áreas que me permiten combinar creatividad, lógica y análisis riguroso para resolver problemas del mundo real. Estos principios personales complementan mi formación académica y profesional, motivándome a mantener siempre una actitud proactiva, ética y humana.\n\n\n\n\nSupervisor — INE (2023–2025), Loreto, Zacatecas\n- Supervisión de actividades diarias para cumplimiento de objetivos.\n- Capacitación del equipo y mejora de rendimiento.\n- Evaluación de desempeño y optimización de procesos.\nMaestro Asistente — IPN (2022–2023), Zacatecas\n- Evaluación del progreso estudiantil.\n- Planeación conjunta de actividades educativas.\n- Creación y adaptación de materiales educativos.\n\n\n\n\nProyecto A — Estandarización de proceso a nivel laboratorio (2021–2023)\n- Herramientas: MATLAB, HACCP Software, Latex\n- Liderazgo de investigación para producción de yogurt con uvas a nivel laboratorio.\n- Reconocimiento al mejor promedio del programa académico (IPN 2017–2022).\n- Primer lugar en Simposium Agroalimentario y Ciclo de Conferencias CUALTIA 2023.\n\n\n\n\n\nLenguajes: Python, JAVA, HTML, ASPEN\n\nHerramientas Matemáticas: MATLAB, R, SPSS, PLC\n\nOfimática: Office, LaTeX\n\n\n\n\n\n\nIdiomas: Español (nativo), Inglés (B1)\n\nIntereses: Lectura, búsqueda, planeación"
  },
  {
    "objectID": "about.html#perfil-personal",
    "href": "about.html#perfil-personal",
    "title": "Sobre Mí",
    "section": "",
    "text": "Me considero una persona profundamente comprometida con el crecimiento intelectual, la lectura reflexiva y el bienestar de mi entorno cercano. Disfruto de los momentos al aire libre, donde encuentro inspiración en la naturaleza y la tranquilidad necesaria para mantener un equilibrio emocional. Valoro profundamente el tiempo con mi familia, ya que es el motor que impulsa mi disciplina, responsabilidad y deseo de superación constante. Asimismo, tengo una gran pasión por la programación y un genuino entusiasmo por la ciencia de datos, áreas que me permiten combinar creatividad, lógica y análisis riguroso para resolver problemas del mundo real. Estos principios personales complementan mi formación académica y profesional, motivándome a mantener siempre una actitud proactiva, ética y humana."
  },
  {
    "objectID": "about.html#experiencia",
    "href": "about.html#experiencia",
    "title": "Sobre Mí",
    "section": "",
    "text": "Supervisor — INE (2023–2025), Loreto, Zacatecas\n- Supervisión de actividades diarias para cumplimiento de objetivos.\n- Capacitación del equipo y mejora de rendimiento.\n- Evaluación de desempeño y optimización de procesos.\nMaestro Asistente — IPN (2022–2023), Zacatecas\n- Evaluación del progreso estudiantil.\n- Planeación conjunta de actividades educativas.\n- Creación y adaptación de materiales educativos."
  },
  {
    "objectID": "about.html#proyectos-conferencias-y-reconocimientos",
    "href": "about.html#proyectos-conferencias-y-reconocimientos",
    "title": "Sobre Mí",
    "section": "",
    "text": "Proyecto A — Estandarización de proceso a nivel laboratorio (2021–2023)\n- Herramientas: MATLAB, HACCP Software, Latex\n- Liderazgo de investigación para producción de yogurt con uvas a nivel laboratorio.\n- Reconocimiento al mejor promedio del programa académico (IPN 2017–2022).\n- Primer lugar en Simposium Agroalimentario y Ciclo de Conferencias CUALTIA 2023."
  },
  {
    "objectID": "about.html#habilidades",
    "href": "about.html#habilidades",
    "title": "Sobre Mí",
    "section": "",
    "text": "Lenguajes: Python, JAVA, HTML, ASPEN\n\nHerramientas Matemáticas: MATLAB, R, SPSS, PLC\n\nOfimática: Office, LaTeX"
  },
  {
    "objectID": "about.html#información-adicional",
    "href": "about.html#información-adicional",
    "title": "Sobre Mí",
    "section": "",
    "text": "Idiomas: Español (nativo), Inglés (B1)\n\nIntereses: Lectura, búsqueda, planeación"
  },
  {
    "objectID": "index.html#presentación-del-proyecto",
    "href": "index.html#presentación-del-proyecto",
    "title": "Centro de Investigación e Innovación en Tecnologías de la Información y Comunicación",
    "section": "Presentación del proyecto",
    "text": "Presentación del proyecto\nEn esta página se encuentran reflejados los cinco reportes desarrollados a lo largo de la asignatura de Análisis de Algoritmos. Cada uno de ellos ha sido debidamente documentado, estructurado y trasladado al formato Quarto con el propósito de comunicar al público el trabajo realizado y los análisis efectuados durante mi estancia en la materia. Estos reportes representan el proceso de aprendizaje y aplicación práctica de los conceptos clave abordados en cada unidad, desde la introducción al análisis algorítmico hasta los algoritmos de intersección de conjuntos, permitiendo evidenciar el desarrollo de competencias técnicas y analíticas fundamentales en el área.\nEsta documentación ha sido preparada para su publicación en un repositorio de GitHub con el objetivo de compartir de forma abierta los contenidos desarrollados, promover el acceso al conocimiento, y facilitar su consulta por parte de docentes, estudiantes y profesionales interesados en el análisis de algoritmos.\nA lo largo del curso se desarrollaron cinco tareas escritas que reflejan los temas fundamentales abordados en cada unidad:\n\nUnidad 1: Introducción al análisis de algoritmos\nSe realizó el reporte 1A. Reporte escrito. Experimentos y análisis, en el que se exploraron conceptos básicos sobre la eficiencia algorítmica y órdenes de crecimiento.\nUnidad 2: Estructuras de datos\nSe trabajó el reporte 2A. Reporte escrito. Experimentos y análisis de estructuras de datos, enfocado en el comportamiento, manipulación y análisis de distintas estructuras como listas, pilas, colas y árboles.\nUnidad 3: Algoritmos de ordenamiento por comparación\nSe elaboró el 3A. Reporte escrito. Experimentos y análisis de algoritmos de ordenamiento, donde se evaluaron métodos como burbuja, inserción, selección, quicksort y mergesort.\nUnidad 4: Algoritmos de búsqueda por comparación\nSe desarrolló el reporte 4A. Reporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación, abordando técnicas como la búsqueda lineal y binaria, con un enfoque en su eficiencia.\nUnidad 5: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\nSe presentó el 5A. Reporte escrito. Experimentos y análisis de algoritmos de intersección de conjuntos, donde se analizaron distintas estrategias para operar sobre múltiples listas ordenadas."
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Proyecto 2",
    "section": "",
    "text": "Proyecto 2\nDescripción del Proyecto 2. Información relevante sobre este segundo proyecto."
  }
]