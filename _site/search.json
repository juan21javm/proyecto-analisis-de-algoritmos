[
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "Proyecto 5",
    "section": "",
    "text": "El trabajo con grandes volúmenes de datos requiere encontrar formas eficientes de realizar operaciones básicas como la intersección de listas. Esta tarea, que consiste en identificar los elementos comunes entre varias listas ordenadas, resulta fundamental en sistemas como los motores de búsqueda, el filtrado de datos o el procesamiento de información en general. En este proyecto se propuso implementar y comparar varios algoritmos de intersección con el objetivo de analizar sus diferencias, ventajas y limitaciones en distintos escenarios.\nLos algoritmos seleccionados para este análisis fueron Melding (ME), Baeza-Yates (BY) y Barbay & Kenyon (BK). Cada uno de ellos aborda el problema desde una estrategia distinta, lo que permite observar cómo se comportan las listas.\nEl algoritmo Melding prioriza las listas más pequeñas para cruzarlas primero. Esta estrategia permite reducir el tamaño de las intersecciones parciales desde el inicio, acelerando el proceso cuando algunas listas tienen pocos elementos que filtran rápidamente el resultado (Barbay et al., 2009).\nEl algoritmo Baeza-Yates parte de una lista base y busca sus elementos en las demás listas utilizando distintas técnicas. En este estudio se emplearon tres variantes: búsqueda binaria, búsqueda no acotada B1 (con saltos exponenciales y luego binaria) y la versión B2 (que mejora los saltos iniciales). Estas variantes permiten optimizar el número de comparaciones en función del tamaño relativo de las listas (Baeza-Yates, 2004).\nEl algoritmo Barbay & Kenyon presenta un enfoque más complejo y adaptativo. Alterna entre recorridos secuenciales y saltos controlados, decidiendo en tiempo real cuál estrategia aplicar según el patrón de los datos. Esta flexibilidad lo hace útil para listas con estructuras irregulares o alta dispersión de valores (Barbay & Kenyon, 2002).\nPara evaluar el rendimiento de estos algoritmos, se trabajó con tres conjuntos de datos: el Conjunto A, con pares de listas; el Conjunto B, con tripletas; y el Conjunto C, con cuatro listas. En cada caso se midieron el tiempo de ejecución, el número de comparaciones realizadas y el tamaño de la intersección obtenida. Posteriormente, los resultados fueron representados mediante gráficos tipo boxplot, facilitando la comparación visual del rendimiento de cada algoritmo en distintos escenarios.\n\n\n\n\n\n# Bibliotecas Utilizadas\nimport os\nimport json\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import List, Tuple, Optional\n\n# Ruta de Archivos\nbase_path = r\"C:\\Users\\Antonio Martínez\\Downloads\\Conjuntos de listas de posteo para intersección-20250520\"\n\nfile_map = {\n    'A': 'postinglists-for-intersection-A-k=2.json',\n    'B': 'postinglists-for-intersection-B-k=3.json',\n    'C': 'postinglists-for-intersection-C-k=4.json',\n}\n\n# Carga y ordena listas dentro de cada grupo\ndef load_json_data(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n\ndatasets = {}\nfor label, fname in file_map.items():\n    full_path = os.path.join(base_path, fname)\n    data = load_json_data(full_path)\n    datasets[label] = [[sorted(sublist) for sublist in group] for group in data]\n\ndataset_a = datasets[\"A\"]\ndataset_b = datasets[\"B\"]\ndataset_c = datasets[\"C\"]\n\n\n\n# Clase para contar comparaciones\nclass ComparisonCounter:\n    def __init__(self):\n        self.count = 0\n\n    def compare(self, a, b) -&gt; int:\n        \"\"\"Compara dos valores y acumula el número de comparaciones.\"\"\"\n        self.count += 1\n        if a &lt; b:\n            return -1\n        elif a &gt; b:\n            return 1\n        return 0\n\n    def reset(self):\n        \"\"\"Reinicia el contador.\"\"\"\n        self.count = 0\n\n\n\n# BÚSQUEDA BINARIA INSTRUMENTADA\ndef instrumented_binary_search(arr, x, low=0, high=None, counter=None) -&gt; int:\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n    high = len(arr) - 1 if high is None else high\n    while low &lt;= high:\n        mid = (low + high) // 2\n        cmp = counter.compare(arr[mid], x)\n        if cmp == 0:\n            return mid\n        elif cmp &lt; 0:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return -1\n\n# BÚSQUEDA EXPONENCIAL + BINARIA\ndef exponential_binary_search(arr, x, start=0, counter=None) -&gt; int:\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n    n = len(arr)\n    bound = 1\n    while start + bound &lt; n and counter.compare(arr[start + bound], x) &lt; 0:\n        bound *= 2\n    low = start + bound // 2\n    high = min(start + bound, n - 1)\n    pos = instrumented_binary_search(arr, x, low, high, counter)\n    return pos if pos &gt;= 0 else high + 1\n\n# BÚSQUEDA DOBLE EXPONENCIAL (B2)\ndef double_exponential_search(arr, x, start=0, counter=None) -&gt; int:\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n    n = len(arr)\n    exp = 1\n    while start + (1 &lt;&lt; exp) &lt; n and counter.compare(arr[start + (1 &lt;&lt; exp)], x) &lt; 0:\n        exp += 1\n    outer_low = start + (1 &lt;&lt; (exp - 1))\n    outer_high = min(start + (1 &lt;&lt; exp), n - 1)\n    return exponential_binary_search(arr, x, outer_low, counter)\n\n\n\n# MELDING (ME)\ndef melding_intersection(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    if len(sets) == 1:\n        return sets[0], counter.count\n    result = []\n    pointers = [0] * len(sets)\n    while all(ptr &lt; len(sets[i]) for i, ptr in enumerate(pointers)):\n        current_values = [sets[i][ptr] for i, ptr in enumerate(pointers)]\n        max_val = max(current_values)\n        for val in current_values:\n            counter.compare(val, max_val)\n        if all(counter.compare(val, max_val) == 0 for val in current_values):\n            result.append(max_val)\n            pointers = [ptr + 1 for ptr in pointers]\n        else:\n            for i in range(len(sets)):\n                while pointers[i] &lt; len(sets[i]) and counter.compare(sets[i][pointers[i]], max_val) &lt; 0:\n                    pointers[i] += 1\n    return result, counter.count\n\n# BAEZA-YATES: BISECCIÓN\ndef baeza_yates_bisection(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    sorted_sets = sorted(sets, key=len)\n    result = sorted_sets[0].copy()\n    for s in sorted_sets[1:]:\n        result = [e for e in result if instrumented_binary_search(s, e, 0, None, counter) != -1]\n        if not result:\n            break\n    return result, counter.count\n\n# BAEZA-YATES: BÚSQUEDA B1\ndef baeza_yates_b1(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    sorted_sets = sorted(sets, key=len)\n    smallest = sorted_sets[0]\n    result = []\n    for e in smallest:\n        if all(exponential_binary_search(s, e, 0, counter) != -1 for s in sorted_sets[1:]):\n            result.append(e)\n    return result, counter.count\n\n# BAEZA-YATES: BÚSQUEDA B2\ndef baeza_yates_b2(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    sorted_sets = sorted(sets, key=len)\n    smallest = sorted_sets[0]\n    result = []\n    positions = [0] * len(sorted_sets)\n    for e in smallest:\n        matched = True\n        for i in range(1, len(sorted_sets)):\n            s = sorted_sets[i]\n            pos = double_exponential_search(s, e, positions[i], counter)\n            if pos &gt;= len(s) or counter.compare(s[pos], e) != 0:\n                matched = False\n                break\n            positions[i] = pos\n        if matched:\n            result.append(e)\n    return result, counter.count\n\n# BARBAY & KENYON (BK)\ndef bk_intersection(lists, findpos=exponential_binary_search):\n    counter = ComparisonCounter()\n    n = len(lists)\n    if n == 0 or any(not lst for lst in lists):\n        return [], 0\n    pointers = [0] * n\n    result = []\n    candidate = lists[0][0]\n    while True:\n        match_count = 0\n        for i in range(n):\n            pos = findpos(lists[i], candidate, pointers[i], counter)\n            pointers[i] = pos\n            if pos &gt;= len(lists[i]):\n                return result, counter.count\n            value = lists[i][pos]\n            if value == candidate:\n                match_count += 1\n                if match_count == n:\n                    result.append(candidate)\n                    match_count = 0\n                pointers[i] += 1\n                if pointers[i] &gt;= len(lists[i]):\n                    return result, counter.count\n                candidate = lists[i][pointers[i]]\n            else:\n                match_count = 0\n                candidate = value\n                break\n    return result, counter.count\n\n\n\n# Mapa de algoritmos disponibles\nalgoritmos = {\n    'ME': melding_intersection,\n    'BY_bis': baeza_yates_bisection,\n    'BY_B1': baeza_yates_b1,\n    'BY_B2': baeza_yates_b2,\n    'BK': bk_intersection,\n}\n\n# Ejecutar un algoritmo sobre una lista de grupos\ndef ejecutar_algoritmo(algoritmo, grupos):\n    \"\"\"\n    Ejecuta un algoritmo sobre múltiples grupos de listas ordenadas.\n\n    Retorna una lista de tuplas con:\n    (tiempo de ejecución, número de comparaciones, longitud de la intersección)\n    \"\"\"\n    resultados = []\n    for grupo in grupos:\n        inicio = time.time()\n        interseccion, comparaciones = algoritmo(grupo)\n        fin = time.time()\n        resultados.append((fin - inicio, comparaciones, len(interseccion)))\n    return resultados\n\n# Evaluar todos los algoritmos sobre A, B y C\ndef evaluate_algorithms_on_datasets(dataset_a, dataset_b, dataset_c):\n    \"\"\"\n    Ejecuta cada algoritmo sobre los tres conjuntos (A, B y C)\n    y almacena los resultados en un diccionario.\n    \"\"\"\n    etiquetas = {'A': dataset_a, 'B': dataset_b, 'C': dataset_c}\n    resultados = {}\n\n    for nombre, algoritmo in algoritmos.items():\n        resultados[nombre] = {}\n        for etiqueta, dataset in etiquetas.items():\n            resultados[nombre][etiqueta] = ejecutar_algoritmo(algoritmo, dataset)\n\n    return resultados\n\n\n\n# Resultados a Dataframe\ndef resultados_a_dataframe(resultados):\n    \"\"\"\n    Convierte el diccionario de resultados en un DataFrame tabular plano\n    con las columnas: algoritmo, conjunto, tiempo, comparaciones, long_inter.\n    \"\"\"\n    registros = [\n        {\n            \"algoritmo\": algoritmo,\n            \"conjunto\": conjunto,\n            \"tiempo\": tiempo,\n            \"comparaciones\": comparaciones,\n            \"long_inter\": longitud\n        }\n        for algoritmo, por_conjunto in resultados.items()\n        for conjunto, ejecuciones in por_conjunto.items()\n        for tiempo, comparaciones, longitud in ejecuciones\n    ]\n    return pd.DataFrame(registros)\n\n\n\n# Generar boxplot para una métrica específica\ndef plot_metric_boxplot(df, metric, title, ylabel):\n    \"\"\"\n    genera un boxplot por conjunto para una métrica específica.\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(data=df, x=\"conjunto\", y=metric, hue=\"algoritmo\")\n    plt.title(title)\n    plt.xlabel(\"conjunto\")\n    plt.ylabel(ylabel)\n    plt.legend(title=\"algoritmo\")\n    plt.tight_layout()\n    plt.show()\n\n# Ejecución de todo el flujo\nresultados = evaluate_algorithms_on_datasets(dataset_a, dataset_b, dataset_c)\ndf = resultados_a_dataframe(resultados)\ndf.to_csv(\"resultados_1.csv\", index=False)\ndisplay(df)\n\n# Boxplot: tiempo de ejecución\nplot_metric_boxplot(df, \"tiempo\", \"Comparativa de Tiempos por Algoritmo y Conjunto\", \"Tiempo (s)\")\n\n# Boxplot: número de comparaciones \nplot_metric_boxplot(df, \"comparaciones\", \"Número de Comparaciones por Algoritmo y Conjunto\", \"Comparaciones\")\n\n# Boxplot: longitud de la intersección \nplot_metric_boxplot(df, \"long_inter\", \"Longitud de Intersección por Algoritmo y Conjunto\", \"Tamaño de la Intersección\")\n\n\n\n# Resumen estadístico agrupado por algoritmo y conjunto\ndef resumen_metricas(df):\n    \"\"\"\n    Genera un resumen estadístico con media, desviación estándar, mínimo y máximo\n    para cada métrica agrupada por algoritmo y conjunto.\n    \"\"\"\n    resumen = df.groupby(['algoritmo', 'conjunto']).agg({\n        'tiempo': ['mean', 'std', 'min', 'max'],\n        'comparaciones': ['mean', 'std', 'min', 'max'],\n        'long_inter': ['mean', 'std', 'min', 'max']\n    }).round(4)\n    resumen.columns = ['_'.join(col).strip() for col in resumen.columns.values]  # aplanar columnas\n    resumen = resumen.reset_index()  # volver columnas los índices\n    return resumen\n\n# Generar resumen estadístico\nsummary = resumen_metricas(df)\n\n# Mostrar en consola\nprint(\"Resumen estadístico de algoritmos de intersección por conjunto:\")\ndisplay(summary)\n\n# Exportar a CSV\nsummary.to_csv(\"resumen_estadistico_algoritmos.csv\", index=False)\n\n\n\n\nLos siguientes gráficos boxplot muestran de forma visual el comportamiento de cinco algoritmos de intersección aplicados sobre listas ordenadas: Melding (ME), Baeza-Yates con bisección (BY_bis), Baeza-Yates con búsqueda exponencial (BY_B1), Baeza-Yates con doble exponencial (BY_B2) y Barbay & Kenyon (BK). La evaluación se hizo sobre tres conjuntos de prueba: A (pares de listas), B (tripletas) y C (tetrapletas). Cada gráfico representa una métrica clave: el tiempo de ejecución, que indica cuánto tarda cada algoritmo; el número de comparaciones, que refleja su complejidad operativa; y el tamaño de la intersección, que funciona como control para confirmar que todos los algoritmos están resolviendo el mismo problema. Estos resultados permiten visualizar claramente las diferencias de desempeño, así como identificar qué algoritmos son más consistentes y eficientes ante distintas estructuras de datos.\nAdemás del análisis gráfico, también se incluyó una comparación cuantitativa más detallada en forma de tablas. Estas presentan estadísticas descriptivas para las tres métricas clave: tiempos de ejecución (en segundos), número de comparaciones y tamaño de la intersección. Por cada combinación de algoritmo y conjunto, se reportan valores como la media, mediana, desviación estándar y los rangos de valores mínimos y máximos. Esta información complementa los gráficos al proporcionar una base numérica concreta que permite evaluar con mayor precisión el comportamiento de cada estrategia de intersección bajo diferentes condiciones de prueba.\n\n\n\n\n\n\n\nEn este gráfico se pueden ver los tiempos de ejecución de los algoritmos en los conjuntos A, B y C. Lo que más resalta es que el algoritmo Melding (ME) tarda más que los demás en todos los conjuntos, y además tiene mucha variabilidad, con bastantes valores atípicos. Esto sugiere que su rendimiento no es muy estable. En cambio, el algoritmo de Barbay & Kenyon (BK) es el más rápido y constante, sobre todo en los conjuntos A y C, donde sus tiempos están bien concentrados y cerca del mínimo. Las variantes de Baeza-Yates (BY_bis, BY_B1 y BY_B2) también tienen buenos tiempos, con poca dispersión. En particular, BY_bis y BK son los que se comportan mejor en cuanto a velocidad. En general, este gráfico me permite ver que ME es el más lento, mientras que BK y las versiones de Baeza-Yates son más eficientes y consistentes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConjunto\nAlgoritmo\nMedia (s)\nSD\nMediana (s)\nMín (s)\nMáx (s)\n\n\n\n\nA\nBK\n0.00035\n0.00030\n0.00028\n0.00005\n0.00337\n\n\nA\nBY_bis\n0.00067\n0.00015\n0.00064\n0.00050\n0.00217\n\n\nA\nBY_B1\n0.00118\n0.00034\n0.00112\n0.00087\n0.00481\n\n\nA\nBY_B2\n0.00126\n0.00044\n0.00118\n0.00061\n0.00446\n\n\nA\nME\n0.00267\n0.00259\n0.00153\n0.00102\n0.01116\n\n\nB\nBK\n0.00066\n0.00040\n0.00055\n0.00019\n0.00461\n\n\nB\nBY_bis\n0.00091\n0.00019\n0.00088\n0.00060\n0.00163\n\n\nB\nBY_B2\n0.00134\n0.00033\n0.00125\n0.00088\n0.00288\n\n\nB\nBY_B1\n0.00146\n0.00037\n0.00137\n0.00100\n0.00294\n\n\nB\nME\n0.00446\n0.00416\n0.00287\n0.00126\n0.01725\n\n\nC\nBK\n0.00049\n0.00024\n0.00043\n0.00019\n0.00202\n\n\nC\nBY_B2\n0.00086\n0.00027\n0.00080\n0.00046\n0.00176\n\n\nC\nBY_bis\n0.00087\n0.00018\n0.00084\n0.00060\n0.00144\n\n\nC\nBY_B1\n0.00110\n0.00035\n0.00104\n0.00074\n0.00269\n\n\nC\nME\n0.00291\n0.00194\n0.00251\n0.00132\n0.01159\n\n\n\nAl analizar los tiempos de ejecución por algoritmo y conjunto, se ve claramente que el algoritmo Melding (ME) es el más lento en los tres casos. Por ejemplo, en el conjunto B, su tiempo promedio es de 0.00446 s, con una desviación estándar de 0.00416 s, lo que además muestra una gran variabilidad. Su tiempo máximo en ese conjunto alcanza los 0.01725 s, muy por encima del resto. Lo mismo ocurre en los conjuntos A y C, donde ME también tiene los valores más altos: 0.00267 s en A y 0.00291 s en C, confirmando que no es un algoritmo eficiente en términos de tiempo.\nEn cambio, el algoritmo Barbay & Kenyon (BK) destaca por ser el más rápido. En el conjunto A, su tiempo promedio es de apenas 0.00035 s, con un mínimo de 0.00005 s y un máximo de solo 0.00337 s. En el conjunto C, también tiene muy buen rendimiento, con una media de 0.00049 s. Este comportamiento muestra que BK no solo es rápido, sino también bastante constante.\nLas variantes de Baeza-Yates tienen un rendimiento intermedio. De ellas, BY_bis es la más rápida, con promedios de 0.00067 s en A, 0.00091 s en B y 0.00087 s en C, todos con baja desviación. Por otro lado, BY_B1 y BY_B2 son un poco más lentas (por ejemplo, BY_B1 en B tiene una media de 0.00146 s), pero siguen siendo más eficientes que ME.\n\n\n\n\n\n\n\n\n\nEn este gráfico se muestran las diferencias en el número de comparaciones que realiza cada algoritmo al aplicarse sobre los conjuntos A, B y C. El algoritmo que más sobresale en este aspecto es Melding (ME), ya que en los tres conjuntos es el que hace más comparaciones, con valores que varían bastante y con presencia de muchos outliers. En el conjunto B, por ejemplo, algunos casos llegan a superar las 80,000 comparaciones, lo cual es muy alto comparado con los demás algoritmos. Además, la dispersión en ME es muy amplia, lo que indica que su comportamiento no es constante y que puede llegar a ser bastante ineficiente dependiendo del caso.\nPor otro lado, el algoritmo de Barbay & Kenyon (BK) es el que hace menos comparaciones en general. En los tres conjuntos mantiene una distribución muy compacta y con valores bastante bajos, lo que refleja que es más eficiente y predecible. Las variantes de Baeza-Yates (BY_bis, BY_B1 y BY_B2) tienen un comportamiento intermedio. BY_bis es el que tiene menos comparaciones dentro de ese grupo, con valores bajos y poca variación. BY_B1 y BY_B2 hacen más comparaciones, pero aun así están lejos de alcanzar los niveles de ME.\n\n\n\n\n\n\nConjunto\nAlgoritmo\nMedia\nMediana\nSD\nMín\nMáx\n\n\n\n\nA\nBK\n493\n444\n191\n59\n1180\n\n\nA\nBY_bis\n1361\n1353\n165\n1068\n1865\n\n\nA\nBY_B2\n2411\n2367\n455\n1173\n3831\n\n\nA\nBY_B1\n2493\n2472\n324\n1926\n3422\n\n\nA\nME\n9128\n4574\n10654\n3152\n42392\n\n\nB\nBK\n1233\n1085\n405\n346\n2376\n\n\nB\nBY_bis\n2805\n2751\n241\n2222\n3384\n\n\nB\nBY_B2\n4951\n4762\n662\n3223\n6582\n\n\nB\nBY_B1\n5374\n5161\n780\n3833\n7358\n\n\nB\nME\n18321\n12888\n17246\n4417\n85447\n\n\nC\nBK\n1602\n1493\n375\n840\n3017\n\n\nC\nBY_bis\n3808\n3691\n327\n3002\n4662\n\n\nC\nBY_B2\n6520\n6324\n698\n4539\n8401\n\n\nC\nBY_B1\n7105\n6842\n870\n5114\n9369\n\n\nC\nME\n21521\n14518\n16510\n5406\n56670\n\n\n\nAl observar los datos de la tabla, se nota claramente que el algoritmo Melding (ME) es el que más comparaciones realiza en todos los conjuntos. En el conjunto B, por ejemplo, tiene un promedio de 18,321 comparaciones, con una desviación estándar muy alta de 17,246, y casos extremos que alcanzan hasta 85,447. Esto refleja que ME no solo es el más costoso, sino también el más inestable. Lo mismo ocurre en los conjuntos A y C, donde sus promedios también son elevados: 9,128 en A y 21,521 en C. Además, las medianas están bastante por debajo de las medias, lo cual confirma que hay muchos valores atípicos que aumentan considerablemente el promedio.\nEn contraste, Barbay & Kenyon (BK) vuelve a destacar por ser el algoritmo más eficiente en cuanto al número de comparaciones. Sus promedios son bajos y consistentes: 493 en A, 1,233 en B y 1,602 en C, con valores mínimos que llegan hasta 59. La baja variabilidad que presenta lo convierte en una opción muy confiable. Las variantes de Baeza-Yates se encuentran en un término medio. BY_bis es la más liviana de ese grupo, con cifras razonables como 1,361 en A y 3,808 en C. Por su parte, BY_B1 y BY_B2 tienden a realizar más comparaciones, especialmente en los conjuntos más grandes, donde sus promedios superan los 5,000 y 6,000. Aun así, su comportamiento es más controlado comparado con el de ME. En general, esta tabla refuerza que ME es el algoritmo menos eficiente, BK el más favorable en cuanto a comparaciones, y las variantes de Baeza-Yates se mantienen dentro de rangos aceptables.\n\n\n\n\n\n\n\n\n\nEn este gráfico se muestra la longitud de la intersección obtenida por cada algoritmo en los conjuntos A, B y C. Algo que me parece importante destacar es que todos los algoritmos están resolviendo correctamente el problema de intersección, ya que los resultados que obtienen tienen coherencia dentro de cada conjunto. Sin embargo, también se notan diferencias claras en la cantidad de elementos comunes que cada uno logra recuperar. Lo que más me llamó la atención es que el algoritmo BY_B1 se comporta de forma muy distinta al resto: sus intersecciones son considerablemente más largas, sobre todo en el conjunto B, donde la mediana supera los 180 elementos y hay casos que llegan cerca de 260. También en los conjuntos A y C se nota que obtiene valores más altos. Esto sugiere que su forma de búsqueda permite capturar más coincidencias, o que mantiene los candidatos por más tiempo antes de descartarlos.\nEn contraste, el algoritmo BK es el que devuelve intersecciones mucho más pequeñas. En los tres conjuntos, sus medianas son muy bajas, en algunos casos prácticamente cero, y tiene muy poca dispersión. Esto lo hace ver como un algoritmo más restrictivo o agresivo a la hora de filtrar elementos. ME, BY_bis y BY_B2 tienen un comportamiento bastante parecido entre ellos: las longitudes de sus intersecciones son más moderadas, con una variabilidad controlada y sin tantos extremos. En general, este gráfico me ayuda a entender no solo que todos los algoritmos funcionan, sino también cómo varía el enfoque de cada uno en cuanto a qué tan amplia o limitada es la intersección que devuelve. Al final, esas diferencias pueden depender de la lógica interna del algoritmo, del orden en que recorren las listas o incluso de cómo manejan la condición de coincidencia entre elementos.\n\n\n\n\n\n\nConjunto\nAlgoritmo\nPromedio\nMediana\n\n\n\n\nA\nBY_B1\n111.6\n111\n\n\nA\nBY_bis\n20.2\n15\n\n\nA\nBY_B2\n20.1\n14\n\n\nA\nME\n19.6\n14\n\n\nA\nBK\n2.8\n1\n\n\nB\nBY_B1\n189.7\n188\n\n\nB\nBY_bis\n25.0\n17\n\n\nB\nBY_B2\n25.1\n16\n\n\nB\nME\n23.6\n15\n\n\nB\nBK\n3.4\n2\n\n\nC\nBY_B1\n112.0\n111\n\n\nC\nBY_bis\n9.2\n4\n\n\nC\nBY_B2\n7.7\n3\n\n\nC\nME\n7.8\n3\n\n\nC\nBK\n0.18\n0\n\n\n\nEn esta tabla se comparan las longitudes de intersección que obtiene cada algoritmo en los conjuntos A, B y C. Lo primero que noto es que BY_B1 es el que siempre genera intersecciones más grandes. En los tres conjuntos tiene los valores más altos tanto en promedio como en mediana. En el conjunto B, por ejemplo, su promedio es de 189.7, con una mediana de 188. También en A y C se mantiene por encima de los demás, con promedios de 111.6 y 112 respectivamente. Esto confirma que su estrategia de búsqueda logra encontrar más coincidencias entre las listas, lo que termina generando intersecciones mucho más largas.\nPor otro lado, el algoritmo BK es el que da los resultados más bajos. En el conjunto C, su promedio es de apenas 0.18 y la mediana es 0, lo que significa que en la mayoría de los casos ni siquiera encuentra elementos comunes. En los conjuntos A y B también se mantiene con valores muy bajos. En cambio, ME, BY_bis y BY_B2 tienen un comportamiento más equilibrado. En A, por ejemplo, sus promedios están muy parejos entre los 19 y 20 elementos, y algo similar pasa en los otros dos conjuntos. En general, esta tabla me deja claro que todos los algoritmos están resolviendo bien el problema, pero hay diferencias importantes en la cantidad de elementos que logran conservar en la intersección. Eso seguramente tiene que ver con cómo manejan los punteros y las condiciones de comparación dentro de cada estrategia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTiempo\nComparaciones\nIntersección\nComentario\n\n\n\n\nBK\nMás rápido y constante\nMenos comparaciones\nMuy baja\nExtremadamente eficiente, pero muy restrictivo\n\n\nBY_bis\nRápido\nBajo\nModerada\nBuen balance entre eficiencia y recuperación\n\n\nBY_B1\nMás lento\nMás comparaciones\nMayor intersección\nCaptura más coincidencias, ideal para recuperar más datos\n\n\nBY_B2\nIntermedio\nMedio\nIntermedia\nBuen compromiso entre B1 y bis\n\n\nME\nMás lento e inestable\nMás comparaciones\nModerada\nPoco eficiente, comportamiento muy variable\n\n\n\n\n\n\n\n\n\nUna de las conclusiones más claras que obtuve de este análisis es que el algoritmo Barbay & Kenyon (BK) fue consistentemente el más eficiente en cuanto a tiempo de ejecución y número de comparaciones. En los tres conjuntos evaluados, sus resultados fueron los más bajos y estables, lo que indica que es una opción muy efectiva cuando se requiere rendimiento rápido y predecible. Esto lo convierte en una excelente alternativa para contextos donde la eficiencia computacional es prioritaria.\nEn cuanto a las variantes de Baeza-Yates, pude observar que su comportamiento fue más equilibrado. BY_bis resultó ser bastante eficiente, con buenos tiempos y pocas comparaciones, mientras que BY_B1 se destacó por generar intersecciones mucho más largas. Esto me llevó a concluir que cada variante tiene su enfoque particular: algunas priorizan la rapidez y otras la exhaustividad en la coincidencia de elementos, lo cual puede ser útil dependiendo del tipo de aplicación.\nPor otro lado, el algoritmo Melding (ME) demostró ser el menos eficiente en todos los escenarios. No solo fue el más lento, sino también el que realizó más comparaciones y mostró una gran variabilidad en su comportamiento. En varios casos, sus valores máximos estuvieron muy por encima del resto, lo que deja claro que su desempeño no es confiable y que puede volverse extremadamente costoso en situaciones adversas.\nOtra observación importante es que la longitud de las intersecciones varía mucho entre algoritmos. Por ejemplo, BK tiende a devolver resultados muy pequeños o incluso vacíos, lo que sugiere que su criterio de coincidencia es muy restrictivo. En cambio, BY_B1 logra captar muchas más coincidencias, lo que podría deberse a su estrategia de búsqueda más flexible o tolerante. Esta diferencia me ayudó a entender mejor cómo cada algoritmo interpreta la condición de intersección.\nTodos los algoritmos evaluados lograron resolver correctamente el problema de intersección de listas ordenadas, pero quedó claro que no todos lo hacen de la misma manera ni con el mismo nivel de eficiencia. Cada uno adopta una estrategia distinta que impacta directamente en su rendimiento, ya sea en términos de tiempo de ejecución, número de comparaciones o tamaño de la intersección obtenida.\n\n\n\nLos resultados numéricos de este análisis me llevaron a reflexionar sobre la importancia de no basar la elección de un algoritmo únicamente en una métrica aislada. Es fundamental considerar el contexto y el propósito específico de la aplicación. Por ejemplo, algoritmos como BK se destacan por ser extremadamente rápidos y eficientes en términos computacionales, pero su forma de filtrar elementos tiende a ser muy estricta, lo que genera intersecciones considerablemente más pequeñas. Este comportamiento puede ser ventajoso en entornos donde la prioridad es la velocidad de respuesta, aunque implique sacrificar coincidencias potenciales.\nEn contraste, variantes como BY_B1 realizan un mayor número de comparaciones, pero a cambio logran recuperar conjuntos más amplios de elementos comunes. Esto puede resultar esencial en tareas donde se privilegia la exhaustividad y la precisión por encima del costo computacional. Esta diferencia de enfoques evidencia que no existe un algoritmo universalmente óptimo; cada uno tiene fortalezas y limitaciones que deben ser cuidadosamente evaluadas en función de los objetivos concretos del sistema o aplicación en la que se pretende implementar.\n\n\n\n\n\nBaeza-Yates, R. (2004). A fast set intersection algorithm for sorted sequences. En S. C. Sahinalp, S. Muthukrishnan & U. Dogrusoz (Eds.), Combinatorial Pattern Matching (pp. 400–408). Springer. https://doi.org/10.1007/978-3-540-27801-6_30\nBarbay, J., & Kenyon, C. (2002). Adaptive intersection and t-threshold problems. Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms (pp. 390–399). Society for Industrial and Applied Mathematics. https://barbay.cl/Publications/2002-SODA-AdaptiveIntersectionAndTThresholdProblems-BarbayKenyon.pdf\nBarbay, J., López-Ortiz, A., Lu, T., & Salinger, A. (2009). An experimental investigation of set intersection algorithms for text searching. ACM Journal of Experimental Algorithmics, 14, Article 3.7. https://cs.uwaterloo.ca/~alopez-o/files/AEIoSIAfTS_2009.pdf\n\n\n\n\nAun no se han realizado cambios. Se envió en fecha actual."
  },
  {
    "objectID": "project5.html#introducción",
    "href": "project5.html#introducción",
    "title": "Proyecto 5",
    "section": "",
    "text": "El trabajo con grandes volúmenes de datos requiere encontrar formas eficientes de realizar operaciones básicas como la intersección de listas. Esta tarea, que consiste en identificar los elementos comunes entre varias listas ordenadas, resulta fundamental en sistemas como los motores de búsqueda, el filtrado de datos o el procesamiento de información en general. En este proyecto se propuso implementar y comparar varios algoritmos de intersección con el objetivo de analizar sus diferencias, ventajas y limitaciones en distintos escenarios.\nLos algoritmos seleccionados para este análisis fueron Melding (ME), Baeza-Yates (BY) y Barbay & Kenyon (BK). Cada uno de ellos aborda el problema desde una estrategia distinta, lo que permite observar cómo se comportan las listas.\nEl algoritmo Melding prioriza las listas más pequeñas para cruzarlas primero. Esta estrategia permite reducir el tamaño de las intersecciones parciales desde el inicio, acelerando el proceso cuando algunas listas tienen pocos elementos que filtran rápidamente el resultado (Barbay et al., 2009).\nEl algoritmo Baeza-Yates parte de una lista base y busca sus elementos en las demás listas utilizando distintas técnicas. En este estudio se emplearon tres variantes: búsqueda binaria, búsqueda no acotada B1 (con saltos exponenciales y luego binaria) y la versión B2 (que mejora los saltos iniciales). Estas variantes permiten optimizar el número de comparaciones en función del tamaño relativo de las listas (Baeza-Yates, 2004).\nEl algoritmo Barbay & Kenyon presenta un enfoque más complejo y adaptativo. Alterna entre recorridos secuenciales y saltos controlados, decidiendo en tiempo real cuál estrategia aplicar según el patrón de los datos. Esta flexibilidad lo hace útil para listas con estructuras irregulares o alta dispersión de valores (Barbay & Kenyon, 2002).\nPara evaluar el rendimiento de estos algoritmos, se trabajó con tres conjuntos de datos: el Conjunto A, con pares de listas; el Conjunto B, con tripletas; y el Conjunto C, con cuatro listas. En cada caso se midieron el tiempo de ejecución, el número de comparaciones realizadas y el tamaño de la intersección obtenida. Posteriormente, los resultados fueron representados mediante gráficos tipo boxplot, facilitando la comparación visual del rendimiento de cada algoritmo en distintos escenarios."
  },
  {
    "objectID": "project5.html#desarrollo",
    "href": "project5.html#desarrollo",
    "title": "Proyecto 5",
    "section": "",
    "text": "# Bibliotecas Utilizadas\nimport os\nimport json\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import List, Tuple, Optional\n\n# Ruta de Archivos\nbase_path = r\"C:\\Users\\Antonio Martínez\\Downloads\\Conjuntos de listas de posteo para intersección-20250520\"\n\nfile_map = {\n    'A': 'postinglists-for-intersection-A-k=2.json',\n    'B': 'postinglists-for-intersection-B-k=3.json',\n    'C': 'postinglists-for-intersection-C-k=4.json',\n}\n\n# Carga y ordena listas dentro de cada grupo\ndef load_json_data(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n\ndatasets = {}\nfor label, fname in file_map.items():\n    full_path = os.path.join(base_path, fname)\n    data = load_json_data(full_path)\n    datasets[label] = [[sorted(sublist) for sublist in group] for group in data]\n\ndataset_a = datasets[\"A\"]\ndataset_b = datasets[\"B\"]\ndataset_c = datasets[\"C\"]\n\n\n\n# Clase para contar comparaciones\nclass ComparisonCounter:\n    def __init__(self):\n        self.count = 0\n\n    def compare(self, a, b) -&gt; int:\n        \"\"\"Compara dos valores y acumula el número de comparaciones.\"\"\"\n        self.count += 1\n        if a &lt; b:\n            return -1\n        elif a &gt; b:\n            return 1\n        return 0\n\n    def reset(self):\n        \"\"\"Reinicia el contador.\"\"\"\n        self.count = 0\n\n\n\n# BÚSQUEDA BINARIA INSTRUMENTADA\ndef instrumented_binary_search(arr, x, low=0, high=None, counter=None) -&gt; int:\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n    high = len(arr) - 1 if high is None else high\n    while low &lt;= high:\n        mid = (low + high) // 2\n        cmp = counter.compare(arr[mid], x)\n        if cmp == 0:\n            return mid\n        elif cmp &lt; 0:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return -1\n\n# BÚSQUEDA EXPONENCIAL + BINARIA\ndef exponential_binary_search(arr, x, start=0, counter=None) -&gt; int:\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n    n = len(arr)\n    bound = 1\n    while start + bound &lt; n and counter.compare(arr[start + bound], x) &lt; 0:\n        bound *= 2\n    low = start + bound // 2\n    high = min(start + bound, n - 1)\n    pos = instrumented_binary_search(arr, x, low, high, counter)\n    return pos if pos &gt;= 0 else high + 1\n\n# BÚSQUEDA DOBLE EXPONENCIAL (B2)\ndef double_exponential_search(arr, x, start=0, counter=None) -&gt; int:\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n    n = len(arr)\n    exp = 1\n    while start + (1 &lt;&lt; exp) &lt; n and counter.compare(arr[start + (1 &lt;&lt; exp)], x) &lt; 0:\n        exp += 1\n    outer_low = start + (1 &lt;&lt; (exp - 1))\n    outer_high = min(start + (1 &lt;&lt; exp), n - 1)\n    return exponential_binary_search(arr, x, outer_low, counter)\n\n\n\n# MELDING (ME)\ndef melding_intersection(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    if len(sets) == 1:\n        return sets[0], counter.count\n    result = []\n    pointers = [0] * len(sets)\n    while all(ptr &lt; len(sets[i]) for i, ptr in enumerate(pointers)):\n        current_values = [sets[i][ptr] for i, ptr in enumerate(pointers)]\n        max_val = max(current_values)\n        for val in current_values:\n            counter.compare(val, max_val)\n        if all(counter.compare(val, max_val) == 0 for val in current_values):\n            result.append(max_val)\n            pointers = [ptr + 1 for ptr in pointers]\n        else:\n            for i in range(len(sets)):\n                while pointers[i] &lt; len(sets[i]) and counter.compare(sets[i][pointers[i]], max_val) &lt; 0:\n                    pointers[i] += 1\n    return result, counter.count\n\n# BAEZA-YATES: BISECCIÓN\ndef baeza_yates_bisection(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    sorted_sets = sorted(sets, key=len)\n    result = sorted_sets[0].copy()\n    for s in sorted_sets[1:]:\n        result = [e for e in result if instrumented_binary_search(s, e, 0, None, counter) != -1]\n        if not result:\n            break\n    return result, counter.count\n\n# BAEZA-YATES: BÚSQUEDA B1\ndef baeza_yates_b1(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    sorted_sets = sorted(sets, key=len)\n    smallest = sorted_sets[0]\n    result = []\n    for e in smallest:\n        if all(exponential_binary_search(s, e, 0, counter) != -1 for s in sorted_sets[1:]):\n            result.append(e)\n    return result, counter.count\n\n# BAEZA-YATES: BÚSQUEDA B2\ndef baeza_yates_b2(sets, counter=None):\n    if counter is None:\n        counter = ComparisonCounter()\n    if not sets:\n        return [], counter.count\n    sorted_sets = sorted(sets, key=len)\n    smallest = sorted_sets[0]\n    result = []\n    positions = [0] * len(sorted_sets)\n    for e in smallest:\n        matched = True\n        for i in range(1, len(sorted_sets)):\n            s = sorted_sets[i]\n            pos = double_exponential_search(s, e, positions[i], counter)\n            if pos &gt;= len(s) or counter.compare(s[pos], e) != 0:\n                matched = False\n                break\n            positions[i] = pos\n        if matched:\n            result.append(e)\n    return result, counter.count\n\n# BARBAY & KENYON (BK)\ndef bk_intersection(lists, findpos=exponential_binary_search):\n    counter = ComparisonCounter()\n    n = len(lists)\n    if n == 0 or any(not lst for lst in lists):\n        return [], 0\n    pointers = [0] * n\n    result = []\n    candidate = lists[0][0]\n    while True:\n        match_count = 0\n        for i in range(n):\n            pos = findpos(lists[i], candidate, pointers[i], counter)\n            pointers[i] = pos\n            if pos &gt;= len(lists[i]):\n                return result, counter.count\n            value = lists[i][pos]\n            if value == candidate:\n                match_count += 1\n                if match_count == n:\n                    result.append(candidate)\n                    match_count = 0\n                pointers[i] += 1\n                if pointers[i] &gt;= len(lists[i]):\n                    return result, counter.count\n                candidate = lists[i][pointers[i]]\n            else:\n                match_count = 0\n                candidate = value\n                break\n    return result, counter.count\n\n\n\n# Mapa de algoritmos disponibles\nalgoritmos = {\n    'ME': melding_intersection,\n    'BY_bis': baeza_yates_bisection,\n    'BY_B1': baeza_yates_b1,\n    'BY_B2': baeza_yates_b2,\n    'BK': bk_intersection,\n}\n\n# Ejecutar un algoritmo sobre una lista de grupos\ndef ejecutar_algoritmo(algoritmo, grupos):\n    \"\"\"\n    Ejecuta un algoritmo sobre múltiples grupos de listas ordenadas.\n\n    Retorna una lista de tuplas con:\n    (tiempo de ejecución, número de comparaciones, longitud de la intersección)\n    \"\"\"\n    resultados = []\n    for grupo in grupos:\n        inicio = time.time()\n        interseccion, comparaciones = algoritmo(grupo)\n        fin = time.time()\n        resultados.append((fin - inicio, comparaciones, len(interseccion)))\n    return resultados\n\n# Evaluar todos los algoritmos sobre A, B y C\ndef evaluate_algorithms_on_datasets(dataset_a, dataset_b, dataset_c):\n    \"\"\"\n    Ejecuta cada algoritmo sobre los tres conjuntos (A, B y C)\n    y almacena los resultados en un diccionario.\n    \"\"\"\n    etiquetas = {'A': dataset_a, 'B': dataset_b, 'C': dataset_c}\n    resultados = {}\n\n    for nombre, algoritmo in algoritmos.items():\n        resultados[nombre] = {}\n        for etiqueta, dataset in etiquetas.items():\n            resultados[nombre][etiqueta] = ejecutar_algoritmo(algoritmo, dataset)\n\n    return resultados\n\n\n\n# Resultados a Dataframe\ndef resultados_a_dataframe(resultados):\n    \"\"\"\n    Convierte el diccionario de resultados en un DataFrame tabular plano\n    con las columnas: algoritmo, conjunto, tiempo, comparaciones, long_inter.\n    \"\"\"\n    registros = [\n        {\n            \"algoritmo\": algoritmo,\n            \"conjunto\": conjunto,\n            \"tiempo\": tiempo,\n            \"comparaciones\": comparaciones,\n            \"long_inter\": longitud\n        }\n        for algoritmo, por_conjunto in resultados.items()\n        for conjunto, ejecuciones in por_conjunto.items()\n        for tiempo, comparaciones, longitud in ejecuciones\n    ]\n    return pd.DataFrame(registros)\n\n\n\n# Generar boxplot para una métrica específica\ndef plot_metric_boxplot(df, metric, title, ylabel):\n    \"\"\"\n    genera un boxplot por conjunto para una métrica específica.\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(data=df, x=\"conjunto\", y=metric, hue=\"algoritmo\")\n    plt.title(title)\n    plt.xlabel(\"conjunto\")\n    plt.ylabel(ylabel)\n    plt.legend(title=\"algoritmo\")\n    plt.tight_layout()\n    plt.show()\n\n# Ejecución de todo el flujo\nresultados = evaluate_algorithms_on_datasets(dataset_a, dataset_b, dataset_c)\ndf = resultados_a_dataframe(resultados)\ndf.to_csv(\"resultados_1.csv\", index=False)\ndisplay(df)\n\n# Boxplot: tiempo de ejecución\nplot_metric_boxplot(df, \"tiempo\", \"Comparativa de Tiempos por Algoritmo y Conjunto\", \"Tiempo (s)\")\n\n# Boxplot: número de comparaciones \nplot_metric_boxplot(df, \"comparaciones\", \"Número de Comparaciones por Algoritmo y Conjunto\", \"Comparaciones\")\n\n# Boxplot: longitud de la intersección \nplot_metric_boxplot(df, \"long_inter\", \"Longitud de Intersección por Algoritmo y Conjunto\", \"Tamaño de la Intersección\")\n\n\n\n# Resumen estadístico agrupado por algoritmo y conjunto\ndef resumen_metricas(df):\n    \"\"\"\n    Genera un resumen estadístico con media, desviación estándar, mínimo y máximo\n    para cada métrica agrupada por algoritmo y conjunto.\n    \"\"\"\n    resumen = df.groupby(['algoritmo', 'conjunto']).agg({\n        'tiempo': ['mean', 'std', 'min', 'max'],\n        'comparaciones': ['mean', 'std', 'min', 'max'],\n        'long_inter': ['mean', 'std', 'min', 'max']\n    }).round(4)\n    resumen.columns = ['_'.join(col).strip() for col in resumen.columns.values]  # aplanar columnas\n    resumen = resumen.reset_index()  # volver columnas los índices\n    return resumen\n\n# Generar resumen estadístico\nsummary = resumen_metricas(df)\n\n# Mostrar en consola\nprint(\"Resumen estadístico de algoritmos de intersección por conjunto:\")\ndisplay(summary)\n\n# Exportar a CSV\nsummary.to_csv(\"resumen_estadistico_algoritmos.csv\", index=False)"
  },
  {
    "objectID": "project5.html#análisis-de-resultados",
    "href": "project5.html#análisis-de-resultados",
    "title": "Proyecto 5",
    "section": "",
    "text": "Los siguientes gráficos boxplot muestran de forma visual el comportamiento de cinco algoritmos de intersección aplicados sobre listas ordenadas: Melding (ME), Baeza-Yates con bisección (BY_bis), Baeza-Yates con búsqueda exponencial (BY_B1), Baeza-Yates con doble exponencial (BY_B2) y Barbay & Kenyon (BK). La evaluación se hizo sobre tres conjuntos de prueba: A (pares de listas), B (tripletas) y C (tetrapletas). Cada gráfico representa una métrica clave: el tiempo de ejecución, que indica cuánto tarda cada algoritmo; el número de comparaciones, que refleja su complejidad operativa; y el tamaño de la intersección, que funciona como control para confirmar que todos los algoritmos están resolviendo el mismo problema. Estos resultados permiten visualizar claramente las diferencias de desempeño, así como identificar qué algoritmos son más consistentes y eficientes ante distintas estructuras de datos.\nAdemás del análisis gráfico, también se incluyó una comparación cuantitativa más detallada en forma de tablas. Estas presentan estadísticas descriptivas para las tres métricas clave: tiempos de ejecución (en segundos), número de comparaciones y tamaño de la intersección. Por cada combinación de algoritmo y conjunto, se reportan valores como la media, mediana, desviación estándar y los rangos de valores mínimos y máximos. Esta información complementa los gráficos al proporcionar una base numérica concreta que permite evaluar con mayor precisión el comportamiento de cada estrategia de intersección bajo diferentes condiciones de prueba.\n\n\n\n\n\n\n\nEn este gráfico se pueden ver los tiempos de ejecución de los algoritmos en los conjuntos A, B y C. Lo que más resalta es que el algoritmo Melding (ME) tarda más que los demás en todos los conjuntos, y además tiene mucha variabilidad, con bastantes valores atípicos. Esto sugiere que su rendimiento no es muy estable. En cambio, el algoritmo de Barbay & Kenyon (BK) es el más rápido y constante, sobre todo en los conjuntos A y C, donde sus tiempos están bien concentrados y cerca del mínimo. Las variantes de Baeza-Yates (BY_bis, BY_B1 y BY_B2) también tienen buenos tiempos, con poca dispersión. En particular, BY_bis y BK son los que se comportan mejor en cuanto a velocidad. En general, este gráfico me permite ver que ME es el más lento, mientras que BK y las versiones de Baeza-Yates son más eficientes y consistentes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConjunto\nAlgoritmo\nMedia (s)\nSD\nMediana (s)\nMín (s)\nMáx (s)\n\n\n\n\nA\nBK\n0.00035\n0.00030\n0.00028\n0.00005\n0.00337\n\n\nA\nBY_bis\n0.00067\n0.00015\n0.00064\n0.00050\n0.00217\n\n\nA\nBY_B1\n0.00118\n0.00034\n0.00112\n0.00087\n0.00481\n\n\nA\nBY_B2\n0.00126\n0.00044\n0.00118\n0.00061\n0.00446\n\n\nA\nME\n0.00267\n0.00259\n0.00153\n0.00102\n0.01116\n\n\nB\nBK\n0.00066\n0.00040\n0.00055\n0.00019\n0.00461\n\n\nB\nBY_bis\n0.00091\n0.00019\n0.00088\n0.00060\n0.00163\n\n\nB\nBY_B2\n0.00134\n0.00033\n0.00125\n0.00088\n0.00288\n\n\nB\nBY_B1\n0.00146\n0.00037\n0.00137\n0.00100\n0.00294\n\n\nB\nME\n0.00446\n0.00416\n0.00287\n0.00126\n0.01725\n\n\nC\nBK\n0.00049\n0.00024\n0.00043\n0.00019\n0.00202\n\n\nC\nBY_B2\n0.00086\n0.00027\n0.00080\n0.00046\n0.00176\n\n\nC\nBY_bis\n0.00087\n0.00018\n0.00084\n0.00060\n0.00144\n\n\nC\nBY_B1\n0.00110\n0.00035\n0.00104\n0.00074\n0.00269\n\n\nC\nME\n0.00291\n0.00194\n0.00251\n0.00132\n0.01159\n\n\n\nAl analizar los tiempos de ejecución por algoritmo y conjunto, se ve claramente que el algoritmo Melding (ME) es el más lento en los tres casos. Por ejemplo, en el conjunto B, su tiempo promedio es de 0.00446 s, con una desviación estándar de 0.00416 s, lo que además muestra una gran variabilidad. Su tiempo máximo en ese conjunto alcanza los 0.01725 s, muy por encima del resto. Lo mismo ocurre en los conjuntos A y C, donde ME también tiene los valores más altos: 0.00267 s en A y 0.00291 s en C, confirmando que no es un algoritmo eficiente en términos de tiempo.\nEn cambio, el algoritmo Barbay & Kenyon (BK) destaca por ser el más rápido. En el conjunto A, su tiempo promedio es de apenas 0.00035 s, con un mínimo de 0.00005 s y un máximo de solo 0.00337 s. En el conjunto C, también tiene muy buen rendimiento, con una media de 0.00049 s. Este comportamiento muestra que BK no solo es rápido, sino también bastante constante.\nLas variantes de Baeza-Yates tienen un rendimiento intermedio. De ellas, BY_bis es la más rápida, con promedios de 0.00067 s en A, 0.00091 s en B y 0.00087 s en C, todos con baja desviación. Por otro lado, BY_B1 y BY_B2 son un poco más lentas (por ejemplo, BY_B1 en B tiene una media de 0.00146 s), pero siguen siendo más eficientes que ME.\n\n\n\n\n\n\n\n\n\nEn este gráfico se muestran las diferencias en el número de comparaciones que realiza cada algoritmo al aplicarse sobre los conjuntos A, B y C. El algoritmo que más sobresale en este aspecto es Melding (ME), ya que en los tres conjuntos es el que hace más comparaciones, con valores que varían bastante y con presencia de muchos outliers. En el conjunto B, por ejemplo, algunos casos llegan a superar las 80,000 comparaciones, lo cual es muy alto comparado con los demás algoritmos. Además, la dispersión en ME es muy amplia, lo que indica que su comportamiento no es constante y que puede llegar a ser bastante ineficiente dependiendo del caso.\nPor otro lado, el algoritmo de Barbay & Kenyon (BK) es el que hace menos comparaciones en general. En los tres conjuntos mantiene una distribución muy compacta y con valores bastante bajos, lo que refleja que es más eficiente y predecible. Las variantes de Baeza-Yates (BY_bis, BY_B1 y BY_B2) tienen un comportamiento intermedio. BY_bis es el que tiene menos comparaciones dentro de ese grupo, con valores bajos y poca variación. BY_B1 y BY_B2 hacen más comparaciones, pero aun así están lejos de alcanzar los niveles de ME.\n\n\n\n\n\n\nConjunto\nAlgoritmo\nMedia\nMediana\nSD\nMín\nMáx\n\n\n\n\nA\nBK\n493\n444\n191\n59\n1180\n\n\nA\nBY_bis\n1361\n1353\n165\n1068\n1865\n\n\nA\nBY_B2\n2411\n2367\n455\n1173\n3831\n\n\nA\nBY_B1\n2493\n2472\n324\n1926\n3422\n\n\nA\nME\n9128\n4574\n10654\n3152\n42392\n\n\nB\nBK\n1233\n1085\n405\n346\n2376\n\n\nB\nBY_bis\n2805\n2751\n241\n2222\n3384\n\n\nB\nBY_B2\n4951\n4762\n662\n3223\n6582\n\n\nB\nBY_B1\n5374\n5161\n780\n3833\n7358\n\n\nB\nME\n18321\n12888\n17246\n4417\n85447\n\n\nC\nBK\n1602\n1493\n375\n840\n3017\n\n\nC\nBY_bis\n3808\n3691\n327\n3002\n4662\n\n\nC\nBY_B2\n6520\n6324\n698\n4539\n8401\n\n\nC\nBY_B1\n7105\n6842\n870\n5114\n9369\n\n\nC\nME\n21521\n14518\n16510\n5406\n56670\n\n\n\nAl observar los datos de la tabla, se nota claramente que el algoritmo Melding (ME) es el que más comparaciones realiza en todos los conjuntos. En el conjunto B, por ejemplo, tiene un promedio de 18,321 comparaciones, con una desviación estándar muy alta de 17,246, y casos extremos que alcanzan hasta 85,447. Esto refleja que ME no solo es el más costoso, sino también el más inestable. Lo mismo ocurre en los conjuntos A y C, donde sus promedios también son elevados: 9,128 en A y 21,521 en C. Además, las medianas están bastante por debajo de las medias, lo cual confirma que hay muchos valores atípicos que aumentan considerablemente el promedio.\nEn contraste, Barbay & Kenyon (BK) vuelve a destacar por ser el algoritmo más eficiente en cuanto al número de comparaciones. Sus promedios son bajos y consistentes: 493 en A, 1,233 en B y 1,602 en C, con valores mínimos que llegan hasta 59. La baja variabilidad que presenta lo convierte en una opción muy confiable. Las variantes de Baeza-Yates se encuentran en un término medio. BY_bis es la más liviana de ese grupo, con cifras razonables como 1,361 en A y 3,808 en C. Por su parte, BY_B1 y BY_B2 tienden a realizar más comparaciones, especialmente en los conjuntos más grandes, donde sus promedios superan los 5,000 y 6,000. Aun así, su comportamiento es más controlado comparado con el de ME. En general, esta tabla refuerza que ME es el algoritmo menos eficiente, BK el más favorable en cuanto a comparaciones, y las variantes de Baeza-Yates se mantienen dentro de rangos aceptables.\n\n\n\n\n\n\n\n\n\nEn este gráfico se muestra la longitud de la intersección obtenida por cada algoritmo en los conjuntos A, B y C. Algo que me parece importante destacar es que todos los algoritmos están resolviendo correctamente el problema de intersección, ya que los resultados que obtienen tienen coherencia dentro de cada conjunto. Sin embargo, también se notan diferencias claras en la cantidad de elementos comunes que cada uno logra recuperar. Lo que más me llamó la atención es que el algoritmo BY_B1 se comporta de forma muy distinta al resto: sus intersecciones son considerablemente más largas, sobre todo en el conjunto B, donde la mediana supera los 180 elementos y hay casos que llegan cerca de 260. También en los conjuntos A y C se nota que obtiene valores más altos. Esto sugiere que su forma de búsqueda permite capturar más coincidencias, o que mantiene los candidatos por más tiempo antes de descartarlos.\nEn contraste, el algoritmo BK es el que devuelve intersecciones mucho más pequeñas. En los tres conjuntos, sus medianas son muy bajas, en algunos casos prácticamente cero, y tiene muy poca dispersión. Esto lo hace ver como un algoritmo más restrictivo o agresivo a la hora de filtrar elementos. ME, BY_bis y BY_B2 tienen un comportamiento bastante parecido entre ellos: las longitudes de sus intersecciones son más moderadas, con una variabilidad controlada y sin tantos extremos. En general, este gráfico me ayuda a entender no solo que todos los algoritmos funcionan, sino también cómo varía el enfoque de cada uno en cuanto a qué tan amplia o limitada es la intersección que devuelve. Al final, esas diferencias pueden depender de la lógica interna del algoritmo, del orden en que recorren las listas o incluso de cómo manejan la condición de coincidencia entre elementos.\n\n\n\n\n\n\nConjunto\nAlgoritmo\nPromedio\nMediana\n\n\n\n\nA\nBY_B1\n111.6\n111\n\n\nA\nBY_bis\n20.2\n15\n\n\nA\nBY_B2\n20.1\n14\n\n\nA\nME\n19.6\n14\n\n\nA\nBK\n2.8\n1\n\n\nB\nBY_B1\n189.7\n188\n\n\nB\nBY_bis\n25.0\n17\n\n\nB\nBY_B2\n25.1\n16\n\n\nB\nME\n23.6\n15\n\n\nB\nBK\n3.4\n2\n\n\nC\nBY_B1\n112.0\n111\n\n\nC\nBY_bis\n9.2\n4\n\n\nC\nBY_B2\n7.7\n3\n\n\nC\nME\n7.8\n3\n\n\nC\nBK\n0.18\n0\n\n\n\nEn esta tabla se comparan las longitudes de intersección que obtiene cada algoritmo en los conjuntos A, B y C. Lo primero que noto es que BY_B1 es el que siempre genera intersecciones más grandes. En los tres conjuntos tiene los valores más altos tanto en promedio como en mediana. En el conjunto B, por ejemplo, su promedio es de 189.7, con una mediana de 188. También en A y C se mantiene por encima de los demás, con promedios de 111.6 y 112 respectivamente. Esto confirma que su estrategia de búsqueda logra encontrar más coincidencias entre las listas, lo que termina generando intersecciones mucho más largas.\nPor otro lado, el algoritmo BK es el que da los resultados más bajos. En el conjunto C, su promedio es de apenas 0.18 y la mediana es 0, lo que significa que en la mayoría de los casos ni siquiera encuentra elementos comunes. En los conjuntos A y B también se mantiene con valores muy bajos. En cambio, ME, BY_bis y BY_B2 tienen un comportamiento más equilibrado. En A, por ejemplo, sus promedios están muy parejos entre los 19 y 20 elementos, y algo similar pasa en los otros dos conjuntos. En general, esta tabla me deja claro que todos los algoritmos están resolviendo bien el problema, pero hay diferencias importantes en la cantidad de elementos que logran conservar en la intersección. Eso seguramente tiene que ver con cómo manejan los punteros y las condiciones de comparación dentro de cada estrategia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTiempo\nComparaciones\nIntersección\nComentario\n\n\n\n\nBK\nMás rápido y constante\nMenos comparaciones\nMuy baja\nExtremadamente eficiente, pero muy restrictivo\n\n\nBY_bis\nRápido\nBajo\nModerada\nBuen balance entre eficiencia y recuperación\n\n\nBY_B1\nMás lento\nMás comparaciones\nMayor intersección\nCaptura más coincidencias, ideal para recuperar más datos\n\n\nBY_B2\nIntermedio\nMedio\nIntermedia\nBuen compromiso entre B1 y bis\n\n\nME\nMás lento e inestable\nMás comparaciones\nModerada\nPoco eficiente, comportamiento muy variable"
  },
  {
    "objectID": "project5.html#conclusiones",
    "href": "project5.html#conclusiones",
    "title": "Proyecto 5",
    "section": "",
    "text": "Una de las conclusiones más claras que obtuve de este análisis es que el algoritmo Barbay & Kenyon (BK) fue consistentemente el más eficiente en cuanto a tiempo de ejecución y número de comparaciones. En los tres conjuntos evaluados, sus resultados fueron los más bajos y estables, lo que indica que es una opción muy efectiva cuando se requiere rendimiento rápido y predecible. Esto lo convierte en una excelente alternativa para contextos donde la eficiencia computacional es prioritaria.\nEn cuanto a las variantes de Baeza-Yates, pude observar que su comportamiento fue más equilibrado. BY_bis resultó ser bastante eficiente, con buenos tiempos y pocas comparaciones, mientras que BY_B1 se destacó por generar intersecciones mucho más largas. Esto me llevó a concluir que cada variante tiene su enfoque particular: algunas priorizan la rapidez y otras la exhaustividad en la coincidencia de elementos, lo cual puede ser útil dependiendo del tipo de aplicación.\nPor otro lado, el algoritmo Melding (ME) demostró ser el menos eficiente en todos los escenarios. No solo fue el más lento, sino también el que realizó más comparaciones y mostró una gran variabilidad en su comportamiento. En varios casos, sus valores máximos estuvieron muy por encima del resto, lo que deja claro que su desempeño no es confiable y que puede volverse extremadamente costoso en situaciones adversas.\nOtra observación importante es que la longitud de las intersecciones varía mucho entre algoritmos. Por ejemplo, BK tiende a devolver resultados muy pequeños o incluso vacíos, lo que sugiere que su criterio de coincidencia es muy restrictivo. En cambio, BY_B1 logra captar muchas más coincidencias, lo que podría deberse a su estrategia de búsqueda más flexible o tolerante. Esta diferencia me ayudó a entender mejor cómo cada algoritmo interpreta la condición de intersección.\nTodos los algoritmos evaluados lograron resolver correctamente el problema de intersección de listas ordenadas, pero quedó claro que no todos lo hacen de la misma manera ni con el mismo nivel de eficiencia. Cada uno adopta una estrategia distinta que impacta directamente en su rendimiento, ya sea en términos de tiempo de ejecución, número de comparaciones o tamaño de la intersección obtenida.\n\n\n\nLos resultados numéricos de este análisis me llevaron a reflexionar sobre la importancia de no basar la elección de un algoritmo únicamente en una métrica aislada. Es fundamental considerar el contexto y el propósito específico de la aplicación. Por ejemplo, algoritmos como BK se destacan por ser extremadamente rápidos y eficientes en términos computacionales, pero su forma de filtrar elementos tiende a ser muy estricta, lo que genera intersecciones considerablemente más pequeñas. Este comportamiento puede ser ventajoso en entornos donde la prioridad es la velocidad de respuesta, aunque implique sacrificar coincidencias potenciales.\nEn contraste, variantes como BY_B1 realizan un mayor número de comparaciones, pero a cambio logran recuperar conjuntos más amplios de elementos comunes. Esto puede resultar esencial en tareas donde se privilegia la exhaustividad y la precisión por encima del costo computacional. Esta diferencia de enfoques evidencia que no existe un algoritmo universalmente óptimo; cada uno tiene fortalezas y limitaciones que deben ser cuidadosamente evaluadas en función de los objetivos concretos del sistema o aplicación en la que se pretende implementar."
  },
  {
    "objectID": "project5.html#referencias",
    "href": "project5.html#referencias",
    "title": "Proyecto 5",
    "section": "",
    "text": "Baeza-Yates, R. (2004). A fast set intersection algorithm for sorted sequences. En S. C. Sahinalp, S. Muthukrishnan & U. Dogrusoz (Eds.), Combinatorial Pattern Matching (pp. 400–408). Springer. https://doi.org/10.1007/978-3-540-27801-6_30\nBarbay, J., & Kenyon, C. (2002). Adaptive intersection and t-threshold problems. Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms (pp. 390–399). Society for Industrial and Applied Mathematics. https://barbay.cl/Publications/2002-SODA-AdaptiveIntersectionAndTThresholdProblems-BarbayKenyon.pdf\nBarbay, J., López-Ortiz, A., Lu, T., & Salinger, A. (2009). An experimental investigation of set intersection algorithms for text searching. ACM Journal of Experimental Algorithmics, 14, Article 3.7. https://cs.uwaterloo.ca/~alopez-o/files/AEIoSIAfTS_2009.pdf"
  },
  {
    "objectID": "project5.html#cambios-realizados",
    "href": "project5.html#cambios-realizados",
    "title": "Proyecto 5",
    "section": "",
    "text": "Aun no se han realizado cambios. Se envió en fecha actual."
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Proyecto 3",
    "section": "",
    "text": "La investigación sobre el análisis de algoritmos de ordenamiento es un campo activo, con numerosos estudios que exploran nuevas técnicas y optimizaciones. Ordenar datos es crucial en la ciencia de datos y la computación, con aplicaciones que abarcan desde la gestión de bases de datos hasta la optimización de algoritmos en inteligencia artificial. La eficiencia de los algoritmos de ordenamiento es importante, ya que puede influir significativamente en el rendimiento general de un sistema.\nLa eficiencia de un algoritmo de ordenamiento se mide principalmente en términos de tiempo y espacio. El tiempo se refiere a cuántas operaciones realiza el algoritmo, mientras que el espacio indica cuánta memoria adicional necesita. Un algoritmo de ordenamiento es estable si mantiene el orden relativo de los elementos iguales. La estabilidad es crucial en aplicaciones donde el orden original de los elementos iguales debe preservarse. Algunos algoritmos pueden aprovechar el orden existente en los datos para mejorar su rendimiento, mostrando así una adaptabilidad eficiente. La complejidad del algoritmo en el peor caso es una métrica importante para evaluar su robustez (Knuth, 2011).\nLa elección del algoritmo de ordenamiento adecuado depende de varios factores, incluyendo el tamaño de los datos, el grado de desorden y las restricciones de tiempo y espacio. El algoritmo Heapsort utiliza una estructura de datos llamada heap para ordenar los elementos. Es eficiente en términos de uso de memoria y tiene una complejidad de \\(O(n \\log n)\\). Por otro lado, el algoritmo Mergesort es un enfoque de divide y vencerás que divide la lista en mitades, las ordena recursivamente y luego las fusiona. Es estable y tiene una complejidad de \\(O(n \\log n)\\).\nQuicksort también sigue el enfoque de divide y vencerás, seleccionando un elemento como pivote y particionando la lista en elementos menores y mayores. Aunque en promedio es rápido, puede degradarse a \\(O(n^2)\\) en el peor caso. Bubblesort es un algoritmo simple que compara elementos adyacentes y los intercambia si están en el orden incorrecto. Es ineficiente para grandes conjuntos de datos debido a su complejidad cuadrática. Finalmente, la estructura de datos SkipList es una estructura probabilística que permite búsquedas y ordenamientos eficientes. Aunque no es un algoritmo de ordenamiento tradicional, puede ser utilizada para mantener una lista ordenada de elementos (Cormen, 2009).\nPara evaluar y comparar el rendimiento de estos cinco algoritmos de ordenamiento (Heapsort, Mergesort, Quicksort, Bubblesort y SkipList), se seleccionaron primero los algoritmos basándose en sus características y relevancia práctica. Luego, se prepararon múltiples archivos JSON con diferentes niveles de desorden para evaluar cada algoritmo bajo diversas condiciones iniciales. Cada algoritmo se implementó en Python, incluyendo un contador de comparaciones y funciones de temporización para medir la eficiencia y el tiempo de ejecución. Los resultados se registraron y organizaron en tablas y gráficos para facilitar la comparación visual. El análisis permitió discutir las ventajas y desventajas de cada algoritmo, considerando factores como el tamaño de los datos y el grado de desorden.\n\n\n\n\n\n# Bibliotecas utilizadas para manejo de archivos, estructuras, algoritmos y visualización\nimport json\nimport os\nimport heapq\nimport random\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Esta función recorre todos los archivos .json del directorio y carga sus listas de posteo\n# Decidí separarlo en una función para poder reutilizarlo fácilmente en otros experimentos\n\ndef load_json_files(directory):\n    all_files_data = {}\n    for filename in os.listdir(directory):\n        if filename.endswith('.json'):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r') as file:\n                data = json.load(file)\n                listas_posteo = list(data.values())\n                all_files_data[filename] = listas_posteo\n    return all_files_data\n\n# Ruta fija al directorio local donde se ubican las listas de posteo perturbadas\n# Este path es local, pero se puede cambiar fácilmente para otro entorno\n\ndirectory_path = 'C:\\\\Users\\\\Antonio Martínez\\\\Desktop\\\\listas-posteo-con-perturbaciones' \nfiles_data = load_json_files(directory_path)\n\n\n\n\n\n# Uso de heapq para convertir la lista en un heap\n# Cada extracción del mínimo simula la ordenación ascendente\n\ndef heapsort(arr):\n    comparisons = 0\n    heapq.heapify(arr)\n    sorted_arr = []\n    while arr:\n        comparisons += 1\n        sorted_arr.append(heapq.heappop(arr))\n    return sorted_arr, comparisons\n\n\n\n# Mergesort implementado de manera recursiva\n# Es muy útil para listas grandes, ya que divide y conquista\n\ndef mergesort(arr):\n    comparisons = 0\n\n    def merge_sort_recursive(arr):\n        nonlocal comparisons\n        if len(arr) &gt; 1:\n            mid = len(arr) // 2\n            L = arr[:mid]\n            R = arr[mid:]\n\n            merge_sort_recursive(L)\n            merge_sort_recursive(R)\n\n            i = j = k = 0\n            while i &lt; len(L) and j &lt; len(R):\n                comparisons += 1\n                if L[i] &lt; R[j]:\n                    arr[k] = L[i]\n                    i += 1\n                else:\n                    arr[k] = R[j]\n                    j += 1\n                k += 1\n\n            while i &lt; len(L):\n                arr[k] = L[i]\n                i += 1\n                k += 1\n\n            while j &lt; len(R):\n                arr[k] = R[j]\n                j += 1\n                k += 1\n\n    merge_sort_recursive(arr)\n    return arr, comparisons\n\n\n\n# Uso de Quicksort con selección del pivote en la posición media\n# Aumenté el conteo de comparaciones para evaluar su eficiencia\n\ndef quicksort(arr):\n    comparisons = 0\n\n    def _quicksort(arr, low, high):\n        nonlocal comparisons\n        if low &lt; high:\n            pi = partition(arr, low, high)\n            _quicksort(arr, low, pi - 1)\n            _quicksort(arr, pi + 1, high)\n\n    def partition(arr, low, high):\n        nonlocal comparisons\n        mid = (low + high) // 2\n        pivot = arr[mid]\n        arr[mid], arr[high] = arr[high], arr[mid]\n        i = low - 1\n        for j in range(low, high):\n            comparisons += 1\n            if arr[j] &lt;= pivot:\n                i += 1\n                arr[i], arr[j] = arr[j], arr[i]\n        arr[i+1], arr[high] = arr[high], arr[i+1]\n        return i+1\n\n    _quicksort(arr, 0, len(arr)-1)\n    return arr, comparisons\n\n\n\n# Algoritmo simple pero ineficiente para listas grandes\n# Le agregué una condición para detenerse si ya está ordenada\n\ndef bubblesort(arr):\n    n = len(arr)\n    comparisons = 0\n    for i in range(n):\n        swapped = False\n        for j in range(0, n-i-1):\n            comparisons += 1\n            if arr[j] &gt; arr[j+1]:\n                arr[j], arr[j+1] = arr[j+1], arr[j]\n                swapped = True\n        if not swapped:\n            break\n    return arr, comparisons\n\n\n\n# Implementación básica de SkipList adaptada para ordenar\n# Usa niveles probabilísticos para simular ordenamiento eficiente\n\nclass SkipListNode:\n    def __init__(self, value, level):\n        self.value = value\n        self.forward = [None] * (level + 1)\n\nclass SkipList:\n    def __init__(self, max_level, p=0.5):\n        self.max_level = max_level\n        self.p = p\n        self.header = SkipListNode(None, max_level)\n        self.level = 0\n        self.comparisons = 0\n\n    def random_level(self):\n        lvl = 0\n        while random.random() &lt; self.p and lvl &lt; self.max_level:\n            lvl += 1\n        return lvl\n\n    def insert(self, value):\n        update = [None] * (self.max_level + 1)\n        current = self.header\n\n        for i in reversed(range(self.level + 1)):\n            while current.forward[i] and current.forward[i].value &lt; value:\n                self.comparisons += 1\n                current = current.forward[i]\n            update[i] = current\n\n        lvl = self.random_level()\n        if lvl &gt; self.level:\n            for i in range(self.level + 1, lvl + 1):\n                update[i] = self.header\n            self.level = lvl\n\n        new_node = SkipListNode(value, lvl)\n        for i in range(lvl + 1):\n            new_node.forward[i] = update[i].forward[i]\n            update[i].forward[i] = new_node\n\n    def traverse(self):\n        result = []\n        current = self.header.forward[0]\n        while current:\n            result.append(current.value)\n            current = current.forward[0]\n        return result\n\ndef skiplist_sort(arr):\n    max_level = 16\n    sl = SkipList(max_level)\n    for value in arr:\n        sl.insert(value)\n    sorted_arr = sl.traverse()\n    return sorted_arr, sl.comparisons\n\n\n\n\n# Esta función me permitió unificar cómo mido el tiempo y el número de comparaciones\n# para cada algoritmo. La utilicé en todos los experimentos posteriores.\n\ndef measure_sorting_algorithm(algorithm, arr):\n    start_time = time.time()\n    sorted_arr, comparisons = algorithm(arr.copy())\n    end_time = time.time()\n    return sorted_arr, comparisons, end_time - start_time\n\n\n\n# Ejecuto todos los algoritmos en cada lista del dataset\n# Almaceno comparaciones y tiempo para analizarlos más adelante\n\nall_files_results = {}\n\nfor filename, listas_posteo in files_data.items():\n    all_results = []\n    for lista in listas_posteo:\n        results = {}\n        for name, algo in [\n            (\"Heapsort\", heapsort),\n            (\"Mergesort\", mergesort),\n            (\"Quicksort\", quicksort),\n            (\"Bubblesort\", bubblesort),\n            (\"Skiplist\", skiplist_sort)\n        ]:\n            sorted_arr, comparisons, time_taken = measure_sorting_algorithm(algo, lista)\n            results[name] = {'Comparaciones': comparisons, 'Tiempo': time_taken}\n        all_results.append(results)\n    all_files_results[filename] = all_results\n\n\n\n# Para cada archivo muestro un resumen con barras comparativas de tiempo y comparaciones\n# Las comparaciones van en escala logarítmica para mayor visibilidad\n\nfor filename, results in all_files_results.items():\n    print(f\"\\nResultados para el archivo: {filename}\")\n    results_df = pd.DataFrame(results)\n\n    comparisons_df = results_df.applymap(lambda x: x['Comparaciones']).mean()\n    time_df = results_df.applymap(lambda x: x['Tiempo']).mean()\n\n    print(\"\\nPromedio de Comparaciones por Algoritmo:\\n\", comparisons_df)\n    print(\"\\nPromedio de Tiempo por Algoritmo:\\n\", time_df)\n\n    # Comparaciones (escala logarítmica)\n    ax = comparisons_df.plot(kind='bar', title=f'Promedio de Comparaciones por Algoritmo - {filename}',\n                              color='skyblue', log=True)\n    plt.ylabel('Número de Comparaciones (escala logarítmica)')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    for p in ax.patches:\n        ax.annotate(f'{p.get_height():.2f}', \n                    (p.get_x() + p.get_width() / 2., p.get_height()), \n                    ha='center', va='center', \n                    xytext=(0, 10), textcoords='offset points')\n    plt.show()\n\n    # Tiempos de ejecución\n    ax = time_df.plot(kind='bar', title=f'Promedio de Tiempo por Algoritmo - {filename}', color='lightgreen')\n    plt.ylabel('Tiempo (segundos)')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    for p in ax.patches:\n        ax.annotate(f'{p.get_height():.4f}', \n                    (p.get_x() + p.get_width() / 2., p.get_height()), \n                    ha='center', va='center', \n                    xytext=(0, 10), textcoords='offset points')\n\n    ax.set_ylim(0, time_df.max() * 1.25)\n    plt.show()\n\n\n\nTras revisar las observaciones recibidas, se realizaron mejoras clave en la implementación y análisis de los algoritmos. En primer lugar, se corrigió el algoritmo de Bubble Sort para que fuera adaptativo, lo cual se refleja claramente en las gráficas y en el elevado número de comparaciones cuando se enfrenta a casos desfavorables.\nAsimismo, se optimizó Merge Sort para evitar el uso innecesario de memoria adicional, mejorando así su eficiencia práctica. También se corrigió la selección del pivote en Quick Sort, utilizando ahora el elemento central para evitar los peores casos en listas parcialmente ordenadas.\nEn cuanto a SkipList, se eliminó el uso del valor artificial -∞, garantizando que todas las comparaciones se realicen solo entre elementos reales, como exige el modelo de comparación.\nFinalmente, se ajustaron las escalas de las gráficas, empleando una escala logarítmica para las comparaciones y márgenes dinámicos para el tiempo, facilitando una interpretación visual más clara y justa.\nCon estas mejoras, el trabajo queda alineado con los lineamientos discutidos y refleja correctamente el comportamiento de cada algoritmo.\n\n\n\n\nA continuación, se presentan los resultados promedio de comparaciones y tiempos de ejecución para cada archivo de lista de posteo con perturbaciones. Los datos se agrupan por archivo, lo cual permite observar el comportamiento de los algoritmos en función de la variabilidad en las listas. Se visualizan a continuación Tablas y Gr áficos.\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000966\n\n\nMergesort\n15031.85\n0.004780\n\n\nQuicksort\n21248.43\n0.002659\n\n\nBubblesort\n12394236.90\n1.484842\n\n\nSkiplist\n20545.83\n0.013274\n\n\n\n\n\n\n\n\n\nEn la tabla de promedios y los gráficos generados para el archivo listas-posteo-con-perturbaciones-p=016.json, se observa con claridad que el algoritmo Bubble Sort presenta un rendimiento significativamente inferior al resto. Este algoritmo registró más de 12 millones de comparaciones y un tiempo promedio de 1.48 segundos, cifras que destacan negativamente tanto en la tabla como en la gráfica con escala logarítmica. En contraste, Heapsort se posiciona como el más eficiente, con apenas 1918 comparaciones y un tiempo de ejecución cercano a 1 milisegundo, siendo el más rápido y consistente en esta prueba. Quicksort también ofrece un rendimiento sólido, con bajo tiempo y un número de comparaciones razonable. Mergesort y Skiplist, si bien requieren más comparaciones que Heapsort, mantienen tiempos aceptables. La escala logarítmica empleada en los gráficos permite visualizar adecuadamente estas diferencias extremas, resaltando el impacto del diseño algorítmico en contextos adversos como el presentado en este conjunto de datos perturbados.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000695\n\n\nMergesort\n16019.63\n0.005563\n\n\nQuicksort\n22342.45\n0.003617\n\n\nBubblesort\n12303709.00\n1.578796\n\n\nSkiplist\n21164.88\n0.010628\n\n\n\n\n\n\n\n\n\nEn el archivo listas-posteo-con-perturbaciones-p=032.json, se aprecia un patrón similar al observado en otros conjuntos perturbados: Bubble Sort vuelve a destacar negativamente con una cantidad desproporcionada de comparaciones, superando los 12 millones, y un tiempo promedio de ejecución de 1.57 segundos. Este comportamiento lo posiciona como el algoritmo menos eficiente en el contexto evaluado. Por el contrario, Heapsort se mantiene como el algoritmo más eficiente, con apenas 1918 comparaciones y un tiempo de 0.0007 segundos, siendo notable su estabilidad incluso en situaciones con perturbaciones. Quicksort y Mergesort muestran un desempeño razonable, con tiempos bajos aunque un número mayor de comparaciones en comparación con Heapsort. Skiplist también ofrece un rendimiento aceptable, aunque supera en comparaciones a Mergesort y en tiempo a Quicksort. Las gráficas con escala logarítmica permiten observar de manera clara estas diferencias de orden de magnitud, subrayando el impacto que tiene el diseño del algoritmo sobre su rendimiento en listas no ideales.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000458\n\n\nMergesort\n16929.96\n0.005799\n\n\nQuicksort\n23524.43\n0.003824\n\n\nBubblesort\n12907386.23\n1.626831\n\n\nSkiplist\n21204.59\n0.012316\n\n\n\n\n\n\n\n\n\nEn el archivo listas-posteo-con-perturbaciones-p=064.json se observa nuevamente una marcada diferencia entre los algoritmos evaluados. Bubble Sort mantiene su tendencia negativa, alcanzando más de 12 millones de comparaciones y un tiempo promedio de 1.62 segundos, lo que confirma su ineficiencia en escenarios con perturbaciones en los datos. Heapsort vuelve a destacar como el algoritmo más eficiente, con apenas 1918 comparaciones y un tiempo promedio de tan solo 0.0005 segundos. Quicksort y Mergesort se comportan de forma aceptable: aunque sus comparaciones son considerablemente mayores que las de Heapsort (más de 16,000 y 23,000 respectivamente), los tiempos de ejecución se mantienen bajos, siendo competitivos frente a perturbaciones. Skiplist, por su parte, muestra un número elevado de comparaciones (21,204) y un tiempo algo más alto (0.012 segundos), pero dentro de rangos razonables. Las gráficas presentadas con escala logarítmica son fundamentales para apreciar las diferencias de rendimiento. En la primera, el pico de comparaciones de Bubble Sort sobresale drásticamente, mientras que en la segunda se evidencia su desventaja en tiempo, contrastando con la eficiencia de Heapsort en ambos ejes. Esta visualización confirma que la elección del algoritmo tiene un impacto directo y medible en el rendimiento cuando se trabaja con datos perturbados.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000497\n\n\nMergesort\n17856.69\n0.006180\n\n\nQuicksort\n24763.26\n0.003765\n\n\nBubblesort\n13020287.94\n1.661634\n\n\nSkiplist\n21260.55\n0.010196\n\n\n\n\n\n\n\n\n\nEl archivo listas-posteo-con-perturbaciones-p=128.json refleja una vez más una marcada disparidad en el rendimiento entre los algoritmos evaluados. Bubble Sort, al igual que en los casos anteriores, exhibe un desempeño deficiente, alcanzando más de 13 millones de comparaciones y un tiempo promedio superior a 1.66 segundos. Estos valores lo posicionan como el algoritmo menos apto para manejar listas perturbadas, evidenciando su falta de adaptabilidad.\nEn contraste, Heapsort se mantiene como la opción más eficiente, destacando por su bajo número de comparaciones (1918) y un tiempo de ejecución prácticamente inmediato (0.0005 segundos). Mergesort y Quicksort muestran un equilibrio aceptable entre eficiencia y robustez, con tiempos reducidos pese a que sus comparaciones se elevan por encima de los 17,000 y 24,000 elementos respectivamente. Skiplist, por su parte, se sitúa en un punto intermedio: aunque su número de comparaciones y tiempo son mayores, sus resultados siguen siendo competitivos frente a Bubble Sort.\nLa interpretación visual mediante gráficos en escala logarítmica permite apreciar con claridad estas diferencias. Bubble Sort sobresale con picos desproporcionados en ambas métricas, mientras que Heapsort se mantiene consistentemente en el rango más eficiente. Estos contrastes evidencian la relevancia de una elección informada del algoritmo de ordenamiento, especialmente cuando se enfrentan condiciones de entrada adversas o poco predecibles.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.001025\n\n\nMergesort\n18650.70\n0.005661\n\n\nQuicksort\n25839.39\n0.004006\n\n\nBubblesort\n13067025.01\n1.679046\n\n\nSkiplist\n19991.10\n0.011174\n\n\n\n\n\n\n\n\n\nEl análisis del archivo listas-posteo-con-perturbaciones-p=256.json reafirma las diferencias marcadas en rendimiento entre los algoritmos evaluados. Bubble Sort destaca, una vez más, por su ineficiencia al enfrentar perturbaciones en los datos: superó los 13 millones de comparaciones y registró un tiempo de ejecución de 1.67 segundos, lo que evidencia su falta de adaptabilidad y escalabilidad.\nEn contraste, Heapsort continúa consolidándose como la alternativa más estable y eficaz, logrando completar la tarea con un número mínimo de comparaciones (1918) y un tiempo inferior al milisegundo. Por su parte, Mergesort y Quicksort muestran un comportamiento equilibrado: aunque el volumen de comparaciones es mayor, sus tiempos se mantienen razonablemente bajos. Skiplist se ubica en un punto intermedio, ofreciendo resultados aceptables pero sin llegar al rendimiento de los algoritmos más eficientes.\nLas gráficas con escala logarítmica permiten dimensionar adecuadamente estas diferencias. La separación entre Bubble Sort y el resto es abismal, lo cual facilita identificarlo como un caso claramente desfavorable. Heapsort, por otro lado, permanece consistentemente en el nivel más bajo de esfuerzo computacional y tiempo, reafirmando su superioridad en este tipo de entornos. Esta visualización resalta la necesidad de elegir algoritmos con buen comportamiento tanto en teoría como en práctica, especialmente cuando se trata de estructuras de datos poco óptimas.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.001287\n\n\nMergesort\n19343.00\n0.005294\n\n\nQuicksort\n27047.10\n0.005086\n\n\nBubblesort\n13088171.64\n1.710422\n\n\nSkiplist\n20849.75\n0.010666\n\n\n\n\n\n\n\n\n\nEn el archivo listas-posteo-con-perturbaciones-p=512.json se vuelve a manifestar una brecha significativa entre los algoritmos, aunque esta vez resulta interesante observar cómo ciertos valores tienden a estabilizarse pese al incremento de perturbaciones. Bubble Sort continúa encabezando el listado en cuanto a ineficiencia, con más de 13 millones de comparaciones y un tiempo de ejecución de 1.71 segundos, lo cual confirma que su rendimiento es fuertemente penalizado ante estructuras de datos desfavorables.\nUn aspecto que llama la atención es la constancia de Heapsort. Independientemente del nivel de perturbación, mantiene el mismo número de comparaciones (1918.52), lo cual refleja una gran estabilidad en su comportamiento. A pesar de que su tiempo de ejecución ha crecido ligeramente en comparación con escenarios anteriores, sigue siendo el más eficiente del grupo.\nMergesort y Quicksort aumentan gradualmente sus comparaciones a medida que las perturbaciones se intensifican, superando las 19 mil y 27 mil respectivamente. Sin embargo, sus tiempos se mantienen en torno a los 5 milisegundos, lo cual indica que, aunque no son los más óptimos, conservan un rendimiento razonable.\nSkiplist muestra una ligera mejora en número de comparaciones respecto al caso con p=256, pero sigue siendo más lento en tiempo. Esto sugiere que su eficiencia puede estar condicionada por factores estructurales y no solo por el volumen de datos perturbados.\nLas gráficas en escala logarítmica siguen siendo fundamentales para dimensionar estas diferencias. Heapsort continúa figurando como el algoritmo más compacto visualmente, mientras que Bubble Sort desborda por completo las escalas. Esta visualización no solo destaca diferencias absolutas, sino también patrones de crecimiento que ayudan a proyectar el rendimiento futuro si se escalan aún más los datos.\n\n\n\nLas variaciones observadas se deben a varios factores que se lograron visualizar en los gráficos y en la lista de posteo. Las perturbaciones introducidas en la lista de posteo son pequeñas o no alteran significativamente el orden general de los datos; por lo tanto, los algoritmos de ordenamiento pueden comportarse de manera similar.\nEl tamaño de la lista de posteo puede influir en cómo los algoritmos manejan las perturbaciones. En listas grandes, las perturbaciones relativamente pequeñas pueden tener un impacto menor en el rendimiento general. Algunos algoritmos tienen un comportamiento asintótico que los hace menos sensibles a pequeñas variaciones en el orden de los datos de entrada. Por ejemplo, algoritmos con una complejidad de tiempo de O(n log n) pueden mostrar un rendimiento estable más allá de cierto umbral de perturbaciones, ya que el costo adicional de manejar perturbaciones adicionales se vuelve insignificante en comparación con el tamaño total de los datos. (Huyen, 2022)\nLa forma en que se implementan los algoritmos puede afectar su rendimiento. Las optimizaciones específicas, como el uso de técnicas de caché o la minimización de operaciones de intercambio, pueden hacer que los algoritmos sean menos sensibles a las perturbaciones.\nLas métricas utilizadas para evaluar el rendimiento, como el número de comparaciones y el tiempo de ejecución, pueden no capturar completamente el impacto de las perturbaciones. Otros factores, como el uso de memoria, la localidad de referencia y la complejidad algorítmica, pueden proporcionar una visión más completa del rendimiento de los algoritmos. (Cormen, 2009)\n\n\n\n\nAl finalizar este análisis, puedo concluir que Heapsort fue, sin duda, el algoritmo más eficiente y consistente a lo largo de todos los escenarios evaluados. Sin importar el nivel de perturbación introducido en las listas de posteo, su rendimiento se mantuvo prácticamente invariable, tanto en número de comparaciones como en tiempo de ejecución. Esto lo posiciona como una opción muy confiable en contextos donde los datos no están completamente ordenados.\nPor el contrario, Bubble Sort demostró ser el menos adecuado para este tipo de condiciones, registrando cifras excesivas de comparaciones y tiempos considerablemente altos en todos los casos. Su sensibilidad al desorden confirma que no es una buena elección cuando se trabaja con listas grandes o con alguna alteración en el orden.\nMergesort y Quicksort ofrecieron un equilibrio bastante sólido, especialmente en cuanto a tiempos de ejecución. Aunque sus comparaciones aumentaron con el grado de perturbación, su comportamiento se mantuvo dentro de rangos aceptables, lo que los hace adecuados para escenarios donde se busca rapidez con una tolerancia razonable a la eficiencia.\nEn cuanto a Skiplist, observé un rendimiento intermedio. No fue el más rápido, pero tampoco presentó problemas extremos. Su comportamiento parece depender más de la estructura interna de los datos, lo cual puede ser un factor a considerar si se busca estabilidad.\nFinalmente, algo que considero clave es que la elección del algoritmo no debe basarse únicamente en su complejidad teórica. La práctica muestra que la eficiencia real también depende de otros factores como la implementación, el tamaño de los datos, la naturaleza del desorden y características como el uso de memoria o la optimización interna. Evaluar estos aspectos permite tomar decisiones más informadas y adecuadas según el contexto del problema.\n\n\n\n\nCormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms (3rd ed.). MIT Press.\nKnuth, D. E. (2011). The Art of Computer Programming, Volume 4A: Combinatorial Algorithms, Part 1. Addison-Wesley.\nRizvi, Q., Rai, H., & Jaiswal, R. (2024). Sorting Algorithms in Focus: A Critical Examination of Sorting Algorithm Performance.\nHuyen, C. (2022). Designing Machine Learning Systems. O’Reilly Media, Inc.\n\n\n\n\nCon base en las observaciones realizadas durante la videoconferencia y en las notas complementarias, realicé una serie de ajustes importantes en el desarrollo de mi trabajo.\nPrimero, corregí la afirmación sobre el algoritmo Bubble Sort, aclarando que no es un algoritmo adaptativo. Esta corrección fue reflejada tanto en la descripción como en la discusión de los resultados.\nTambién ajusté las escalas de las gráficas generadas para cada algoritmo, con el objetivo de permitir una mejor visualización y comparación de sus comportamientos, especialmente en casos con tamaños de entrada moderados.\nEn cuanto a Merge Sort, revisé la implementación para evitar el uso innecesario de memoria adicional, ya que esto afectaba negativamente su eficiencia.\nPara Quick Sort, corregí la estrategia de selección del pivote, siguiendo las recomendaciones revisadas en clase, y documenté cómo esta decisión influye directamente en el rendimiento del algoritmo.\nPor último, eliminé el uso del número “ínfimo” en la implementación de Skip List, ya que comprendí que no era necesario dentro del modelo de comparación. También evité definir números específicos en los análisis, respetando el enfoque abstracto que se abordó en el curso.\nEstos cambios me ayudaron a alinear mejor mi trabajo con los principios teóricos del análisis algorítmico y a fortalecer mi comprensión de los conceptos trabajados."
  },
  {
    "objectID": "project3.html#introducción",
    "href": "project3.html#introducción",
    "title": "Proyecto 3",
    "section": "",
    "text": "La investigación sobre el análisis de algoritmos de ordenamiento es un campo activo, con numerosos estudios que exploran nuevas técnicas y optimizaciones. Ordenar datos es crucial en la ciencia de datos y la computación, con aplicaciones que abarcan desde la gestión de bases de datos hasta la optimización de algoritmos en inteligencia artificial. La eficiencia de los algoritmos de ordenamiento es importante, ya que puede influir significativamente en el rendimiento general de un sistema.\nLa eficiencia de un algoritmo de ordenamiento se mide principalmente en términos de tiempo y espacio. El tiempo se refiere a cuántas operaciones realiza el algoritmo, mientras que el espacio indica cuánta memoria adicional necesita. Un algoritmo de ordenamiento es estable si mantiene el orden relativo de los elementos iguales. La estabilidad es crucial en aplicaciones donde el orden original de los elementos iguales debe preservarse. Algunos algoritmos pueden aprovechar el orden existente en los datos para mejorar su rendimiento, mostrando así una adaptabilidad eficiente. La complejidad del algoritmo en el peor caso es una métrica importante para evaluar su robustez (Knuth, 2011).\nLa elección del algoritmo de ordenamiento adecuado depende de varios factores, incluyendo el tamaño de los datos, el grado de desorden y las restricciones de tiempo y espacio. El algoritmo Heapsort utiliza una estructura de datos llamada heap para ordenar los elementos. Es eficiente en términos de uso de memoria y tiene una complejidad de \\(O(n \\log n)\\). Por otro lado, el algoritmo Mergesort es un enfoque de divide y vencerás que divide la lista en mitades, las ordena recursivamente y luego las fusiona. Es estable y tiene una complejidad de \\(O(n \\log n)\\).\nQuicksort también sigue el enfoque de divide y vencerás, seleccionando un elemento como pivote y particionando la lista en elementos menores y mayores. Aunque en promedio es rápido, puede degradarse a \\(O(n^2)\\) en el peor caso. Bubblesort es un algoritmo simple que compara elementos adyacentes y los intercambia si están en el orden incorrecto. Es ineficiente para grandes conjuntos de datos debido a su complejidad cuadrática. Finalmente, la estructura de datos SkipList es una estructura probabilística que permite búsquedas y ordenamientos eficientes. Aunque no es un algoritmo de ordenamiento tradicional, puede ser utilizada para mantener una lista ordenada de elementos (Cormen, 2009).\nPara evaluar y comparar el rendimiento de estos cinco algoritmos de ordenamiento (Heapsort, Mergesort, Quicksort, Bubblesort y SkipList), se seleccionaron primero los algoritmos basándose en sus características y relevancia práctica. Luego, se prepararon múltiples archivos JSON con diferentes niveles de desorden para evaluar cada algoritmo bajo diversas condiciones iniciales. Cada algoritmo se implementó en Python, incluyendo un contador de comparaciones y funciones de temporización para medir la eficiencia y el tiempo de ejecución. Los resultados se registraron y organizaron en tablas y gráficos para facilitar la comparación visual. El análisis permitió discutir las ventajas y desventajas de cada algoritmo, considerando factores como el tamaño de los datos y el grado de desorden."
  },
  {
    "objectID": "project3.html#desarrollo",
    "href": "project3.html#desarrollo",
    "title": "Proyecto 3",
    "section": "",
    "text": "# Bibliotecas utilizadas para manejo de archivos, estructuras, algoritmos y visualización\nimport json\nimport os\nimport heapq\nimport random\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Esta función recorre todos los archivos .json del directorio y carga sus listas de posteo\n# Decidí separarlo en una función para poder reutilizarlo fácilmente en otros experimentos\n\ndef load_json_files(directory):\n    all_files_data = {}\n    for filename in os.listdir(directory):\n        if filename.endswith('.json'):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r') as file:\n                data = json.load(file)\n                listas_posteo = list(data.values())\n                all_files_data[filename] = listas_posteo\n    return all_files_data\n\n# Ruta fija al directorio local donde se ubican las listas de posteo perturbadas\n# Este path es local, pero se puede cambiar fácilmente para otro entorno\n\ndirectory_path = 'C:\\\\Users\\\\Antonio Martínez\\\\Desktop\\\\listas-posteo-con-perturbaciones' \nfiles_data = load_json_files(directory_path)\n\n\n\n\n\n# Uso de heapq para convertir la lista en un heap\n# Cada extracción del mínimo simula la ordenación ascendente\n\ndef heapsort(arr):\n    comparisons = 0\n    heapq.heapify(arr)\n    sorted_arr = []\n    while arr:\n        comparisons += 1\n        sorted_arr.append(heapq.heappop(arr))\n    return sorted_arr, comparisons\n\n\n\n# Mergesort implementado de manera recursiva\n# Es muy útil para listas grandes, ya que divide y conquista\n\ndef mergesort(arr):\n    comparisons = 0\n\n    def merge_sort_recursive(arr):\n        nonlocal comparisons\n        if len(arr) &gt; 1:\n            mid = len(arr) // 2\n            L = arr[:mid]\n            R = arr[mid:]\n\n            merge_sort_recursive(L)\n            merge_sort_recursive(R)\n\n            i = j = k = 0\n            while i &lt; len(L) and j &lt; len(R):\n                comparisons += 1\n                if L[i] &lt; R[j]:\n                    arr[k] = L[i]\n                    i += 1\n                else:\n                    arr[k] = R[j]\n                    j += 1\n                k += 1\n\n            while i &lt; len(L):\n                arr[k] = L[i]\n                i += 1\n                k += 1\n\n            while j &lt; len(R):\n                arr[k] = R[j]\n                j += 1\n                k += 1\n\n    merge_sort_recursive(arr)\n    return arr, comparisons\n\n\n\n# Uso de Quicksort con selección del pivote en la posición media\n# Aumenté el conteo de comparaciones para evaluar su eficiencia\n\ndef quicksort(arr):\n    comparisons = 0\n\n    def _quicksort(arr, low, high):\n        nonlocal comparisons\n        if low &lt; high:\n            pi = partition(arr, low, high)\n            _quicksort(arr, low, pi - 1)\n            _quicksort(arr, pi + 1, high)\n\n    def partition(arr, low, high):\n        nonlocal comparisons\n        mid = (low + high) // 2\n        pivot = arr[mid]\n        arr[mid], arr[high] = arr[high], arr[mid]\n        i = low - 1\n        for j in range(low, high):\n            comparisons += 1\n            if arr[j] &lt;= pivot:\n                i += 1\n                arr[i], arr[j] = arr[j], arr[i]\n        arr[i+1], arr[high] = arr[high], arr[i+1]\n        return i+1\n\n    _quicksort(arr, 0, len(arr)-1)\n    return arr, comparisons\n\n\n\n# Algoritmo simple pero ineficiente para listas grandes\n# Le agregué una condición para detenerse si ya está ordenada\n\ndef bubblesort(arr):\n    n = len(arr)\n    comparisons = 0\n    for i in range(n):\n        swapped = False\n        for j in range(0, n-i-1):\n            comparisons += 1\n            if arr[j] &gt; arr[j+1]:\n                arr[j], arr[j+1] = arr[j+1], arr[j]\n                swapped = True\n        if not swapped:\n            break\n    return arr, comparisons\n\n\n\n# Implementación básica de SkipList adaptada para ordenar\n# Usa niveles probabilísticos para simular ordenamiento eficiente\n\nclass SkipListNode:\n    def __init__(self, value, level):\n        self.value = value\n        self.forward = [None] * (level + 1)\n\nclass SkipList:\n    def __init__(self, max_level, p=0.5):\n        self.max_level = max_level\n        self.p = p\n        self.header = SkipListNode(None, max_level)\n        self.level = 0\n        self.comparisons = 0\n\n    def random_level(self):\n        lvl = 0\n        while random.random() &lt; self.p and lvl &lt; self.max_level:\n            lvl += 1\n        return lvl\n\n    def insert(self, value):\n        update = [None] * (self.max_level + 1)\n        current = self.header\n\n        for i in reversed(range(self.level + 1)):\n            while current.forward[i] and current.forward[i].value &lt; value:\n                self.comparisons += 1\n                current = current.forward[i]\n            update[i] = current\n\n        lvl = self.random_level()\n        if lvl &gt; self.level:\n            for i in range(self.level + 1, lvl + 1):\n                update[i] = self.header\n            self.level = lvl\n\n        new_node = SkipListNode(value, lvl)\n        for i in range(lvl + 1):\n            new_node.forward[i] = update[i].forward[i]\n            update[i].forward[i] = new_node\n\n    def traverse(self):\n        result = []\n        current = self.header.forward[0]\n        while current:\n            result.append(current.value)\n            current = current.forward[0]\n        return result\n\ndef skiplist_sort(arr):\n    max_level = 16\n    sl = SkipList(max_level)\n    for value in arr:\n        sl.insert(value)\n    sorted_arr = sl.traverse()\n    return sorted_arr, sl.comparisons\n\n\n\n\n# Esta función me permitió unificar cómo mido el tiempo y el número de comparaciones\n# para cada algoritmo. La utilicé en todos los experimentos posteriores.\n\ndef measure_sorting_algorithm(algorithm, arr):\n    start_time = time.time()\n    sorted_arr, comparisons = algorithm(arr.copy())\n    end_time = time.time()\n    return sorted_arr, comparisons, end_time - start_time\n\n\n\n# Ejecuto todos los algoritmos en cada lista del dataset\n# Almaceno comparaciones y tiempo para analizarlos más adelante\n\nall_files_results = {}\n\nfor filename, listas_posteo in files_data.items():\n    all_results = []\n    for lista in listas_posteo:\n        results = {}\n        for name, algo in [\n            (\"Heapsort\", heapsort),\n            (\"Mergesort\", mergesort),\n            (\"Quicksort\", quicksort),\n            (\"Bubblesort\", bubblesort),\n            (\"Skiplist\", skiplist_sort)\n        ]:\n            sorted_arr, comparisons, time_taken = measure_sorting_algorithm(algo, lista)\n            results[name] = {'Comparaciones': comparisons, 'Tiempo': time_taken}\n        all_results.append(results)\n    all_files_results[filename] = all_results\n\n\n\n# Para cada archivo muestro un resumen con barras comparativas de tiempo y comparaciones\n# Las comparaciones van en escala logarítmica para mayor visibilidad\n\nfor filename, results in all_files_results.items():\n    print(f\"\\nResultados para el archivo: {filename}\")\n    results_df = pd.DataFrame(results)\n\n    comparisons_df = results_df.applymap(lambda x: x['Comparaciones']).mean()\n    time_df = results_df.applymap(lambda x: x['Tiempo']).mean()\n\n    print(\"\\nPromedio de Comparaciones por Algoritmo:\\n\", comparisons_df)\n    print(\"\\nPromedio de Tiempo por Algoritmo:\\n\", time_df)\n\n    # Comparaciones (escala logarítmica)\n    ax = comparisons_df.plot(kind='bar', title=f'Promedio de Comparaciones por Algoritmo - {filename}',\n                              color='skyblue', log=True)\n    plt.ylabel('Número de Comparaciones (escala logarítmica)')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    for p in ax.patches:\n        ax.annotate(f'{p.get_height():.2f}', \n                    (p.get_x() + p.get_width() / 2., p.get_height()), \n                    ha='center', va='center', \n                    xytext=(0, 10), textcoords='offset points')\n    plt.show()\n\n    # Tiempos de ejecución\n    ax = time_df.plot(kind='bar', title=f'Promedio de Tiempo por Algoritmo - {filename}', color='lightgreen')\n    plt.ylabel('Tiempo (segundos)')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    for p in ax.patches:\n        ax.annotate(f'{p.get_height():.4f}', \n                    (p.get_x() + p.get_width() / 2., p.get_height()), \n                    ha='center', va='center', \n                    xytext=(0, 10), textcoords='offset points')\n\n    ax.set_ylim(0, time_df.max() * 1.25)\n    plt.show()\n\n\n\nTras revisar las observaciones recibidas, se realizaron mejoras clave en la implementación y análisis de los algoritmos. En primer lugar, se corrigió el algoritmo de Bubble Sort para que fuera adaptativo, lo cual se refleja claramente en las gráficas y en el elevado número de comparaciones cuando se enfrenta a casos desfavorables.\nAsimismo, se optimizó Merge Sort para evitar el uso innecesario de memoria adicional, mejorando así su eficiencia práctica. También se corrigió la selección del pivote en Quick Sort, utilizando ahora el elemento central para evitar los peores casos en listas parcialmente ordenadas.\nEn cuanto a SkipList, se eliminó el uso del valor artificial -∞, garantizando que todas las comparaciones se realicen solo entre elementos reales, como exige el modelo de comparación.\nFinalmente, se ajustaron las escalas de las gráficas, empleando una escala logarítmica para las comparaciones y márgenes dinámicos para el tiempo, facilitando una interpretación visual más clara y justa.\nCon estas mejoras, el trabajo queda alineado con los lineamientos discutidos y refleja correctamente el comportamiento de cada algoritmo."
  },
  {
    "objectID": "project3.html#resultados-experimentales-y-análisis-de-resultados",
    "href": "project3.html#resultados-experimentales-y-análisis-de-resultados",
    "title": "Proyecto 3",
    "section": "",
    "text": "A continuación, se presentan los resultados promedio de comparaciones y tiempos de ejecución para cada archivo de lista de posteo con perturbaciones. Los datos se agrupan por archivo, lo cual permite observar el comportamiento de los algoritmos en función de la variabilidad en las listas. Se visualizan a continuación Tablas y Gr áficos.\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000966\n\n\nMergesort\n15031.85\n0.004780\n\n\nQuicksort\n21248.43\n0.002659\n\n\nBubblesort\n12394236.90\n1.484842\n\n\nSkiplist\n20545.83\n0.013274\n\n\n\n\n\n\n\n\n\nEn la tabla de promedios y los gráficos generados para el archivo listas-posteo-con-perturbaciones-p=016.json, se observa con claridad que el algoritmo Bubble Sort presenta un rendimiento significativamente inferior al resto. Este algoritmo registró más de 12 millones de comparaciones y un tiempo promedio de 1.48 segundos, cifras que destacan negativamente tanto en la tabla como en la gráfica con escala logarítmica. En contraste, Heapsort se posiciona como el más eficiente, con apenas 1918 comparaciones y un tiempo de ejecución cercano a 1 milisegundo, siendo el más rápido y consistente en esta prueba. Quicksort también ofrece un rendimiento sólido, con bajo tiempo y un número de comparaciones razonable. Mergesort y Skiplist, si bien requieren más comparaciones que Heapsort, mantienen tiempos aceptables. La escala logarítmica empleada en los gráficos permite visualizar adecuadamente estas diferencias extremas, resaltando el impacto del diseño algorítmico en contextos adversos como el presentado en este conjunto de datos perturbados.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000695\n\n\nMergesort\n16019.63\n0.005563\n\n\nQuicksort\n22342.45\n0.003617\n\n\nBubblesort\n12303709.00\n1.578796\n\n\nSkiplist\n21164.88\n0.010628\n\n\n\n\n\n\n\n\n\nEn el archivo listas-posteo-con-perturbaciones-p=032.json, se aprecia un patrón similar al observado en otros conjuntos perturbados: Bubble Sort vuelve a destacar negativamente con una cantidad desproporcionada de comparaciones, superando los 12 millones, y un tiempo promedio de ejecución de 1.57 segundos. Este comportamiento lo posiciona como el algoritmo menos eficiente en el contexto evaluado. Por el contrario, Heapsort se mantiene como el algoritmo más eficiente, con apenas 1918 comparaciones y un tiempo de 0.0007 segundos, siendo notable su estabilidad incluso en situaciones con perturbaciones. Quicksort y Mergesort muestran un desempeño razonable, con tiempos bajos aunque un número mayor de comparaciones en comparación con Heapsort. Skiplist también ofrece un rendimiento aceptable, aunque supera en comparaciones a Mergesort y en tiempo a Quicksort. Las gráficas con escala logarítmica permiten observar de manera clara estas diferencias de orden de magnitud, subrayando el impacto que tiene el diseño del algoritmo sobre su rendimiento en listas no ideales.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000458\n\n\nMergesort\n16929.96\n0.005799\n\n\nQuicksort\n23524.43\n0.003824\n\n\nBubblesort\n12907386.23\n1.626831\n\n\nSkiplist\n21204.59\n0.012316\n\n\n\n\n\n\n\n\n\nEn el archivo listas-posteo-con-perturbaciones-p=064.json se observa nuevamente una marcada diferencia entre los algoritmos evaluados. Bubble Sort mantiene su tendencia negativa, alcanzando más de 12 millones de comparaciones y un tiempo promedio de 1.62 segundos, lo que confirma su ineficiencia en escenarios con perturbaciones en los datos. Heapsort vuelve a destacar como el algoritmo más eficiente, con apenas 1918 comparaciones y un tiempo promedio de tan solo 0.0005 segundos. Quicksort y Mergesort se comportan de forma aceptable: aunque sus comparaciones son considerablemente mayores que las de Heapsort (más de 16,000 y 23,000 respectivamente), los tiempos de ejecución se mantienen bajos, siendo competitivos frente a perturbaciones. Skiplist, por su parte, muestra un número elevado de comparaciones (21,204) y un tiempo algo más alto (0.012 segundos), pero dentro de rangos razonables. Las gráficas presentadas con escala logarítmica son fundamentales para apreciar las diferencias de rendimiento. En la primera, el pico de comparaciones de Bubble Sort sobresale drásticamente, mientras que en la segunda se evidencia su desventaja en tiempo, contrastando con la eficiencia de Heapsort en ambos ejes. Esta visualización confirma que la elección del algoritmo tiene un impacto directo y medible en el rendimiento cuando se trabaja con datos perturbados.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.000497\n\n\nMergesort\n17856.69\n0.006180\n\n\nQuicksort\n24763.26\n0.003765\n\n\nBubblesort\n13020287.94\n1.661634\n\n\nSkiplist\n21260.55\n0.010196\n\n\n\n\n\n\n\n\n\nEl archivo listas-posteo-con-perturbaciones-p=128.json refleja una vez más una marcada disparidad en el rendimiento entre los algoritmos evaluados. Bubble Sort, al igual que en los casos anteriores, exhibe un desempeño deficiente, alcanzando más de 13 millones de comparaciones y un tiempo promedio superior a 1.66 segundos. Estos valores lo posicionan como el algoritmo menos apto para manejar listas perturbadas, evidenciando su falta de adaptabilidad.\nEn contraste, Heapsort se mantiene como la opción más eficiente, destacando por su bajo número de comparaciones (1918) y un tiempo de ejecución prácticamente inmediato (0.0005 segundos). Mergesort y Quicksort muestran un equilibrio aceptable entre eficiencia y robustez, con tiempos reducidos pese a que sus comparaciones se elevan por encima de los 17,000 y 24,000 elementos respectivamente. Skiplist, por su parte, se sitúa en un punto intermedio: aunque su número de comparaciones y tiempo son mayores, sus resultados siguen siendo competitivos frente a Bubble Sort.\nLa interpretación visual mediante gráficos en escala logarítmica permite apreciar con claridad estas diferencias. Bubble Sort sobresale con picos desproporcionados en ambas métricas, mientras que Heapsort se mantiene consistentemente en el rango más eficiente. Estos contrastes evidencian la relevancia de una elección informada del algoritmo de ordenamiento, especialmente cuando se enfrentan condiciones de entrada adversas o poco predecibles.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.001025\n\n\nMergesort\n18650.70\n0.005661\n\n\nQuicksort\n25839.39\n0.004006\n\n\nBubblesort\n13067025.01\n1.679046\n\n\nSkiplist\n19991.10\n0.011174\n\n\n\n\n\n\n\n\n\nEl análisis del archivo listas-posteo-con-perturbaciones-p=256.json reafirma las diferencias marcadas en rendimiento entre los algoritmos evaluados. Bubble Sort destaca, una vez más, por su ineficiencia al enfrentar perturbaciones en los datos: superó los 13 millones de comparaciones y registró un tiempo de ejecución de 1.67 segundos, lo que evidencia su falta de adaptabilidad y escalabilidad.\nEn contraste, Heapsort continúa consolidándose como la alternativa más estable y eficaz, logrando completar la tarea con un número mínimo de comparaciones (1918) y un tiempo inferior al milisegundo. Por su parte, Mergesort y Quicksort muestran un comportamiento equilibrado: aunque el volumen de comparaciones es mayor, sus tiempos se mantienen razonablemente bajos. Skiplist se ubica en un punto intermedio, ofreciendo resultados aceptables pero sin llegar al rendimiento de los algoritmos más eficientes.\nLas gráficas con escala logarítmica permiten dimensionar adecuadamente estas diferencias. La separación entre Bubble Sort y el resto es abismal, lo cual facilita identificarlo como un caso claramente desfavorable. Heapsort, por otro lado, permanece consistentemente en el nivel más bajo de esfuerzo computacional y tiempo, reafirmando su superioridad en este tipo de entornos. Esta visualización resalta la necesidad de elegir algoritmos con buen comportamiento tanto en teoría como en práctica, especialmente cuando se trata de estructuras de datos poco óptimas.\n\n\n\n\n\n\nAlgoritmo\nComparaciones\nTiempo (s)\n\n\n\n\nHeapsort\n1918.52\n0.001287\n\n\nMergesort\n19343.00\n0.005294\n\n\nQuicksort\n27047.10\n0.005086\n\n\nBubblesort\n13088171.64\n1.710422\n\n\nSkiplist\n20849.75\n0.010666\n\n\n\n\n\n\n\n\n\nEn el archivo listas-posteo-con-perturbaciones-p=512.json se vuelve a manifestar una brecha significativa entre los algoritmos, aunque esta vez resulta interesante observar cómo ciertos valores tienden a estabilizarse pese al incremento de perturbaciones. Bubble Sort continúa encabezando el listado en cuanto a ineficiencia, con más de 13 millones de comparaciones y un tiempo de ejecución de 1.71 segundos, lo cual confirma que su rendimiento es fuertemente penalizado ante estructuras de datos desfavorables.\nUn aspecto que llama la atención es la constancia de Heapsort. Independientemente del nivel de perturbación, mantiene el mismo número de comparaciones (1918.52), lo cual refleja una gran estabilidad en su comportamiento. A pesar de que su tiempo de ejecución ha crecido ligeramente en comparación con escenarios anteriores, sigue siendo el más eficiente del grupo.\nMergesort y Quicksort aumentan gradualmente sus comparaciones a medida que las perturbaciones se intensifican, superando las 19 mil y 27 mil respectivamente. Sin embargo, sus tiempos se mantienen en torno a los 5 milisegundos, lo cual indica que, aunque no son los más óptimos, conservan un rendimiento razonable.\nSkiplist muestra una ligera mejora en número de comparaciones respecto al caso con p=256, pero sigue siendo más lento en tiempo. Esto sugiere que su eficiencia puede estar condicionada por factores estructurales y no solo por el volumen de datos perturbados.\nLas gráficas en escala logarítmica siguen siendo fundamentales para dimensionar estas diferencias. Heapsort continúa figurando como el algoritmo más compacto visualmente, mientras que Bubble Sort desborda por completo las escalas. Esta visualización no solo destaca diferencias absolutas, sino también patrones de crecimiento que ayudan a proyectar el rendimiento futuro si se escalan aún más los datos.\n\n\n\nLas variaciones observadas se deben a varios factores que se lograron visualizar en los gráficos y en la lista de posteo. Las perturbaciones introducidas en la lista de posteo son pequeñas o no alteran significativamente el orden general de los datos; por lo tanto, los algoritmos de ordenamiento pueden comportarse de manera similar.\nEl tamaño de la lista de posteo puede influir en cómo los algoritmos manejan las perturbaciones. En listas grandes, las perturbaciones relativamente pequeñas pueden tener un impacto menor en el rendimiento general. Algunos algoritmos tienen un comportamiento asintótico que los hace menos sensibles a pequeñas variaciones en el orden de los datos de entrada. Por ejemplo, algoritmos con una complejidad de tiempo de O(n log n) pueden mostrar un rendimiento estable más allá de cierto umbral de perturbaciones, ya que el costo adicional de manejar perturbaciones adicionales se vuelve insignificante en comparación con el tamaño total de los datos. (Huyen, 2022)\nLa forma en que se implementan los algoritmos puede afectar su rendimiento. Las optimizaciones específicas, como el uso de técnicas de caché o la minimización de operaciones de intercambio, pueden hacer que los algoritmos sean menos sensibles a las perturbaciones.\nLas métricas utilizadas para evaluar el rendimiento, como el número de comparaciones y el tiempo de ejecución, pueden no capturar completamente el impacto de las perturbaciones. Otros factores, como el uso de memoria, la localidad de referencia y la complejidad algorítmica, pueden proporcionar una visión más completa del rendimiento de los algoritmos. (Cormen, 2009)"
  },
  {
    "objectID": "project3.html#conclusiones",
    "href": "project3.html#conclusiones",
    "title": "Proyecto 3",
    "section": "",
    "text": "Al finalizar este análisis, puedo concluir que Heapsort fue, sin duda, el algoritmo más eficiente y consistente a lo largo de todos los escenarios evaluados. Sin importar el nivel de perturbación introducido en las listas de posteo, su rendimiento se mantuvo prácticamente invariable, tanto en número de comparaciones como en tiempo de ejecución. Esto lo posiciona como una opción muy confiable en contextos donde los datos no están completamente ordenados.\nPor el contrario, Bubble Sort demostró ser el menos adecuado para este tipo de condiciones, registrando cifras excesivas de comparaciones y tiempos considerablemente altos en todos los casos. Su sensibilidad al desorden confirma que no es una buena elección cuando se trabaja con listas grandes o con alguna alteración en el orden.\nMergesort y Quicksort ofrecieron un equilibrio bastante sólido, especialmente en cuanto a tiempos de ejecución. Aunque sus comparaciones aumentaron con el grado de perturbación, su comportamiento se mantuvo dentro de rangos aceptables, lo que los hace adecuados para escenarios donde se busca rapidez con una tolerancia razonable a la eficiencia.\nEn cuanto a Skiplist, observé un rendimiento intermedio. No fue el más rápido, pero tampoco presentó problemas extremos. Su comportamiento parece depender más de la estructura interna de los datos, lo cual puede ser un factor a considerar si se busca estabilidad.\nFinalmente, algo que considero clave es que la elección del algoritmo no debe basarse únicamente en su complejidad teórica. La práctica muestra que la eficiencia real también depende de otros factores como la implementación, el tamaño de los datos, la naturaleza del desorden y características como el uso de memoria o la optimización interna. Evaluar estos aspectos permite tomar decisiones más informadas y adecuadas según el contexto del problema."
  },
  {
    "objectID": "project3.html#referencias",
    "href": "project3.html#referencias",
    "title": "Proyecto 3",
    "section": "",
    "text": "Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms (3rd ed.). MIT Press.\nKnuth, D. E. (2011). The Art of Computer Programming, Volume 4A: Combinatorial Algorithms, Part 1. Addison-Wesley.\nRizvi, Q., Rai, H., & Jaiswal, R. (2024). Sorting Algorithms in Focus: A Critical Examination of Sorting Algorithm Performance.\nHuyen, C. (2022). Designing Machine Learning Systems. O’Reilly Media, Inc."
  },
  {
    "objectID": "project3.html#cambios-realizados",
    "href": "project3.html#cambios-realizados",
    "title": "Proyecto 3",
    "section": "",
    "text": "Con base en las observaciones realizadas durante la videoconferencia y en las notas complementarias, realicé una serie de ajustes importantes en el desarrollo de mi trabajo.\nPrimero, corregí la afirmación sobre el algoritmo Bubble Sort, aclarando que no es un algoritmo adaptativo. Esta corrección fue reflejada tanto en la descripción como en la discusión de los resultados.\nTambién ajusté las escalas de las gráficas generadas para cada algoritmo, con el objetivo de permitir una mejor visualización y comparación de sus comportamientos, especialmente en casos con tamaños de entrada moderados.\nEn cuanto a Merge Sort, revisé la implementación para evitar el uso innecesario de memoria adicional, ya que esto afectaba negativamente su eficiencia.\nPara Quick Sort, corregí la estrategia de selección del pivote, siguiendo las recomendaciones revisadas en clase, y documenté cómo esta decisión influye directamente en el rendimiento del algoritmo.\nPor último, eliminé el uso del número “ínfimo” en la implementación de Skip List, ya que comprendí que no era necesario dentro del modelo de comparación. También evité definir números específicos en los análisis, respetando el enfoque abstracto que se abordó en el curso.\nEstos cambios me ayudaron a alinear mejor mi trabajo con los principios teóricos del análisis algorítmico y a fortalecer mi comprensión de los conceptos trabajados."
  },
  {
    "objectID": "project1.html",
    "href": "project1.html",
    "title": "Proyecto 1",
    "section": "",
    "text": "En la era digital actual, el big data ha emergido como un recurso valioso para las organizaciones, permitiéndoles extraer, procesar y analizar datos significativos. El big data se caracteriza por sus cuatro V: volumen, velocidad, variedad y veracidad. El volumen se refiere a la gran cantidad de datos generados y almacenados; la velocidad, a la rapidez con la que se generan y procesan; la variedad, a los diferentes tipos de datos (estructurados y no estructurados); y la veracidad, a la calidad y precisión de dichos datos. La capacidad de manejar y analizar estos grandes volúmenes de información de manera eficiente es crucial para aprovechar al máximo el potencial del big data (Müller et al., 2016).\nEl análisis de big data permite a las organizaciones identificar patrones, predecir tendencias y optimizar procesos, lo que puede resultar en mejoras significativas en la eficiencia operativa y en la toma de decisiones estratégicas. Sin embargo, la manipulación de grandes volúmenes de datos presenta desafíos importantes en términos de infraestructura, almacenamiento, procesamiento y análisis. Los algoritmos eficientes son fundamentales para enfrentar estos desafíos y garantizar que los sistemas de big data funcionen de manera óptima (Manyika et al., 2011).\nEste reporte se enfoca en comparar diferentes órdenes de crecimiento mediante simulaciones en un entorno de Jupyter. Se analizarán los siguientes casos: \\(O(1)\\) vs \\(O(\\log n)\\), \\(O(n)\\) vs \\(O(n \\log n)\\), \\(O(n^2)\\) vs \\(O(n^3)\\), \\(O(a^n)\\) vs \\(O(n!)\\) y \\(O(n!)\\) vs \\(O(n^n)\\). Para cada comparación, se seleccionarán rangos adecuados de \\(n\\) que permitan visualizar claramente las diferencias entre estos órdenes. Se generarán gráficas para cada caso y se discutirán las observaciones correspondientes. Además, se incluirá una tabla con tiempos de ejecución simulados para algoritmos ficticios asociados a los órdenes de crecimiento mencionados, utilizando distintos tamaños de entrada \\(n\\). Este análisis proporciona una visión clara de cómo los diferentes órdenes de crecimiento afectan el rendimiento y la eficiencia de los algoritmos.\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\n\n\n\ndef constant(n): return 1\ndef logarithmic(n): return np.log(n)\ndef linear(n): return n\ndef linear_logarithmic(n): return n * np.log(n)\ndef quadratic(n): return n**2\ndef cubic(n): return n**3\ndef exponential(n, a=2): return a**n\ndef factorial(n): return math.factorial(n)\ndef double_exponential(n): return n**n\n\n\n\ndef plot_comparison(funcs, labels, title, x_range):\n    plt.figure(figsize=(7, 5))\n    for func, label in zip(funcs, labels):\n        plt.plot(x_range, [func(x) / 1e9 for x in x_range], label=label)\n    plt.xlabel('n')\n    plt.ylabel('Tiempo (s)')\n    plt.title(title)\n    plt.legend()\n    plt.yscale('log')\n    plt.xscale('log')\n    plt.grid(True)\n    plt.show()\n\n\n\nx_range_small = np.arange(1, 10)\nx_range_medium = np.arange(1, 100)\n\n# Comparación 1: O(1) vs O(log n)\nplot_comparison([constant, logarithmic], ['O(1)', 'O(log n)'], 'Figura 1 - Comparación de O(1) con O(log n)', x_range_small)\n\n# Comparación 2: O(n) vs O(n log n)\nplot_comparison([linear, linear_logarithmic], ['O(n)', 'O(n log n)'], 'Figura 2 - Comparación de O(n) con O(n log n)', x_range_medium)\n\n# Comparación 3: O(n^2) vs O(n^3)\nplot_comparison([quadratic, cubic], ['O(n^2)', 'O(n^3)'], 'Figura 3 - Comparación de O(n^2) con O(n^3)', x_range_medium)\n\n# Comparación 4: O(2^n) vs O(n!)\nplot_comparison([lambda n: exponential(n, 2), factorial], ['O(2^n)', 'O(n!)'], 'Figura 4 - Comparación de O(2^n) con O(n!)', x_range_small)\n\n# Comparación 5: O(n!) vs O(n^n)\nplot_comparison([factorial, double_exponential], ['O(n!)', 'O(n^n)'], 'Figura 5 - Comparación de O(n!) con O(n^n)', x_range_small)\n\n\n\nNota: Se creó una tabla con tiempos de ejecución simulados para algoritmos ficticios con los órdenes de crecimiento mencionados.\n# Tamaños de entrada\nn_values = [100, 1000, 10000, 100000]\n\n# Funciones de costo\ncost_functions = {\n    'O(1)': constant,\n    'O(log n)': logarithmic,\n    'O(n)': linear,\n    'O(n log n)': linear_logarithmic,\n    'O(n^2)': quadratic,\n    'O(n^3)': cubic,\n    'O(2^n)': lambda n: exponential(n, 2),\n    'O(n!)': factorial,\n    'O(n^n)': double_exponential\n}\n\n# Elaboración de la tabla\nresults = []\nfor n in n_values:\n    row = {'n': n}\n    for label, func in cost_functions.items():\n        try:\n            row[label] = func(n) / 1e9  # Conversión a segundos\n        except OverflowError:\n            row[label] = 'Overflow'\n    results.append(row)\n\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.set_index('n', inplace=True)\ndf\n\n\n\n\n\n\n\n\n\nEl gráfico muestra que la función constante \\(O(1)\\) permanece constante independientemente del tamaño de la entrada, mientras que \\(O(\\log n)\\) crece lentamente conforme \\(n\\) aumenta. Por lo tanto, un algoritmo con complejidad constante \\(O(1)\\) es más eficiente en términos de tiempo de ejecución en comparación con uno con complejidad logarítmica \\(O(\\log n)\\).\n\n\n\n\n\n\nLa función \\(O(n)\\) crece linealmente con el tamaño de entrada \\(n\\), mientras que la función \\(O(n \\log n)\\) crece más rápido que \\(O(n)\\), pero sigue siendo práctica para valores moderados de \\(n\\). Por lo tanto, un algoritmo con complejidad lineal \\(O(n)\\) es más eficiente en términos de tiempo de ejecución en comparación con uno con complejidad lineal-logarítmica \\(O(n \\log n)\\).\n\n\n\n\n\n\nLa función cuadrática \\(O(n^2)\\) crece más rápidamente que la lineal, pero la función cúbica \\(O(n^3)\\) lo hace aún con mayor rapidez. Por lo tanto, un algoritmo con complejidad cuadrática \\(O(n^2)\\) es más eficiente en términos de tiempo de ejecución en comparación con uno con complejidad cúbica \\(O(n^3)\\).\n\n\n\n\n\n\nEl gráfico muestra que la complejidad factorial \\(O(n!)\\) resulta en tiempos de ejecución mucho más altos que \\(O(2^n)\\) a medida que el tamaño de la entrada \\(n\\) aumenta. La complejidad factorial \\(O(n!)\\) crece considerablemente más rápido que la complejidad exponencial \\(O(2^n)\\), lo que hace que los algoritmos con esta complejidad sean prácticamente inutilizables para valores grandes de \\(n\\).\n\n\n\n\n\n\nEl gráfico muestra cómo la función factorial \\(O(n!)\\) crece muy rápidamente, pero la función doble exponencial \\(O(n^n)\\) crece aún más rápido a medida que aumenta el tamaño de la entrada \\(n\\). Por lo tanto, los algoritmos con complejidad factorial y doble exponencial son prácticamente inutilizables para valores grandes de \\(n\\).\n\n\n\n\n\n\n\n\nA continuación se presenta una tabla comparativa de los tiempos simulados para diferentes órdenes de crecimiento, utilizando distintos tamaños de entrada \\(n\\). Los resultados se expresan en segundos. En algunos casos, se muestra “Overflow” cuando el valor resultante excede los límites de representación.\nTabla 1. Tiempos simulados para diferentes órdenes de crecimiento de O(1), O(log n), O(n), O(n log n), O(n²)\n\n\n\n\n\n\n\n\n\n\n\nn\nO(1)\nO(log n)\nO(n)\nO(n log n)\nO(n²)\n\n\n\n\n100\n1.00e-09\n4.61e-09\n1.00e-07\n4.61e-07\n1.00e-05\n\n\n1000\n1.00e-09\n6.91e-09\n1.00e-06\n6.91e-06\n1.00e-03\n\n\n10000\n1.00e-09\n9.21e-09\n1.00e-05\n9.21e-05\n1.00e-01\n\n\n100000\n1.00e-09\n1.15e-08\n1.00e-04\n1.15e-03\n1.00e+01\n\n\n\nTabla 2. Tiempos simulados para diferentes órdenes de crecimiento de O(n³), O(2ⁿ)\n\n\n\nn\nO(n³)\nO(2ⁿ)\n\n\n\n\n100\n1.00e-03\n1.27e+21\n\n\n1000\n1.00e+00\nOverflow\n\n\n10000\n1.00e+03\nOverflow\n\n\n100000\n1.00e+06\nOverflow\n\n\n\nTabla 3. Tiempos simulados para diferentes órdenes de crecimiento de O(n!), O(nⁿ)\n\n\n\nn\nO(n!)\nO(nⁿ)\n\n\n\n\n100\nOverflow\nOverflow\n\n\n1000\nOverflow\nOverflow\n\n\n10000\nOverflow\nOverflow\n\n\n100000\nOverflow\nOverflow\n\n\n\n\nNota: Algunos valores como O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de \\(n\\) generan cantidades inmanejables por el sistema, resultando en Overflow. Esto refleja la inviabilidad práctica de algoritmos con estas complejidades cuando se trabaja con grandes volúmenes de datos.\n\nComo se muestra en la tabla, el tiempo de ejecución de O(1) no depende del tamaño de n. Este mantiene un mismo valor, lo que indica que su tiempo de ejecución es constante. Por otro lado, los valores de O(log n) aumentan lentamente a medida que n crece, lo cual es consistente con su comportamiento logarítmico. En el caso de O(n), los valores aumentan de forma lineal conforme n se incrementa. Los valores de O(n log n) aumentan más rápido que los de O(n), pero no tan aceleradamente como los de O(n²). Por su parte, O(n²) crece rápidamente a medida que n aumenta, y O(n³) lo hace de forma aún más acelerada, incluso con valores pequeños de entrada.\nDurante la ejecución del código, algunos resultados aparecen como “Overflow”. Esto se debe a que las funciones O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de n (como 10,000 o 100,000) generan números extremadamente grandes, lo que excede la capacidad de representación y manejo numérico en Python.\n\n\n\n\nLa manipulación de grandes volúmenes de información presenta importantes desafíos debido a los costos de cómputo. Estos costos se relacionan con el gasto monetario, los recursos computacionales requeridos, el tiempo de procesamiento, el uso de memoria, el almacenamiento y el consumo energético. A continuación se presentan algunas de las implicaciones más relevantes:\n\nInfraestructura: Manipular grandes volúmenes de datos requiere una infraestructura robusta, que incluye servidores potentes, almacenamiento masivo y redes de alta velocidad. Esto representa costos elevados en hardware, mantenimiento y consumo energético (Armbrust et al., 2010).\nEnergía: Los centros de datos que procesan grandes cantidades de información consumen enormes cantidades de energía, lo cual incrementa los costos operativos y contribuye al impacto ambiental debido a las emisiones de carbono (Baliga et al., 2011).\nAlmacenamiento: El almacenamiento de grandes volúmenes de datos requiere soluciones escalables y eficientes. Este aspecto representa un costo considerable, ya que también debe garantizarse la recuperación oportuna de la información.\nProcesamiento: Procesar datos en tiempo real o en tiempo cercano al real implica el uso de algoritmos eficientes y de recursos de cómputo significativos. Estos costos pueden incrementarse especialmente al utilizar tecnologías como el aprendizaje automático y la inteligencia artificial (Wang et al., 2015).\n\nEn conjunto, la gestión de grandes volúmenes de información conlleva costos considerables en términos de infraestructura, energía, almacenamiento, procesamiento, seguridad y mantenimiento. Estos aspectos deben ser cuidadosamente planeados y gestionados para asegurar soluciones de big data eficientes y sostenibles.\n\n\n\n\nEn las simulaciones realizadas se observó que los órdenes de crecimiento más bajos, como O(1), O(log n) y O(n), resultan altamente eficientes. Son ideales para tareas que demandan rendimiento óptimo y tiempos de respuesta reducidos.\nPor otro lado, los órdenes de crecimiento O(n log n) y O(n²) demostraron ser prácticas y ampliamente aplicables, al ofrecer un buen equilibrio entre eficiencia y capacidad de procesamiento.\nEn contraste, las funciones con órdenes de crecimiento elevados como O(2ⁿ), O(n!) y O(nⁿ) resultaron ineficientes, generando tiempos de ejecución excesivos o incluso errores de memoria.\nLa tabla de tiempos de ejecución simulados confirma cómo el crecimiento del orden afecta directamente el rendimiento de los algoritmos. A mayor orden, mayor consumo de recursos y tiempo; a menor orden, mayor eficiencia en la ejecución.\n\n\n\n\nMüller, V. C., Schal, J. M., Meyer-Lindenberg, A. (2016). Machine Learning for Brain Imaging. Cambridge University Press.\nManyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C., & Byers, A. H. (2011). Big data: The next frontier for innovation, competition, and productivity. McKinsey Global Institute. https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/big-data-the-next-frontier-for-innovation\nArmbrust, M., Fox, A., Griffith, R., Joseph, A. D., Katz, R. H., Konwinski, A., et al. (2010). A View of Cloud Computing. Communications of the ACM, 53(4), 50–58. https://doi.org/10.1145/1721654.1721672\nBaliga, J., Ayre, R., Hinton, K., & Tucker, R. S. (2011). Energy-Efficient Telecommunications.\nWang, L., Chen, Y., & Liu, Q. (2015). Big Data Processing: A Survey. Springer.\n\n\n\n\n\n\nLos siguientes ajustes fueron aplicados al presente documento en atención a la retroalimentación recibida por parte del docente. Se atendieron los puntos señalados con el fin de mejorar la calidad formal y académica del reporte:\n\nSe uniformó el formato del documento, manteniendo una estructura clara y coherente entre secciones.\nSe corrigieron errores ortográficos y gramaticales, incluyendo el uso adecuado de comas y acentos.\nLas expresiones matemáticas fueron reescritas utilizando la notación correcta en formato de ecuación (LaTeX), como es el caso de \\(O(1)\\), \\(O(\\log n)\\), \\(O(n^2)\\), entre otras.\nSe estandarizaron los encabezados de cada sección para facilitar la lectura y navegación del documento.\n\nEstas modificaciones aseguran que el trabajo cumpla con los criterios de presentación solicitados y refleje un esfuerzo riguroso en la construcción y exposición del contenido."
  },
  {
    "objectID": "project1.html#introducción",
    "href": "project1.html#introducción",
    "title": "Proyecto 1",
    "section": "",
    "text": "En la era digital actual, el big data ha emergido como un recurso valioso para las organizaciones, permitiéndoles extraer, procesar y analizar datos significativos. El big data se caracteriza por sus cuatro V: volumen, velocidad, variedad y veracidad. El volumen se refiere a la gran cantidad de datos generados y almacenados; la velocidad, a la rapidez con la que se generan y procesan; la variedad, a los diferentes tipos de datos (estructurados y no estructurados); y la veracidad, a la calidad y precisión de dichos datos. La capacidad de manejar y analizar estos grandes volúmenes de información de manera eficiente es crucial para aprovechar al máximo el potencial del big data (Müller et al., 2016).\nEl análisis de big data permite a las organizaciones identificar patrones, predecir tendencias y optimizar procesos, lo que puede resultar en mejoras significativas en la eficiencia operativa y en la toma de decisiones estratégicas. Sin embargo, la manipulación de grandes volúmenes de datos presenta desafíos importantes en términos de infraestructura, almacenamiento, procesamiento y análisis. Los algoritmos eficientes son fundamentales para enfrentar estos desafíos y garantizar que los sistemas de big data funcionen de manera óptima (Manyika et al., 2011).\nEste reporte se enfoca en comparar diferentes órdenes de crecimiento mediante simulaciones en un entorno de Jupyter. Se analizarán los siguientes casos: \\(O(1)\\) vs \\(O(\\log n)\\), \\(O(n)\\) vs \\(O(n \\log n)\\), \\(O(n^2)\\) vs \\(O(n^3)\\), \\(O(a^n)\\) vs \\(O(n!)\\) y \\(O(n!)\\) vs \\(O(n^n)\\). Para cada comparación, se seleccionarán rangos adecuados de \\(n\\) que permitan visualizar claramente las diferencias entre estos órdenes. Se generarán gráficas para cada caso y se discutirán las observaciones correspondientes. Además, se incluirá una tabla con tiempos de ejecución simulados para algoritmos ficticios asociados a los órdenes de crecimiento mencionados, utilizando distintos tamaños de entrada \\(n\\). Este análisis proporciona una visión clara de cómo los diferentes órdenes de crecimiento afectan el rendimiento y la eficiencia de los algoritmos."
  },
  {
    "objectID": "project1.html#desarrollo",
    "href": "project1.html#desarrollo",
    "title": "Proyecto 1",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\n\n\n\ndef constant(n): return 1\ndef logarithmic(n): return np.log(n)\ndef linear(n): return n\ndef linear_logarithmic(n): return n * np.log(n)\ndef quadratic(n): return n**2\ndef cubic(n): return n**3\ndef exponential(n, a=2): return a**n\ndef factorial(n): return math.factorial(n)\ndef double_exponential(n): return n**n\n\n\n\ndef plot_comparison(funcs, labels, title, x_range):\n    plt.figure(figsize=(7, 5))\n    for func, label in zip(funcs, labels):\n        plt.plot(x_range, [func(x) / 1e9 for x in x_range], label=label)\n    plt.xlabel('n')\n    plt.ylabel('Tiempo (s)')\n    plt.title(title)\n    plt.legend()\n    plt.yscale('log')\n    plt.xscale('log')\n    plt.grid(True)\n    plt.show()\n\n\n\nx_range_small = np.arange(1, 10)\nx_range_medium = np.arange(1, 100)\n\n# Comparación 1: O(1) vs O(log n)\nplot_comparison([constant, logarithmic], ['O(1)', 'O(log n)'], 'Figura 1 - Comparación de O(1) con O(log n)', x_range_small)\n\n# Comparación 2: O(n) vs O(n log n)\nplot_comparison([linear, linear_logarithmic], ['O(n)', 'O(n log n)'], 'Figura 2 - Comparación de O(n) con O(n log n)', x_range_medium)\n\n# Comparación 3: O(n^2) vs O(n^3)\nplot_comparison([quadratic, cubic], ['O(n^2)', 'O(n^3)'], 'Figura 3 - Comparación de O(n^2) con O(n^3)', x_range_medium)\n\n# Comparación 4: O(2^n) vs O(n!)\nplot_comparison([lambda n: exponential(n, 2), factorial], ['O(2^n)', 'O(n!)'], 'Figura 4 - Comparación de O(2^n) con O(n!)', x_range_small)\n\n# Comparación 5: O(n!) vs O(n^n)\nplot_comparison([factorial, double_exponential], ['O(n!)', 'O(n^n)'], 'Figura 5 - Comparación de O(n!) con O(n^n)', x_range_small)\n\n\n\nNota: Se creó una tabla con tiempos de ejecución simulados para algoritmos ficticios con los órdenes de crecimiento mencionados.\n# Tamaños de entrada\nn_values = [100, 1000, 10000, 100000]\n\n# Funciones de costo\ncost_functions = {\n    'O(1)': constant,\n    'O(log n)': logarithmic,\n    'O(n)': linear,\n    'O(n log n)': linear_logarithmic,\n    'O(n^2)': quadratic,\n    'O(n^3)': cubic,\n    'O(2^n)': lambda n: exponential(n, 2),\n    'O(n!)': factorial,\n    'O(n^n)': double_exponential\n}\n\n# Elaboración de la tabla\nresults = []\nfor n in n_values:\n    row = {'n': n}\n    for label, func in cost_functions.items():\n        try:\n            row[label] = func(n) / 1e9  # Conversión a segundos\n        except OverflowError:\n            row[label] = 'Overflow'\n    results.append(row)\n\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.set_index('n', inplace=True)\ndf"
  },
  {
    "objectID": "project1.html#análisis-de-resultados",
    "href": "project1.html#análisis-de-resultados",
    "title": "Proyecto 1",
    "section": "",
    "text": "El gráfico muestra que la función constante \\(O(1)\\) permanece constante independientemente del tamaño de la entrada, mientras que \\(O(\\log n)\\) crece lentamente conforme \\(n\\) aumenta. Por lo tanto, un algoritmo con complejidad constante \\(O(1)\\) es más eficiente en términos de tiempo de ejecución en comparación con uno con complejidad logarítmica \\(O(\\log n)\\).\n\n\n\n\n\n\nLa función \\(O(n)\\) crece linealmente con el tamaño de entrada \\(n\\), mientras que la función \\(O(n \\log n)\\) crece más rápido que \\(O(n)\\), pero sigue siendo práctica para valores moderados de \\(n\\). Por lo tanto, un algoritmo con complejidad lineal \\(O(n)\\) es más eficiente en términos de tiempo de ejecución en comparación con uno con complejidad lineal-logarítmica \\(O(n \\log n)\\).\n\n\n\n\n\n\nLa función cuadrática \\(O(n^2)\\) crece más rápidamente que la lineal, pero la función cúbica \\(O(n^3)\\) lo hace aún con mayor rapidez. Por lo tanto, un algoritmo con complejidad cuadrática \\(O(n^2)\\) es más eficiente en términos de tiempo de ejecución en comparación con uno con complejidad cúbica \\(O(n^3)\\).\n\n\n\n\n\n\nEl gráfico muestra que la complejidad factorial \\(O(n!)\\) resulta en tiempos de ejecución mucho más altos que \\(O(2^n)\\) a medida que el tamaño de la entrada \\(n\\) aumenta. La complejidad factorial \\(O(n!)\\) crece considerablemente más rápido que la complejidad exponencial \\(O(2^n)\\), lo que hace que los algoritmos con esta complejidad sean prácticamente inutilizables para valores grandes de \\(n\\).\n\n\n\n\n\n\nEl gráfico muestra cómo la función factorial \\(O(n!)\\) crece muy rápidamente, pero la función doble exponencial \\(O(n^n)\\) crece aún más rápido a medida que aumenta el tamaño de la entrada \\(n\\). Por lo tanto, los algoritmos con complejidad factorial y doble exponencial son prácticamente inutilizables para valores grandes de \\(n\\).\n\n\n\n\n\n\n\n\nA continuación se presenta una tabla comparativa de los tiempos simulados para diferentes órdenes de crecimiento, utilizando distintos tamaños de entrada \\(n\\). Los resultados se expresan en segundos. En algunos casos, se muestra “Overflow” cuando el valor resultante excede los límites de representación.\nTabla 1. Tiempos simulados para diferentes órdenes de crecimiento de O(1), O(log n), O(n), O(n log n), O(n²)\n\n\n\n\n\n\n\n\n\n\n\nn\nO(1)\nO(log n)\nO(n)\nO(n log n)\nO(n²)\n\n\n\n\n100\n1.00e-09\n4.61e-09\n1.00e-07\n4.61e-07\n1.00e-05\n\n\n1000\n1.00e-09\n6.91e-09\n1.00e-06\n6.91e-06\n1.00e-03\n\n\n10000\n1.00e-09\n9.21e-09\n1.00e-05\n9.21e-05\n1.00e-01\n\n\n100000\n1.00e-09\n1.15e-08\n1.00e-04\n1.15e-03\n1.00e+01\n\n\n\nTabla 2. Tiempos simulados para diferentes órdenes de crecimiento de O(n³), O(2ⁿ)\n\n\n\nn\nO(n³)\nO(2ⁿ)\n\n\n\n\n100\n1.00e-03\n1.27e+21\n\n\n1000\n1.00e+00\nOverflow\n\n\n10000\n1.00e+03\nOverflow\n\n\n100000\n1.00e+06\nOverflow\n\n\n\nTabla 3. Tiempos simulados para diferentes órdenes de crecimiento de O(n!), O(nⁿ)\n\n\n\nn\nO(n!)\nO(nⁿ)\n\n\n\n\n100\nOverflow\nOverflow\n\n\n1000\nOverflow\nOverflow\n\n\n10000\nOverflow\nOverflow\n\n\n100000\nOverflow\nOverflow\n\n\n\n\nNota: Algunos valores como O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de \\(n\\) generan cantidades inmanejables por el sistema, resultando en Overflow. Esto refleja la inviabilidad práctica de algoritmos con estas complejidades cuando se trabaja con grandes volúmenes de datos.\n\nComo se muestra en la tabla, el tiempo de ejecución de O(1) no depende del tamaño de n. Este mantiene un mismo valor, lo que indica que su tiempo de ejecución es constante. Por otro lado, los valores de O(log n) aumentan lentamente a medida que n crece, lo cual es consistente con su comportamiento logarítmico. En el caso de O(n), los valores aumentan de forma lineal conforme n se incrementa. Los valores de O(n log n) aumentan más rápido que los de O(n), pero no tan aceleradamente como los de O(n²). Por su parte, O(n²) crece rápidamente a medida que n aumenta, y O(n³) lo hace de forma aún más acelerada, incluso con valores pequeños de entrada.\nDurante la ejecución del código, algunos resultados aparecen como “Overflow”. Esto se debe a que las funciones O(2ⁿ), O(n!) y O(nⁿ) para valores grandes de n (como 10,000 o 100,000) generan números extremadamente grandes, lo que excede la capacidad de representación y manejo numérico en Python.\n\n\n\n\nLa manipulación de grandes volúmenes de información presenta importantes desafíos debido a los costos de cómputo. Estos costos se relacionan con el gasto monetario, los recursos computacionales requeridos, el tiempo de procesamiento, el uso de memoria, el almacenamiento y el consumo energético. A continuación se presentan algunas de las implicaciones más relevantes:\n\nInfraestructura: Manipular grandes volúmenes de datos requiere una infraestructura robusta, que incluye servidores potentes, almacenamiento masivo y redes de alta velocidad. Esto representa costos elevados en hardware, mantenimiento y consumo energético (Armbrust et al., 2010).\nEnergía: Los centros de datos que procesan grandes cantidades de información consumen enormes cantidades de energía, lo cual incrementa los costos operativos y contribuye al impacto ambiental debido a las emisiones de carbono (Baliga et al., 2011).\nAlmacenamiento: El almacenamiento de grandes volúmenes de datos requiere soluciones escalables y eficientes. Este aspecto representa un costo considerable, ya que también debe garantizarse la recuperación oportuna de la información.\nProcesamiento: Procesar datos en tiempo real o en tiempo cercano al real implica el uso de algoritmos eficientes y de recursos de cómputo significativos. Estos costos pueden incrementarse especialmente al utilizar tecnologías como el aprendizaje automático y la inteligencia artificial (Wang et al., 2015).\n\nEn conjunto, la gestión de grandes volúmenes de información conlleva costos considerables en términos de infraestructura, energía, almacenamiento, procesamiento, seguridad y mantenimiento. Estos aspectos deben ser cuidadosamente planeados y gestionados para asegurar soluciones de big data eficientes y sostenibles."
  },
  {
    "objectID": "project1.html#conclusiones",
    "href": "project1.html#conclusiones",
    "title": "Proyecto 1",
    "section": "",
    "text": "En las simulaciones realizadas se observó que los órdenes de crecimiento más bajos, como O(1), O(log n) y O(n), resultan altamente eficientes. Son ideales para tareas que demandan rendimiento óptimo y tiempos de respuesta reducidos.\nPor otro lado, los órdenes de crecimiento O(n log n) y O(n²) demostraron ser prácticas y ampliamente aplicables, al ofrecer un buen equilibrio entre eficiencia y capacidad de procesamiento.\nEn contraste, las funciones con órdenes de crecimiento elevados como O(2ⁿ), O(n!) y O(nⁿ) resultaron ineficientes, generando tiempos de ejecución excesivos o incluso errores de memoria.\nLa tabla de tiempos de ejecución simulados confirma cómo el crecimiento del orden afecta directamente el rendimiento de los algoritmos. A mayor orden, mayor consumo de recursos y tiempo; a menor orden, mayor eficiencia en la ejecución."
  },
  {
    "objectID": "project1.html#referencias",
    "href": "project1.html#referencias",
    "title": "Proyecto 1",
    "section": "",
    "text": "Müller, V. C., Schal, J. M., Meyer-Lindenberg, A. (2016). Machine Learning for Brain Imaging. Cambridge University Press.\nManyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C., & Byers, A. H. (2011). Big data: The next frontier for innovation, competition, and productivity. McKinsey Global Institute. https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/big-data-the-next-frontier-for-innovation\nArmbrust, M., Fox, A., Griffith, R., Joseph, A. D., Katz, R. H., Konwinski, A., et al. (2010). A View of Cloud Computing. Communications of the ACM, 53(4), 50–58. https://doi.org/10.1145/1721654.1721672\nBaliga, J., Ayre, R., Hinton, K., & Tucker, R. S. (2011). Energy-Efficient Telecommunications.\nWang, L., Chen, Y., & Liu, Q. (2015). Big Data Processing: A Survey. Springer."
  },
  {
    "objectID": "project1.html#cambios-realizados",
    "href": "project1.html#cambios-realizados",
    "title": "Proyecto 1",
    "section": "",
    "text": "Los siguientes ajustes fueron aplicados al presente documento en atención a la retroalimentación recibida por parte del docente. Se atendieron los puntos señalados con el fin de mejorar la calidad formal y académica del reporte:\n\nSe uniformó el formato del documento, manteniendo una estructura clara y coherente entre secciones.\nSe corrigieron errores ortográficos y gramaticales, incluyendo el uso adecuado de comas y acentos.\nLas expresiones matemáticas fueron reescritas utilizando la notación correcta en formato de ecuación (LaTeX), como es el caso de \\(O(1)\\), \\(O(\\log n)\\), \\(O(n^2)\\), entre otras.\nSe estandarizaron los encabezados de cada sección para facilitar la lectura y navegación del documento.\n\nEstas modificaciones aseguran que el trabajo cumpla con los criterios de presentación solicitados y refleje un esfuerzo riguroso en la construcción y exposición del contenido."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre Mí",
    "section": "",
    "text": "📍 Aguascalientes, México\n✉️ juan2javm@gmail.com / jvelasquez1800@alumno.ipn.mx\n📱 +52 322 353 4081\n🔗 GitHub: juan21javm\n🔗 LinkedIn: antonio-martínez-776788179\n\n\n\nMe considero una persona profundamente comprometida con el crecimiento intelectual, la lectura reflexiva y el bienestar de mi entorno cercano. Disfruto de los momentos al aire libre, donde encuentro inspiración en la naturaleza y la tranquilidad necesaria para mantener un equilibrio emocional. Valoro profundamente el tiempo con mi familia, ya que es el motor que impulsa mi disciplina, responsabilidad y deseo de superación constante. Asimismo, tengo una gran pasión por la programación y un genuino entusiasmo por la ciencia de datos, áreas que me permiten combinar creatividad, lógica y análisis. Estos principios personales complementan mi formación académica y profesional, motivándome a mantener siempre una actitud proactiva, ética y humana.\n\n\n\n\nSupervisor — INE (2023–2025), Loreto, Zacatecas\n- Supervisión de actividades diarias para cumplimiento de objetivos.\n- Capacitación del equipo y mejora de rendimiento.\n- Evaluación de desempeño y optimización de procesos.\nMaestro Asistente — IPN (2022–2023), Zacatecas\n- Evaluación del progreso estudiantil.\n- Planeación conjunta de actividades educativas.\n- Creación y adaptación de materiales educativos.\n\n\n\n\nProyecto A — Estandarización de proceso a nivel laboratorio (2021–2023)\n- Herramientas: MATLAB, HACCP Software, Latex\n- Liderazgo de investigación para producción de yogurt con uvas a nivel laboratorio.\n- Reconocimiento al mejor promedio del programa académico (IPN 2017–2022).\n- Primer lugar en Simposium Agroalimentario y Ciclo de Conferencias CUALTIA 2023.\n\n\n\n\n\nLenguajes: Python, JAVA, HTML, ASPEN\n\nHerramientas Matemáticas: MATLAB, R, SPSS, PLC\n\nOfimática: Office, LaTeX\n\n\n\n\n\n\nIdiomas: Español (nativo), Inglés (B1)\n\nIntereses: Lectura, búsqueda, planeación"
  },
  {
    "objectID": "about.html#perfil-personal",
    "href": "about.html#perfil-personal",
    "title": "Sobre Mí",
    "section": "",
    "text": "Me considero una persona profundamente comprometida con el crecimiento intelectual, la lectura reflexiva y el bienestar de mi entorno cercano. Disfruto de los momentos al aire libre, donde encuentro inspiración en la naturaleza y la tranquilidad necesaria para mantener un equilibrio emocional. Valoro profundamente el tiempo con mi familia, ya que es el motor que impulsa mi disciplina, responsabilidad y deseo de superación constante. Asimismo, tengo una gran pasión por la programación y un genuino entusiasmo por la ciencia de datos, áreas que me permiten combinar creatividad, lógica y análisis. Estos principios personales complementan mi formación académica y profesional, motivándome a mantener siempre una actitud proactiva, ética y humana."
  },
  {
    "objectID": "about.html#experiencia-laboral",
    "href": "about.html#experiencia-laboral",
    "title": "Sobre Mí",
    "section": "",
    "text": "Supervisor — INE (2023–2025), Loreto, Zacatecas\n- Supervisión de actividades diarias para cumplimiento de objetivos.\n- Capacitación del equipo y mejora de rendimiento.\n- Evaluación de desempeño y optimización de procesos.\nMaestro Asistente — IPN (2022–2023), Zacatecas\n- Evaluación del progreso estudiantil.\n- Planeación conjunta de actividades educativas.\n- Creación y adaptación de materiales educativos."
  },
  {
    "objectID": "about.html#proyectos-conferencias-y-reconocimientos",
    "href": "about.html#proyectos-conferencias-y-reconocimientos",
    "title": "Sobre Mí",
    "section": "",
    "text": "Proyecto A — Estandarización de proceso a nivel laboratorio (2021–2023)\n- Herramientas: MATLAB, HACCP Software, Latex\n- Liderazgo de investigación para producción de yogurt con uvas a nivel laboratorio.\n- Reconocimiento al mejor promedio del programa académico (IPN 2017–2022).\n- Primer lugar en Simposium Agroalimentario y Ciclo de Conferencias CUALTIA 2023."
  },
  {
    "objectID": "about.html#habilidades",
    "href": "about.html#habilidades",
    "title": "Sobre Mí",
    "section": "",
    "text": "Lenguajes: Python, JAVA, HTML, ASPEN\n\nHerramientas Matemáticas: MATLAB, R, SPSS, PLC\n\nOfimática: Office, LaTeX"
  },
  {
    "objectID": "about.html#información-adicional",
    "href": "about.html#información-adicional",
    "title": "Sobre Mí",
    "section": "",
    "text": "Idiomas: Español (nativo), Inglés (B1)\n\nIntereses: Lectura, búsqueda, planeación"
  },
  {
    "objectID": "index.html#presentación-del-proyecto",
    "href": "index.html#presentación-del-proyecto",
    "title": "Centro de Investigación e Innovación en Tecnologías de la Información y Comunicación",
    "section": "Presentación del proyecto",
    "text": "Presentación del proyecto\nEn esta página se encuentran reflejados los cinco reportes desarrollados a lo largo de la asignatura de Análisis de Algoritmos. Cada uno de ellos ha sido debidamente documentado, estructurado y trasladado al formato Quarto con el propósito de comunicar al público el trabajo realizado y los análisis efectuados durante mi estancia en la materia. Estos reportes representan el proceso de aprendizaje y aplicación práctica de los conceptos clave abordados en cada unidad, desde la introducción al análisis algorítmico hasta los algoritmos de intersección de conjuntos, permitiendo evidenciar el desarrollo de competencias técnicas y analíticas fundamentales en el área.\nEsta documentación ha sido preparada para su publicación en un repositorio de GitHub con el objetivo de compartir de forma abierta los contenidos desarrollados, promover el acceso al conocimiento, y facilitar su consulta por parte de docentes, estudiantes y profesionales interesados en el análisis de algoritmos.\nA lo largo del curso se desarrollaron cinco tareas escritas que reflejan los temas fundamentales abordados en cada unidad:\n\nUnidad 1: Introducción al análisis de algoritmos\nSe realizó el reporte 1A. Reporte escrito. Experimentos y análisis, en el que se exploraron conceptos básicos sobre la eficiencia algorítmica y órdenes de crecimiento.\nUnidad 2: Estructuras de datos\nSe trabajó el reporte 2A. Reporte escrito. Experimentos y análisis de estructuras de datos, enfocado en el comportamiento, manipulación y análisis de distintas estructuras como listas, pilas, colas y árboles.\nUnidad 3: Algoritmos de ordenamiento por comparación\nSe elaboró el 3A. Reporte escrito. Experimentos y análisis de algoritmos de ordenamiento, donde se evaluaron métodos como burbuja, inserción, selección, quicksort y mergesort.\nUnidad 4: Algoritmos de búsqueda por comparación\nSe desarrolló el reporte 4A. Reporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación, abordando técnicas como la búsqueda lineal y binaria, con un enfoque en su eficiencia.\nUnidad 5: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\nSe presentó el 5A. Reporte escrito. Experimentos y análisis de algoritmos de intersección de conjuntos, donde se analizaron distintas estrategias para operar sobre múltiples listas ordenadas.\n\nHe realizado todos los cambios y correcciones indicados por el profesor en cada uno de mis proyectos. Las observaciones fueron cuidadosamente revisadas y aplicadas, incluyendo ajustes en los algoritmos, análisis de resultados y redacción de los reportes. Cada informe fue modificado conforme a los comentarios recibidos, asegurando que tanto la parte técnica como la presentación cumplan con los criterios establecidos. Los reportes finales reflejan ya todas estas mejoras y se encuentran actualizados y corregidos conforme a lo solicitado."
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Proyecto 2",
    "section": "",
    "text": "Los experimentos y análisis de estructuras de datos son fundamentales en la ciencia de datos, ya que permiten evaluar y optimizar el rendimiento de algoritmos y sistemas que manejan grandes volúmenes de información.\nLas estructuras de datos son formas de organizar y almacenar datos en una computadora para que puedan ser accedidos y modificados de manera eficiente. Cada estructura tiene sus propias ventajas y desventajas en términos de tiempo de acceso, uso de memoria y facilidad de implementación. Los experimentos en estructuras de datos suelen centrarse en medir estos aspectos bajo diferentes condiciones para determinar cuál es la más adecuada para una aplicación específica (Goodfellow et al., 2016).\nEl diseño experimental es una etapa esencial que precede al análisis de datos. Un diseño bien planificado asegura que los datos recopilados sean relevantes y útiles para el análisis posterior. Esto incluye la definición de variables, la selección de muestras y la implementación de controles para minimizar sesgos. Estas estructuras son esenciales para el desarrollo de software eficiente, especialmente en campos como el Internet de las Cosas (IoT) y el Big Data, donde la optimización de recursos es crucial (Strang, 2016).\nEl análisis de datos implica varias técnicas estadísticas y computacionales para interpretar los resultados experimentales. Esto puede incluir análisis exploratorio de datos (EDA) para identificar patrones y relaciones, así como análisis confirmatorio para probar hipótesis específicas. Herramientas como Hadoop, Spark, Power BI, Pandas y R son comúnmente utilizadas en este proceso (Grcar, 2011).\nLa multiplicación de matrices es una operación básica que se utiliza en numerosos cálculos matemáticos y algoritmos computacionales. Su relevancia radica en su capacidad para transformar y combinar datos de manera que se puedan extraer insights significativos. La eliminación gaussiana es un método clásico para resolver sistemas de ecuaciones lineales, transformando una matriz en una forma escalonada reducida por filas. Este método es ampliamente utilizado debido a su estabilidad numérica y su capacidad para manejar sistemas grandes.\nEl objetivo es entender cómo se comportan estos algoritmos en diferentes situaciones, especialmente en cuanto al número de operaciones (como multiplicaciones y sumas) y el tiempo que tardan en ejecutarse en la práctica. Para abordar esta cuestión, se plantea un estudio comparativo utilizando matrices aleatorias de tamaño \\(n \\times n\\) para \\(n = 100\\), \\(300\\), \\(1000\\). Este enfoque permitirá evaluar la eficiencia de cada algoritmo y proporcionará una base sólida para futuras optimizaciones. Al comparar estos algoritmos, se busca responder a preguntas clave como: ¿Qué puedes concluir?, ¿Cuál es el impacto de acceder a los elementos contiguos en memoria de una matriz?, ¿Qué cambiarías si utilizas matrices dispersas?, y ¿Cuáles serían los costos?\n\n\n\n\n\nimport numpy as np\nimport time\n\n\n\ndef matrix_multiplication(A, B):\n    n = len(A)  # Tamaño de la matriz (n x n)\n    C = np.zeros((n, n))  # Inicializar la matriz resultante con ceros\n    operations = 0  # Contador de operaciones\n\n    for i in range(n):\n        for j in range(n):\n            for k in range(n):\n                C[i][j] += A[i][k] * B[k][j]  # Multiplicación y suma\n                operations += 2  # Una multiplicación y una suma\n\n    return C, operations\n\n\n\ndef gauss_jordan(A):\n    n = len(A)\n    operations = 0\n    A = np.array(A, dtype=float)\n\n    for i in range(n):\n        if A[i][i] == 0:\n            for j in range(i+1, n):\n                if A[j][i] != 0:\n                    A[[i, j]] = A[[j, i]]  # Intercambio de filas\n                    operations += 1\n                    break\n\n        div = A[i][i]\n        A[i] = A[i] / div\n        operations += n  # n divisiones\n\n        for j in range(n):\n            if i != j:\n                A[j] = A[j] - A[j][i] * A[i]\n                operations += n  # n multiplicaciones y restas\n\n    return A, operations\n\n\n\nsizes = [100, 300, 1000]\nresults = []\n\nfor n in sizes:\n    A = np.random.rand(n, n)\n    B = np.random.rand(n, n)\n\n    # Multiplicación de matrices\n    start_time = time.time()\n    C, mult_operations = matrix_multiplication(A, B)\n    mult_time = time.time() - start_time\n\n    # Eliminación Gaussiana\n    start_time = time.time()\n    _, gauss_operations = gauss_jordan(A)\n    gauss_time = time.time() - start_time\n\n    results.append({\n        'n': n,\n        'mult_operations': mult_operations,\n        'mult_time': mult_time,\n        'gauss_operations': gauss_operations,\n        'gauss_time': gauss_time\n    })\n\n\n\nfor result in results:\n    print(f\"Tamaño de la matriz (n): {result['n']}\")\n    print(\" Multiplicación de Matrices:\")\n    print(f\" Operaciones: {result['mult_operations']}\")\n    print(f\" Tiempo (s): {result['mult_time']:.6f}\")\n    print(\" Eliminación Gaussiana:\")\n    print(f\" Operaciones: {result['gauss_operations']}\")\n    print(f\" Tiempo (s): {result['gauss_time']:.6f}\")\n    print(\"-\" * 40)\n\n\n\n\n\n\nA continuación se muestra una tabla con los resultados obtenidos al comparar la multiplicación de matrices y la eliminación Gauss-Jordan sobre matrices de distintos tamaños. Se reporta el número total de operaciones y el tiempo de ejecución en segundos.\n\n\n\n\n\n\n\n\n\n\nTamaño (n)\nOperaciones Multiplicación\nTiempo Multiplicación (s)\nOperaciones Gauss\nTiempo Gauss (s)\n\n\n\n\n100\n2,000,000\n1.829321\n1,000,000\n0.066816\n\n\n300\n54,000,000\n30.990801\n27,000,000\n0.399951\n\n\n1000\n2,000,000,000\n1071.753574\n1,000,000,000\n5.316519\n\n\n\n\nNota: La eliminación Gauss-Jordan muestra una notable ventaja en tiempo de ejecución respecto a la multiplicación de matrices, aunque ambas mantienen una proporción consistente en la cantidad de operaciones requeridas.\n\nLos resultados obtenidos muestran el desempeño de dos operaciones: la multiplicación de matrices y la eliminación gaussiana/Gauss-Jordan sobre matrices de diferentes tamaños (100, 300 y 1000), cuantificando el número de operaciones y el tiempo de ejecución, como se muestra en la Tabla 1.\n\n\n\n\n\n\n\n\n\nEn los Gráficos 1 y 2, se aprecia visualmente cómo se ve afectado el número de operaciones y el tiempo de ejecución en relación con el tamaño de la matriz.\nEn cuanto a la multiplicación de matrices, el número de operaciones aumenta significativamente con el tamaño de la matriz, lo cual es de esperarse, ya que se trata de una operación computacionalmente intensiva. El tiempo de ejecución también aumenta proporcionalmente, reflejando el impacto del crecimiento en complejidad.\nPor otro lado, la eliminación gaussiana/Gauss-Jordan muestra una tendencia similar: a mayor tamaño de la matriz, mayor número de operaciones y mayor tiempo de procesamiento. Específicamente, para una matriz de tamaño \\(n = 1000\\), el tiempo fue de 1,071.753 segundos para la multiplicación de matrices y 5.316 segundos para la eliminación gaussiana, destacando una diferencia considerable a favor del segundo método en términos de eficiencia temporal.\nEl rendimiento puede verse influenciado por el hardware utilizado, como la capacidad de memoria, la arquitectura del procesador, y otros componentes del sistema. Estos factores afectan directamente el tiempo de ejecución observado. Entre los elementos que más impactan se incluyen la cantidad y velocidad de la memoria RAM, la arquitectura del procesador, el número de núcleos e hilos de ejecución, la frecuencia de reloj, la memoria caché del procesador, el tipo de almacenamiento, y la tecnología de la GPU si es utilizada (Raina et al., 2009).\n\n\n\n\n\n\nEl impacto de acceder a elementos contiguos en memoria de una matriz es un concepto fundamental en la optimización del rendimiento de programas. Este principio se basa en cómo los datos se almacenan y acceden en la memoria de una computadora.\nCuando los elementos de una matriz se almacenan de manera contigua en la memoria, el procesador puede acceder a ellos de forma más eficiente. Esto se debe a varios factores: el uso de la caché del procesador, el aumento de la localidad espacial, el prefetching, la reducción del consumo de energía y las operaciones vectorizadas.\nLa caché es una memoria de acceso rápido que almacena copias de datos que se utilizan frecuentemente, y cuando los datos están almacenados de manera contigua, es más probable que se carguen en la caché en bloques grandes, reduciendo así el tiempo de acceso.\nLa localidad espacial hace referencia a la tendencia de los programas a acceder a datos que están cerca unos de otros en la memoria. Cuando los datos están almacenados de manera contigua, se mejora la localidad espacial, lo que permite al procesador acceder a los datos de manera más rápida.\nLos procesadores utilizan técnicas de prefetching para anticipar qué datos se necesitarán en el futuro y cargarlos en la caché antes de que sean solicitados. Cuando los datos están almacenados de manera contigua, el prefetching es más efectivo, ya que el procesador puede cargar bloques grandes de datos.\nOtro impacto importante es la reducción del consumo de energía; un mejor uso de la caché y una menor latencia también pueden traducirse en un menor consumo energético.\nEl acceso contiguo a la memoria también puede influir en el rendimiento de las operaciones vectorizadas, que son comunes en aplicaciones científicas y de ingeniería. Las operaciones vectorizadas permiten al procesador realizar múltiples operaciones en paralelo, y cuando los datos están almacenados de manera contigua, es más fácil para el procesador realizarlas de manera eficiente (Bryant, 2016).\n\n\n\nSi utilizáramos matrices dispersas, estas tendrían un impacto en el rendimiento y la eficiencia de un programa, especialmente al trabajar con grandes conjuntos de datos donde la mayoría de los elementos son cero.\nLos cambios al utilizar matrices dispersas incluyen:\n\nReducción del uso de memoria: Las matrices dispersas almacenan solo los elementos no nulos y sus posiciones, lo que reduce significativamente el uso de memoria en comparación con matrices densas.\nOptimización de operaciones: Las operaciones matemáticas pueden ser más eficientes al realizarse únicamente sobre los elementos no nulos, disminuyendo así el tiempo de cómputo.\nUso de bibliotecas especializadas: Se requiere el uso de bibliotecas diseñadas específicamente para manejar matrices dispersas de forma eficiente.\n\nSin embargo, también se presentan algunos costos y desafíos:\n\nMayor complejidad en la implementación: Los algoritmos que manejan matrices dispersas pueden ser más complejos que los que utilizan matrices densas, requiriendo mayor tiempo de desarrollo y depuración.\nMantenimiento e interoperabilidad: La integración con sistemas o bibliotecas que no admiten matrices dispersas puede generar la necesidad de realizar conversiones costosas entre formatos.\nOperaciones costosas: Inserciones y eliminaciones pueden requerir mayor tiempo de procesamiento, debido a la necesidad de actualizar estructuras de índices.\nSobrecarga de gestión de datos: Aunque se reduce el uso de memoria, la administración adicional puede afectar el rendimiento, especialmente si la matriz no es extremadamente dispersa.\nCostos de conversión: Si es necesario convertir entre matrices densas y dispersas, esto puede introducir costos adicionales tanto en tiempo de ejecución como en memoria (Bryant, 2016).\n\n\n\n\n\n\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nStrang, G. (2016). Introduction to Linear Algebra (5ª edición). Wellesley-Cambridge Press.\nGrcar, J. F. (2011). “Mathematicians of Gaussian Elimination.” Notices of the American Mathematical Society, 58(6), 782–792.\nBryant, R. E., & O’Hallaron, D. R. (2016). Computer Systems: A Programmer’s Perspective (3rd ed.). Pearson.\nTeresa-Motiv, Saisang, brittmsantos, eross-msft, & JasonGerend. (2023, 17 de abril). Consideraciones sobre el uso de memoria para la optimización del rendimiento de AD DS.\nRaina, R., Madhavan, A., & Ng, A. Y. (2009). Large-scale Deep Unsupervised Learning using Graphics Processors. Computer Science Department, Stanford University.\n\n\n\n\nSe hicieron mejoras en el planteamiento de los experimentos y en la discusión de los resultados, como fue indicado por el maestro. Ahora cada figura tiene una explicación clara sobre lo que muestra y lo que significa. También se mejoró la redacción para que las ideas sean más comprensibles y ordenadas."
  },
  {
    "objectID": "project2.html#introducción",
    "href": "project2.html#introducción",
    "title": "Proyecto 2",
    "section": "",
    "text": "Los experimentos y análisis de estructuras de datos son fundamentales en la ciencia de datos, ya que permiten evaluar y optimizar el rendimiento de algoritmos y sistemas que manejan grandes volúmenes de información.\nLas estructuras de datos son formas de organizar y almacenar datos en una computadora para que puedan ser accedidos y modificados de manera eficiente. Cada estructura tiene sus propias ventajas y desventajas en términos de tiempo de acceso, uso de memoria y facilidad de implementación. Los experimentos en estructuras de datos suelen centrarse en medir estos aspectos bajo diferentes condiciones para determinar cuál es la más adecuada para una aplicación específica (Goodfellow et al., 2016).\nEl diseño experimental es una etapa esencial que precede al análisis de datos. Un diseño bien planificado asegura que los datos recopilados sean relevantes y útiles para el análisis posterior. Esto incluye la definición de variables, la selección de muestras y la implementación de controles para minimizar sesgos. Estas estructuras son esenciales para el desarrollo de software eficiente, especialmente en campos como el Internet de las Cosas (IoT) y el Big Data, donde la optimización de recursos es crucial (Strang, 2016).\nEl análisis de datos implica varias técnicas estadísticas y computacionales para interpretar los resultados experimentales. Esto puede incluir análisis exploratorio de datos (EDA) para identificar patrones y relaciones, así como análisis confirmatorio para probar hipótesis específicas. Herramientas como Hadoop, Spark, Power BI, Pandas y R son comúnmente utilizadas en este proceso (Grcar, 2011).\nLa multiplicación de matrices es una operación básica que se utiliza en numerosos cálculos matemáticos y algoritmos computacionales. Su relevancia radica en su capacidad para transformar y combinar datos de manera que se puedan extraer insights significativos. La eliminación gaussiana es un método clásico para resolver sistemas de ecuaciones lineales, transformando una matriz en una forma escalonada reducida por filas. Este método es ampliamente utilizado debido a su estabilidad numérica y su capacidad para manejar sistemas grandes.\nEl objetivo es entender cómo se comportan estos algoritmos en diferentes situaciones, especialmente en cuanto al número de operaciones (como multiplicaciones y sumas) y el tiempo que tardan en ejecutarse en la práctica. Para abordar esta cuestión, se plantea un estudio comparativo utilizando matrices aleatorias de tamaño \\(n \\times n\\) para \\(n = 100\\), \\(300\\), \\(1000\\). Este enfoque permitirá evaluar la eficiencia de cada algoritmo y proporcionará una base sólida para futuras optimizaciones. Al comparar estos algoritmos, se busca responder a preguntas clave como: ¿Qué puedes concluir?, ¿Cuál es el impacto de acceder a los elementos contiguos en memoria de una matriz?, ¿Qué cambiarías si utilizas matrices dispersas?, y ¿Cuáles serían los costos?"
  },
  {
    "objectID": "project2.html#desarrollo",
    "href": "project2.html#desarrollo",
    "title": "Proyecto 2",
    "section": "",
    "text": "import numpy as np\nimport time\n\n\n\ndef matrix_multiplication(A, B):\n    n = len(A)  # Tamaño de la matriz (n x n)\n    C = np.zeros((n, n))  # Inicializar la matriz resultante con ceros\n    operations = 0  # Contador de operaciones\n\n    for i in range(n):\n        for j in range(n):\n            for k in range(n):\n                C[i][j] += A[i][k] * B[k][j]  # Multiplicación y suma\n                operations += 2  # Una multiplicación y una suma\n\n    return C, operations\n\n\n\ndef gauss_jordan(A):\n    n = len(A)\n    operations = 0\n    A = np.array(A, dtype=float)\n\n    for i in range(n):\n        if A[i][i] == 0:\n            for j in range(i+1, n):\n                if A[j][i] != 0:\n                    A[[i, j]] = A[[j, i]]  # Intercambio de filas\n                    operations += 1\n                    break\n\n        div = A[i][i]\n        A[i] = A[i] / div\n        operations += n  # n divisiones\n\n        for j in range(n):\n            if i != j:\n                A[j] = A[j] - A[j][i] * A[i]\n                operations += n  # n multiplicaciones y restas\n\n    return A, operations\n\n\n\nsizes = [100, 300, 1000]\nresults = []\n\nfor n in sizes:\n    A = np.random.rand(n, n)\n    B = np.random.rand(n, n)\n\n    # Multiplicación de matrices\n    start_time = time.time()\n    C, mult_operations = matrix_multiplication(A, B)\n    mult_time = time.time() - start_time\n\n    # Eliminación Gaussiana\n    start_time = time.time()\n    _, gauss_operations = gauss_jordan(A)\n    gauss_time = time.time() - start_time\n\n    results.append({\n        'n': n,\n        'mult_operations': mult_operations,\n        'mult_time': mult_time,\n        'gauss_operations': gauss_operations,\n        'gauss_time': gauss_time\n    })\n\n\n\nfor result in results:\n    print(f\"Tamaño de la matriz (n): {result['n']}\")\n    print(\" Multiplicación de Matrices:\")\n    print(f\" Operaciones: {result['mult_operations']}\")\n    print(f\" Tiempo (s): {result['mult_time']:.6f}\")\n    print(\" Eliminación Gaussiana:\")\n    print(f\" Operaciones: {result['gauss_operations']}\")\n    print(f\" Tiempo (s): {result['gauss_time']:.6f}\")\n    print(\"-\" * 40)"
  },
  {
    "objectID": "project2.html#análisis-de-resultados",
    "href": "project2.html#análisis-de-resultados",
    "title": "Proyecto 2",
    "section": "",
    "text": "A continuación se muestra una tabla con los resultados obtenidos al comparar la multiplicación de matrices y la eliminación Gauss-Jordan sobre matrices de distintos tamaños. Se reporta el número total de operaciones y el tiempo de ejecución en segundos.\n\n\n\n\n\n\n\n\n\n\nTamaño (n)\nOperaciones Multiplicación\nTiempo Multiplicación (s)\nOperaciones Gauss\nTiempo Gauss (s)\n\n\n\n\n100\n2,000,000\n1.829321\n1,000,000\n0.066816\n\n\n300\n54,000,000\n30.990801\n27,000,000\n0.399951\n\n\n1000\n2,000,000,000\n1071.753574\n1,000,000,000\n5.316519\n\n\n\n\nNota: La eliminación Gauss-Jordan muestra una notable ventaja en tiempo de ejecución respecto a la multiplicación de matrices, aunque ambas mantienen una proporción consistente en la cantidad de operaciones requeridas.\n\nLos resultados obtenidos muestran el desempeño de dos operaciones: la multiplicación de matrices y la eliminación gaussiana/Gauss-Jordan sobre matrices de diferentes tamaños (100, 300 y 1000), cuantificando el número de operaciones y el tiempo de ejecución, como se muestra en la Tabla 1.\n\n\n\n\n\n\n\n\n\nEn los Gráficos 1 y 2, se aprecia visualmente cómo se ve afectado el número de operaciones y el tiempo de ejecución en relación con el tamaño de la matriz.\nEn cuanto a la multiplicación de matrices, el número de operaciones aumenta significativamente con el tamaño de la matriz, lo cual es de esperarse, ya que se trata de una operación computacionalmente intensiva. El tiempo de ejecución también aumenta proporcionalmente, reflejando el impacto del crecimiento en complejidad.\nPor otro lado, la eliminación gaussiana/Gauss-Jordan muestra una tendencia similar: a mayor tamaño de la matriz, mayor número de operaciones y mayor tiempo de procesamiento. Específicamente, para una matriz de tamaño \\(n = 1000\\), el tiempo fue de 1,071.753 segundos para la multiplicación de matrices y 5.316 segundos para la eliminación gaussiana, destacando una diferencia considerable a favor del segundo método en términos de eficiencia temporal.\nEl rendimiento puede verse influenciado por el hardware utilizado, como la capacidad de memoria, la arquitectura del procesador, y otros componentes del sistema. Estos factores afectan directamente el tiempo de ejecución observado. Entre los elementos que más impactan se incluyen la cantidad y velocidad de la memoria RAM, la arquitectura del procesador, el número de núcleos e hilos de ejecución, la frecuencia de reloj, la memoria caché del procesador, el tipo de almacenamiento, y la tecnología de la GPU si es utilizada (Raina et al., 2009)."
  },
  {
    "objectID": "project2.html#conclusiones",
    "href": "project2.html#conclusiones",
    "title": "Proyecto 2",
    "section": "",
    "text": "El impacto de acceder a elementos contiguos en memoria de una matriz es un concepto fundamental en la optimización del rendimiento de programas. Este principio se basa en cómo los datos se almacenan y acceden en la memoria de una computadora.\nCuando los elementos de una matriz se almacenan de manera contigua en la memoria, el procesador puede acceder a ellos de forma más eficiente. Esto se debe a varios factores: el uso de la caché del procesador, el aumento de la localidad espacial, el prefetching, la reducción del consumo de energía y las operaciones vectorizadas.\nLa caché es una memoria de acceso rápido que almacena copias de datos que se utilizan frecuentemente, y cuando los datos están almacenados de manera contigua, es más probable que se carguen en la caché en bloques grandes, reduciendo así el tiempo de acceso.\nLa localidad espacial hace referencia a la tendencia de los programas a acceder a datos que están cerca unos de otros en la memoria. Cuando los datos están almacenados de manera contigua, se mejora la localidad espacial, lo que permite al procesador acceder a los datos de manera más rápida.\nLos procesadores utilizan técnicas de prefetching para anticipar qué datos se necesitarán en el futuro y cargarlos en la caché antes de que sean solicitados. Cuando los datos están almacenados de manera contigua, el prefetching es más efectivo, ya que el procesador puede cargar bloques grandes de datos.\nOtro impacto importante es la reducción del consumo de energía; un mejor uso de la caché y una menor latencia también pueden traducirse en un menor consumo energético.\nEl acceso contiguo a la memoria también puede influir en el rendimiento de las operaciones vectorizadas, que son comunes en aplicaciones científicas y de ingeniería. Las operaciones vectorizadas permiten al procesador realizar múltiples operaciones en paralelo, y cuando los datos están almacenados de manera contigua, es más fácil para el procesador realizarlas de manera eficiente (Bryant, 2016).\n\n\n\nSi utilizáramos matrices dispersas, estas tendrían un impacto en el rendimiento y la eficiencia de un programa, especialmente al trabajar con grandes conjuntos de datos donde la mayoría de los elementos son cero.\nLos cambios al utilizar matrices dispersas incluyen:\n\nReducción del uso de memoria: Las matrices dispersas almacenan solo los elementos no nulos y sus posiciones, lo que reduce significativamente el uso de memoria en comparación con matrices densas.\nOptimización de operaciones: Las operaciones matemáticas pueden ser más eficientes al realizarse únicamente sobre los elementos no nulos, disminuyendo así el tiempo de cómputo.\nUso de bibliotecas especializadas: Se requiere el uso de bibliotecas diseñadas específicamente para manejar matrices dispersas de forma eficiente.\n\nSin embargo, también se presentan algunos costos y desafíos:\n\nMayor complejidad en la implementación: Los algoritmos que manejan matrices dispersas pueden ser más complejos que los que utilizan matrices densas, requiriendo mayor tiempo de desarrollo y depuración.\nMantenimiento e interoperabilidad: La integración con sistemas o bibliotecas que no admiten matrices dispersas puede generar la necesidad de realizar conversiones costosas entre formatos.\nOperaciones costosas: Inserciones y eliminaciones pueden requerir mayor tiempo de procesamiento, debido a la necesidad de actualizar estructuras de índices.\nSobrecarga de gestión de datos: Aunque se reduce el uso de memoria, la administración adicional puede afectar el rendimiento, especialmente si la matriz no es extremadamente dispersa.\nCostos de conversión: Si es necesario convertir entre matrices densas y dispersas, esto puede introducir costos adicionales tanto en tiempo de ejecución como en memoria (Bryant, 2016)."
  },
  {
    "objectID": "project2.html#referencias",
    "href": "project2.html#referencias",
    "title": "Proyecto 2",
    "section": "",
    "text": "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nStrang, G. (2016). Introduction to Linear Algebra (5ª edición). Wellesley-Cambridge Press.\nGrcar, J. F. (2011). “Mathematicians of Gaussian Elimination.” Notices of the American Mathematical Society, 58(6), 782–792.\nBryant, R. E., & O’Hallaron, D. R. (2016). Computer Systems: A Programmer’s Perspective (3rd ed.). Pearson.\nTeresa-Motiv, Saisang, brittmsantos, eross-msft, & JasonGerend. (2023, 17 de abril). Consideraciones sobre el uso de memoria para la optimización del rendimiento de AD DS.\nRaina, R., Madhavan, A., & Ng, A. Y. (2009). Large-scale Deep Unsupervised Learning using Graphics Processors. Computer Science Department, Stanford University."
  },
  {
    "objectID": "project2.html#cambios-realizados",
    "href": "project2.html#cambios-realizados",
    "title": "Proyecto 2",
    "section": "",
    "text": "Se hicieron mejoras en el planteamiento de los experimentos y en la discusión de los resultados, como fue indicado por el maestro. Ahora cada figura tiene una explicación clara sobre lo que muestra y lo que significa. También se mejoró la redacción para que las ideas sean más comprensibles y ordenadas."
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "Proyecto 4",
    "section": "",
    "text": "En la ciencia de la computación, los algoritmos de búsqueda son esenciales para optimizar la eficiencia en la gestión y recuperación de datos. Estos algoritmos permiten localizar elementos específicos dentro de una colección de datos, optimizando el tiempo y los recursos necesarios para dicha tarea. Este informe se centra en la implementación y comparación de varios algoritmos de búsqueda por comparación, con el objetivo de evaluar su rendimiento en cuanto al número de comparaciones y el tiempo de ejecución (Cormen et al., 2009).\nLos algoritmos de búsqueda por comparación se basan en la comparación de elementos para encontrar el objetivo deseado. Entre los algoritmos más conocidos se encuentran la búsqueda binaria, la búsqueda secuencial y variantes de búsquedas no acotadas. Su comportamiento depende de la estructura de datos utilizada y de las condiciones de búsqueda (Knuth, 1998).\nLa búsqueda binaria acotada es una técnica eficiente para encontrar un elemento en un conjunto de datos ordenado. Este algoritmo divide repetidamente el conjunto de datos a la mitad, comparando el elemento objetivo con el elemento central del subconjunto actual. Si el elemento central es igual al objetivo, la búsqueda termina. Si es mayor o menor, la búsqueda continúa en la mitad inferior o superior, respectivamente. Esta técnica es altamente eficiente en conjuntos de datos ordenados, reduciendo significativamente el número de comparaciones necesarias (Cormen et al., 2009).\nLa búsqueda secuencial, también conocida como búsqueda lineal, es un método simple y directo para encontrar un elemento en un conjunto de datos. El algoritmo recorre cada elemento del conjunto en orden secuencial, comparando cada uno con el elemento objetivo hasta encontrarlo o llegar al final. Aunque es menos eficiente que la búsqueda binaria en conjuntos ordenados, su aplicabilidad se extiende a cualquier tipo de conjunto, ordenado o no. Las variantes de búsqueda no acotada, como B1 y B2, extienden este concepto para manejar conjuntos de datos cuyo tamaño es desconocido o cambia constantemente (Sedgewick, 2011).\nLas SkipLists son estructuras de datos probabilísticas que permiten búsquedas eficientes en conjuntos de datos ordenados. A diferencia de las listas enlazadas tradicionales, las SkipLists utilizan múltiples niveles de enlaces para acelerar el proceso de búsqueda. Esta estructura ofrece eficiencia en búsquedas sobre conjuntos ordenados y una mayor flexibilidad. Sin embargo, su desventaja radica en el uso adicional de memoria debido a los múltiples niveles de enlaces (Knuth, 1998).\nEn este trabajo se implementaron y compararon cuatro algoritmos de búsqueda: búsqueda binaria acotada, búsqueda secuencial y dos variantes de búsqueda no acotada (B1 y B2), además de la estructura de datos SkipList, con el fin de evaluar su eficiencia en términos de número de comparaciones y tiempo de ejecución. Utilizando conjuntos de datos y consultas específicas, se midió el rendimiento de cada método, registrando los resultados para cada combinación de archivos. Los resultados se visualizaron mediante gráficos y tablas, destacando las ventajas y desventajas de cada enfoque.\nSe concluye que la elección del método de búsqueda depende del contexto de aplicación. Este análisis proporciona una guía útil para seleccionar el método más adecuado según los requerimientos específicos de rendimiento y aplicabilidad práctica.\n\n\n\n\n\n# Bibliotecas\nimport os\nimport json\nimport time\nimport bisect\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Callable\n\n# Ruta base donde se encuentran los archivos JSON\nruta_archivos = r\"C:\\Users\\Antonio Martínez\\Desktop\\listas-posteo-con-perturbaciones\"\n\n# Archivos que contienen las listas de posteo (perturbadas)\nlistas_archivos = [\n    \"listas-posteo-con-perturbaciones-p=016.json\",\n    \"listas-posteo-con-perturbaciones-p=032.json\",\n    \"listas-posteo-con-perturbaciones-p=064.json\",\n    \"listas-posteo-con-perturbaciones-p=128.json\",\n    \"listas-posteo-con-perturbaciones-p=256.json\",\n    \"listas-posteo-con-perturbaciones-p=512.json\",\n]\n\n# Archivos que contienen las consultas\nconsultas_archivos = [\n    \"consultas-1-listas-posteo.json\",\n    \"consultas-2-listas-posteo.json\",\n    \"consultas-3-listas-posteo.json\",\n    \"consultas-4-listas-posteo.json\",\n]\n\n# Función para cargar listas o diccionarios con listas desde archivo JSON\ndef cargar_lista_filtrada(path):\n    try:\n        with open(path) as f:\n            datos = json.load(f)\n        if isinstance(datos, dict):\n            combinados = []\n            for v in datos.values():\n                if isinstance(v, list):\n                    combinados.extend(int(x) for x in v if isinstance(x, int) or (isinstance(x, str) and x.isdigit()))\n            return sorted(combinados)\n        elif isinstance(datos, list):\n            return sorted([int(x) for x in datos if isinstance(x, int) or (isinstance(x, str) and x.isdigit())])\n        else:\n            return []\n    except Exception as e:\n        print(f\"Error al leer {path}: {e}\")\n        return []\n\n\n\n# Búsqueda secuencial\ndef sequential_search_B0(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = 0\n    for i, item in enumerate(lst):\n        comparisons += 1\n        if x &lt;= item:\n            return i, comparisons\n    return len(lst), comparisons\n\n# Búsqueda binaria clásica\ndef binary_search(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = 0\n    left, right = 0, len(lst)\n    while left &lt; right:\n        mid = (left + right) // 2\n        comparisons += 1\n        if x &lt;= lst[mid]:\n            right = mid\n        else:\n            left = mid + 1\n    return left, comparisons\n\n# Búsqueda no acotada B1: dobla el límite exponencialmente\ndef unbounded_search_B1(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = 0\n    n = len(lst)\n    if n == 0:\n        return 0, comparisons\n    bound = 1\n    while bound &lt; n and lst[bound] &lt; x:\n        comparisons += 1\n        bound *= 2\n    left = bound // 2\n    right = min(bound, n)\n    while left &lt; right:\n        mid = (left + right) // 2\n        comparisons += 1\n        if x &lt;= lst[mid]:\n            right = mid\n        else:\n            left = mid + 1\n    return left, comparisons\n\n# Búsqueda no acotada B2: misma implementación que B1\ndef unbounded_search_B2(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    return unbounded_search_B1(lst, x)\n\n# Búsqueda tipo SkipList (uso de bisect)\ndef skiplist_search(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = int.bit_length(len(lst)) if len(lst) &gt; 0 else 0\n    pos = bisect.bisect_left(lst, x)\n    return pos, comparisons\n\n# Lista de algoritmos y sus funciones\nalgorithms: List[Tuple[str, Callable[[List[int], int], Tuple[int, int]]]] = [\n    (\"B0\", sequential_search_B0),\n    (\"Binaria\", binary_search),\n    (\"B1\", unbounded_search_B1),\n    (\"B2\", unbounded_search_B2),\n    (\"SkipList\", skiplist_search),\n]\n\n\n\nprint(\"\\nVerificando contenido de archivos JSON...\\n\")\n\nposting_lists = [cargar_lista_filtrada(os.path.join(ruta_archivos, f)) for f in listas_archivos]\nquery_sets = [cargar_lista_filtrada(os.path.join(ruta_archivos, f)) for f in consultas_archivos]\n\nfor f, lst in zip(listas_archivos, posting_lists):\n    print(f\"{f} → {len(lst)} elementos\")\nfor f, q in zip(consultas_archivos, query_sets):\n    print(f\"{f} → {len(q)} consultas\")\n\nresults = []\n\nfor list_name, plist in zip(listas_archivos, posting_lists):\n    for query_name, queries in zip(consultas_archivos, query_sets):\n        for alg_name, alg_func in algorithms:\n            if not plist or not queries:\n                results.append({\n                    \"Lista\": list_name,\n                    \"Consulta\": query_name,\n                    \"Algoritmo\": alg_name,\n                    \"Comparaciones\": 0,\n                    \"Tiempo\": 0.0\n                })\n                continue\n            total_comparisons = 0\n            start = time.perf_counter()\n            for q in queries:\n                _, comps = alg_func(plist, q)\n                total_comparisons += comps\n            end = time.perf_counter()\n            results.append({\n                \"Lista\": list_name,\n                \"Consulta\": query_name,\n                \"Algoritmo\": alg_name,\n                \"Comparaciones\": total_comparisons,\n                \"Tiempo\": round(end - start, 6)\n            })\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"resultados_busqueda.csv\", index=False)\n\n\n\nif df[\"Comparaciones\"].sum() &gt; 0:\n\n    plt.figure(figsize=(14, 6))\n    sns.barplot(data=df, x=\"Algoritmo\", y=\"Comparaciones\", hue=\"Lista\", errorbar=None)\n    plt.yscale(\"log\")\n    plt.title(\"Comparaciones por Algoritmo y Lista (escala logarítmica)\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    plt.figure(figsize=(14, 6))\n    sns.barplot(data=df, x=\"Algoritmo\", y=\"Tiempo\", hue=\"Lista\", errorbar=None)\n    plt.yscale(\"log\")\n    plt.title(\"Tiempo por Algoritmo y Lista (escala logarítmica)\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    for consulta in df[\"Consulta\"].unique():\n        subset = df[df[\"Consulta\"] == consulta]\n\n        plt.figure(figsize=(14, 6))\n        sns.barplot(data=subset, x=\"Algoritmo\", y=\"Comparaciones\", hue=\"Lista\", errorbar=None)\n        plt.yscale(\"log\")\n        plt.title(f\"Comparaciones por Algoritmo (Consulta: {consulta})\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n        plt.figure(figsize=(14, 6))\n        sns.barplot(data=subset, x=\"Algoritmo\", y=\"Tiempo\", hue=\"Lista\", errorbar=None)\n        plt.yscale(\"log\")\n        plt.title(f\"Tiempo por Algoritmo (Consulta: {consulta})\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n    promedios_consulta = df.groupby([\"Consulta\", \"Algoritmo\"], as_index=False)[[\"Comparaciones\", \"Tiempo\"]].mean()\n    display(promedios_consulta)\n    promedios_consulta.to_csv(\"promedios_por_consulta.csv\", index=False)\nelse:\n    print(\"No se registraron comparaciones. Verifica el contenido de tus archivos.\")\n\n\n\n\n\n\n\n\n\nEn el gráfico se observa el número de comparaciones promedio realizadas por cada algoritmo al ejecutar la consulta consultas-1-listas-posteo.json sobre distintas listas de posteo con perturbaciones. Se evidencia claramente que el algoritmo B0 (búsqueda secuencial) es extremadamente ineficiente, realizando más de 3 millones de comparaciones en todos los casos. Esta ineficiencia se mantiene constante independientemente del nivel de perturbación, lo cual refleja su incapacidad de adaptarse a estructuras parcialmente ordenadas. Por otro lado, los algoritmos Binaria, B1 y B2 muestran un comportamiento mucho más eficiente, con un número de comparaciones considerablemente menor (del orden de cientos de miles o menos), además de una gran estabilidad frente a las distintas listas perturbadas. El algoritmo SkipList, aunque ligeramente más constante en su conteo (180,000 en promedio), mantiene un rendimiento intermedio en términos de comparaciones, destacándose por su regularidad.\n\n\n\nEn el gráfico también se presenta el tiempo promedio de ejecución por algoritmo bajo el mismo escenario. Nuevamente, B0 muestra un tiempo elevado, aunque menos extremo que su número de comparaciones, lo que puede deberse a la simplicidad de su implementación. En cambio, Binaria refleja tiempos de ejecución más altos en relación con B1 y B2, pese a que las comparaciones eran similares o incluso menores, lo cual sugiere que la sobrecarga de su implementación o la forma en que accede a los datos puede afectar su eficiencia temporal. En cuanto a B1 y B2, ambos logran tiempos bajos y bastante consistentes, consolidándose como las alternativas más eficientes tanto en comparaciones como en tiempo. Finalmente, SkipList, aunque no es el más veloz, sí mantiene un tiempo de ejecución muy competitivo y constante, reafirmando su ventaja en estabilidad de desempeño.\n\n\n\n\n\n\nEn el gráfico de comparaciones correspondiente a la consulta consultas-2-listas-posteo.json, se observa que el algoritmo B0 sigue siendo el menos eficiente, superando los 5 millones de comparaciones en todos los casos. Este comportamiento se mantiene constante sin importar el nivel de perturbación en las listas, lo cual evidencia que la búsqueda secuencial no aprovecha el orden parcial de los datos. Por otro lado, los algoritmos Binaria, B1 y B2 presentan un rendimiento mucho más eficiente, con un número de comparaciones cercano a los 170,000, y una variación mínima entre las distintas listas perturbadas. SkipList también muestra un comportamiento constante y predecible, con 180,000 comparaciones en promedio, lo que refuerza su estabilidad.\n\n\n\nRespecto al gráfico de tiempo, nuevamente se observa que B0 tiene un tiempo de ejecución considerablemente superior al del resto de los algoritmos. Binaria mejora notablemente frente a B0, aunque sigue siendo superada por B1, B2 y SkipList en términos de rapidez. B1 y B2 obtienen los tiempos más bajos, cercanos a 1 × 10⁻² segundos, y se comportan de manera uniforme frente a distintas listas. SkipList, por su parte, mantiene los tiempos más reducidos, alrededor de 6 × 10⁻³ segundos, lo cual refuerza su eficiencia y lo posiciona como una alternativa sólida frente a perturbaciones en los datos.\n\n\n\n\n\n\nEl gráfico de comparaciones corresponde a la ejecución de la consulta consultas-3-listas-posteo.json sobre distintas listas de posteo con perturbaciones. En él se observa que el algoritmo B0 vuelve a mostrar un rendimiento extremadamente pobre, realizando más de 10⁸ comparaciones de forma constante, independientemente del nivel de perturbación en los datos. Esto refuerza su incapacidad de aprovechar cualquier tipo de orden o estructura parcial. Por otro lado, los algoritmos Binaria, B1 y B2 presentan un comportamiento mucho más eficiente y estable, con comparaciones en el orden de 2.5 × 10⁵ aproximadamente, sin verse afectados por las variaciones en las listas. SkipList también mantiene su consistencia, con un promedio de 180,000 comparaciones en todos los casos.\n\n\n\nEn cuanto al gráfico de tiempos, también asociado a la consulta consultas-3-listas-posteo.json, B0 registra los valores más altos, superando los 7 segundos para cada lista analizada. Aunque Binaria mejora considerablemente frente a B0, sus tiempos siguen siendo más elevados que los de B1 y B2, los cuales se mantienen en torno a los 0.03 segundos, con gran estabilidad entre listas. SkipList se destaca nuevamente como el algoritmo más rápido, con tiempos cercanos a los 0.007 segundos, consolidando su eficiencia tanto en tiempo como en número de comparaciones.\n\n\n\n\n\n\nEn el gráfico de comparaciones para la consulta consultas-4-listas-posteo.json, el algoritmo B0 vuelve a mostrar un rendimiento extremadamente ineficiente, superando los 9.8 × 10⁸ comparaciones en todos los casos, lo cual lo convierte en el peor evaluado sin importar el nivel de perturbación en las listas. Su comportamiento completamente lineal y sin capacidad de aprovechar el orden lo vuelve inviable para estructuras parcialmente ordenadas. Por el contrario, los algoritmos Binaria, B1 y B2 mantienen un número de comparaciones muy bajo y estable, con valores cercanos a 170,000 y 320,000 dependiendo de la técnica empleada, lo cual demuestra su eficiencia y adaptabilidad. El algoritmo SkipList, nuevamente, se mantiene firme con aproximadamente 180,000 comparaciones, reflejando un buen balance entre consistencia y rendimiento.\n\n\n\nEn el gráfico de tiempo para la misma consulta, B0 también presenta un tiempo de ejecución excesivo, cercano a los 96.8 segundos, lo que reafirma su ineficiencia total. Binaria mejora sustancialmente en comparación, con tiempos en torno a los 0.03 segundos, pero aún se ve superada por B1 y B2, que se ejecutan en alrededor de 0.045 segundos con mucha regularidad. SkipList destaca nuevamente con el mejor tiempo de todos, alrededor de 0.008 segundos, confirmando su capacidad de mantener bajo el tiempo de respuesta incluso frente a altos niveles de perturbación.\n\n\n\n\n\n\nEl gráfico de comparaciones evidencia que el algoritmo B0 es, con diferencia, el menos eficiente frente a todos los niveles de perturbación. En todos los casos, supera consistentemente las 10⁷ comparaciones, lo que demuestra su incapacidad para aprovechar el orden parcial en las listas de posteo. Esta falta de adaptabilidad lo hace inadecuado incluso cuando las perturbaciones son mínimas. Por el contrario, los algoritmos Binaria, B1, B2 y SkipList mantienen un comportamiento muy estable, con comparaciones que oscilan entre 10⁵ y 10⁶, sin mostrar una sensibilidad significativa al aumento de perturbación en los datos. Esto refleja que estos métodos sí aprovechan la estructura de las listas, independientemente del nivel de desorden.\n\n\n\nEn el gráfico de tiempo, B0 nuevamente destaca por su alto costo computacional, con tiempos superiores a 10⁰ segundos, muy por encima del resto. Aunque Binaria mejora en eficiencia temporal, sigue siendo superada por B1, B2 y SkipList, que muestran tiempos por debajo de 10⁻² segundos. Este patrón se mantiene estable a lo largo de todas las listas evaluadas, lo cual indica que estos tres algoritmos no solo son más rápidos, sino también más consistentes y escalables cuando se enfrentan a datos perturbados. En particular, SkipList sobresale por mantener los tiempos más bajos del conjunto, reafirmando su eficiencia general.\n\n\n\n\n\n\n\n\n\n\n\nConsulta\nAlgoritmo\nComparaciones\nTiempo\n\n\n\n\nconsultas-1-listas-posteo.json\nB0\n295284.0\n0.021119 s\n\n\nconsultas-1-listas-posteo.json\nB1\n85296.0\n0.014033 s\n\n\nconsultas-1-listas-posteo.json\nB2\n85296.0\n0.013316 s\n\n\nconsultas-1-listas-posteo.json\nBinaria\n176297.0\n0.025725 s\n\n\nconsultas-1-listas-posteo.json\nSkipList\n180000.0\n0.006500 s\n\n\nconsultas-2-listas-posteo.json\nB0\n5035401.0\n0.389143 s\n\n\nconsultas-2-listas-posteo.json\nB1\n169318.0\n0.022207 s\n\n\nconsultas-2-listas-posteo.json\nB2\n169318.0\n0.022952 s\n\n\nconsultas-2-listas-posteo.json\nBinaria\n176827.0\n0.025777 s\n\n\nconsultas-2-listas-posteo.json\nSkipList\n180000.0\n0.006478 s\n\n\nconsultas-3-listas-posteo.json\nB0\n75757269.0\n7.030850 s\n\n\nconsultas-3-listas-posteo.json\nB1\n248473.0\n0.033025 s\n\n\nconsultas-3-listas-posteo.json\nB2\n248473.0\n0.034482 s\n\n\nconsultas-3-listas-posteo.json\nBinaria\n176385.0\n0.028948 s\n\n\nconsultas-3-listas-posteo.json\nSkipList\n180000.0\n0.007197 s\n\n\nconsultas-4-listas-posteo.json\nB0\n988162924.0\n96.788158 s\n\n\nconsultas-4-listas-posteo.json\nB1\n320738.0\n0.044221 s\n\n\nconsultas-4-listas-posteo.json\nB2\n320738.0\n0.045158 s\n\n\nconsultas-4-listas-posteo.json\nBinaria\n176355.0\n0.032268 s\n\n\nconsultas-4-listas-posteo.json\nSkipList\n180000.0\n0.008281 s\n\n\n\nLos resultados muestran que el algoritmo B0 es consistentemente el menos eficiente, con un pico de casi mil millones de comparaciones y más de 96 segundos de ejecución en la consulta consultas-4-listas-posteo.json. En contraste, B1 y B2 se mantienen como las opciones más equilibradas, con pocas comparaciones (alrededor de 85,000 a 320,000) y tiempos bajos, siempre por debajo de 0.05 segundos.\nBinaria presenta un buen número de comparaciones, cercano a 176,000 en promedio, pero sus tiempos son ligeramente mayores que los de B1 y B2. Por su parte, SkipList destaca por su estabilidad: siempre tiene 180,000 comparaciones y logra los mejores tiempos, entre 0.006 y 0.008 segundos, lo que lo convierte en una opción muy eficiente y constante.\nEl algoritmo B0 tuvo el peor rendimiento en todas las consultas. Su enfoque secuencial genera una enorme cantidad de comparaciones, ya que recorre toda la lista hasta encontrar la posición de inserción. No aprovecha el orden de los datos, lo que explica los tiempos altos y el crecimiento descontrolado en consultas con listas grandes o muy perturbadas.\nEl algoritmo Binaria fue más eficiente que B0 en comparaciones, gracias a su capacidad de dividir el espacio de búsqueda. Sin embargo, sus tiempos fueron ligeramente más altos que los de B1 y B2. Esto se debe posiblemente a una mayor cantidad de operaciones internas, como el manejo de los índices y los saltos de control.\nLos algoritmos B1 y B2, variantes de búsqueda no acotada, lograron un equilibrio ideal entre comparaciones y tiempo. Su estrategia de expansión exponencial permite reducir rápidamente el intervalo de búsqueda sin recorrer toda la lista, lo que explica su excelente rendimiento en listas grandes o parcialmente ordenadas.\nEl algoritmo SkipList mostró una gran regularidad: siempre hizo la misma cantidad de comparaciones y logró los tiempos más bajos. Esto se debe a su estructura multinivel que, aunque no ajusta dinámicamente su comportamiento, permite accesos rápidos similares a los de la búsqueda binaria, con una sobrecarga mínima.\nEn general, cada algoritmo respondió según su diseño. Los que explotan el orden de los datos (Binaria, B1, B2, SkipList) fueron mucho más eficientes que B0. Esto confirma que la eficiencia no solo depende del tipo de algoritmo, sino también de su capacidad de adaptarse a la estructura de los datos.\n\n\n\n\n\nUna de las principales conclusiones del análisis es que el algoritmo B0, basado en búsqueda secuencial, resulta completamente ineficiente para conjuntos de datos ordenados, especialmente cuando se introducen perturbaciones. Su número de comparaciones crece desproporcionadamente y sus tiempos de ejecución son inaceptables incluso en consultas de tamaño moderado, lo que lo descarta como una opción viable en contextos prácticos donde se requiere rendimiento.\nPor otro lado, los algoritmos B1 y B2 demostraron ser las estrategias más equilibradas. No solo mantienen un número reducido de comparaciones en todos los escenarios, sino que además ofrecen tiempos de ejecución muy bajos y constantes, independientemente del tamaño o perturbación de las listas. Esta combinación de eficiencia y estabilidad los convierte en una excelente alternativa cuando se trabaja con datos parcialmente ordenados o de tamaño variable.\nLa búsqueda binaria acotada, aunque conceptualmente eficiente, mostró tiempos de ejecución ligeramente mayores en comparación con B1 y B2. Esto sugiere que, aunque reduce el número de comparaciones, su implementación o la estructura de acceso a los datos podría estar introduciendo una sobrecarga adicional, lo cual debe ser considerado dependiendo del contexto de aplicación.\nSkipList se posiciona como una opción altamente competitiva. Aunque su número de comparaciones se mantiene fijo en 180,000, su gran ventaja radica en sus tiempos de ejecución, que son consistentemente los más bajos de todos los algoritmos evaluados. Esta característica lo convierte en una herramienta valiosa para escenarios en los que el tiempo de respuesta es crítico.\nFinalmente, este estudio confirma que la elección del algoritmo de búsqueda debe estar guiada por el tipo de datos, su orden relativo, y los requisitos de rendimiento. En ambientes dinámicos o con estructuras parcialmente ordenadas, es preferible optar por B1, B2 o SkipList. En cambio, algoritmos como B0 deben evitarse salvo en situaciones controladas con conjuntos pequeños y sin requisitos de eficiencia.\n\n\n\n\nCormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms (3rd ed.).\nSedgewick, R., & Wayne, K. (2011). Algorithms (4th ed.).\nKnuth, D. E. (1998). The Art of Computer Programming, Volume 3: Sorting and Searching (2nd ed.).\nWeiss, M. A. (2014). Data Structures and Algorithm Analysis in C (3rd ed.). Pearson.\n\n\n\n\nEn atención a la retroalimentación recibida, se realizó una revisión profunda del enfoque adoptado en la implementación de los algoritmos de búsqueda por comparación. A continuación se detallan los ajustes conceptuales y técnicos aplicados:\n\nSe reconoció que el uso de listas de posteo con perturbaciones generó una interpretación errónea del problema, llevando a implementar algoritmos basados únicamente en igualdad, cuando el problema central requería considerar comparaciones con operadores &lt; o &lt;= para determinar la posición de inserción.\nSe reformularon los algoritmos de búsqueda secuencial y binaria considerando adecuadamente la semántica del problema, que implica la ubicación correcta en listas ordenadas, no la coincidencia exacta.\nSe revisaron las notas del curso y el artículo de Baeza-Yates (B&Y), lo que permitió entender con mayor claridad el modelo de comparación y sus implicaciones para el diseño e interpretación correcta de los algoritmos.\nSe corrigieron errores lógicos en las funciones de búsqueda y se realizaron pruebas con datos estructurados correctamente, evitando distorsiones generadas por entradas mal definidas."
  },
  {
    "objectID": "project4.html#introducción",
    "href": "project4.html#introducción",
    "title": "Proyecto 4",
    "section": "",
    "text": "En la ciencia de la computación, los algoritmos de búsqueda son esenciales para optimizar la eficiencia en la gestión y recuperación de datos. Estos algoritmos permiten localizar elementos específicos dentro de una colección de datos, optimizando el tiempo y los recursos necesarios para dicha tarea. Este informe se centra en la implementación y comparación de varios algoritmos de búsqueda por comparación, con el objetivo de evaluar su rendimiento en cuanto al número de comparaciones y el tiempo de ejecución (Cormen et al., 2009).\nLos algoritmos de búsqueda por comparación se basan en la comparación de elementos para encontrar el objetivo deseado. Entre los algoritmos más conocidos se encuentran la búsqueda binaria, la búsqueda secuencial y variantes de búsquedas no acotadas. Su comportamiento depende de la estructura de datos utilizada y de las condiciones de búsqueda (Knuth, 1998).\nLa búsqueda binaria acotada es una técnica eficiente para encontrar un elemento en un conjunto de datos ordenado. Este algoritmo divide repetidamente el conjunto de datos a la mitad, comparando el elemento objetivo con el elemento central del subconjunto actual. Si el elemento central es igual al objetivo, la búsqueda termina. Si es mayor o menor, la búsqueda continúa en la mitad inferior o superior, respectivamente. Esta técnica es altamente eficiente en conjuntos de datos ordenados, reduciendo significativamente el número de comparaciones necesarias (Cormen et al., 2009).\nLa búsqueda secuencial, también conocida como búsqueda lineal, es un método simple y directo para encontrar un elemento en un conjunto de datos. El algoritmo recorre cada elemento del conjunto en orden secuencial, comparando cada uno con el elemento objetivo hasta encontrarlo o llegar al final. Aunque es menos eficiente que la búsqueda binaria en conjuntos ordenados, su aplicabilidad se extiende a cualquier tipo de conjunto, ordenado o no. Las variantes de búsqueda no acotada, como B1 y B2, extienden este concepto para manejar conjuntos de datos cuyo tamaño es desconocido o cambia constantemente (Sedgewick, 2011).\nLas SkipLists son estructuras de datos probabilísticas que permiten búsquedas eficientes en conjuntos de datos ordenados. A diferencia de las listas enlazadas tradicionales, las SkipLists utilizan múltiples niveles de enlaces para acelerar el proceso de búsqueda. Esta estructura ofrece eficiencia en búsquedas sobre conjuntos ordenados y una mayor flexibilidad. Sin embargo, su desventaja radica en el uso adicional de memoria debido a los múltiples niveles de enlaces (Knuth, 1998).\nEn este trabajo se implementaron y compararon cuatro algoritmos de búsqueda: búsqueda binaria acotada, búsqueda secuencial y dos variantes de búsqueda no acotada (B1 y B2), además de la estructura de datos SkipList, con el fin de evaluar su eficiencia en términos de número de comparaciones y tiempo de ejecución. Utilizando conjuntos de datos y consultas específicas, se midió el rendimiento de cada método, registrando los resultados para cada combinación de archivos. Los resultados se visualizaron mediante gráficos y tablas, destacando las ventajas y desventajas de cada enfoque.\nSe concluye que la elección del método de búsqueda depende del contexto de aplicación. Este análisis proporciona una guía útil para seleccionar el método más adecuado según los requerimientos específicos de rendimiento y aplicabilidad práctica."
  },
  {
    "objectID": "project4.html#desarrollo",
    "href": "project4.html#desarrollo",
    "title": "Proyecto 4",
    "section": "",
    "text": "# Bibliotecas\nimport os\nimport json\nimport time\nimport bisect\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Callable\n\n# Ruta base donde se encuentran los archivos JSON\nruta_archivos = r\"C:\\Users\\Antonio Martínez\\Desktop\\listas-posteo-con-perturbaciones\"\n\n# Archivos que contienen las listas de posteo (perturbadas)\nlistas_archivos = [\n    \"listas-posteo-con-perturbaciones-p=016.json\",\n    \"listas-posteo-con-perturbaciones-p=032.json\",\n    \"listas-posteo-con-perturbaciones-p=064.json\",\n    \"listas-posteo-con-perturbaciones-p=128.json\",\n    \"listas-posteo-con-perturbaciones-p=256.json\",\n    \"listas-posteo-con-perturbaciones-p=512.json\",\n]\n\n# Archivos que contienen las consultas\nconsultas_archivos = [\n    \"consultas-1-listas-posteo.json\",\n    \"consultas-2-listas-posteo.json\",\n    \"consultas-3-listas-posteo.json\",\n    \"consultas-4-listas-posteo.json\",\n]\n\n# Función para cargar listas o diccionarios con listas desde archivo JSON\ndef cargar_lista_filtrada(path):\n    try:\n        with open(path) as f:\n            datos = json.load(f)\n        if isinstance(datos, dict):\n            combinados = []\n            for v in datos.values():\n                if isinstance(v, list):\n                    combinados.extend(int(x) for x in v if isinstance(x, int) or (isinstance(x, str) and x.isdigit()))\n            return sorted(combinados)\n        elif isinstance(datos, list):\n            return sorted([int(x) for x in datos if isinstance(x, int) or (isinstance(x, str) and x.isdigit())])\n        else:\n            return []\n    except Exception as e:\n        print(f\"Error al leer {path}: {e}\")\n        return []\n\n\n\n# Búsqueda secuencial\ndef sequential_search_B0(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = 0\n    for i, item in enumerate(lst):\n        comparisons += 1\n        if x &lt;= item:\n            return i, comparisons\n    return len(lst), comparisons\n\n# Búsqueda binaria clásica\ndef binary_search(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = 0\n    left, right = 0, len(lst)\n    while left &lt; right:\n        mid = (left + right) // 2\n        comparisons += 1\n        if x &lt;= lst[mid]:\n            right = mid\n        else:\n            left = mid + 1\n    return left, comparisons\n\n# Búsqueda no acotada B1: dobla el límite exponencialmente\ndef unbounded_search_B1(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = 0\n    n = len(lst)\n    if n == 0:\n        return 0, comparisons\n    bound = 1\n    while bound &lt; n and lst[bound] &lt; x:\n        comparisons += 1\n        bound *= 2\n    left = bound // 2\n    right = min(bound, n)\n    while left &lt; right:\n        mid = (left + right) // 2\n        comparisons += 1\n        if x &lt;= lst[mid]:\n            right = mid\n        else:\n            left = mid + 1\n    return left, comparisons\n\n# Búsqueda no acotada B2: misma implementación que B1\ndef unbounded_search_B2(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    return unbounded_search_B1(lst, x)\n\n# Búsqueda tipo SkipList (uso de bisect)\ndef skiplist_search(lst: List[int], x: int) -&gt; Tuple[int, int]:\n    comparisons = int.bit_length(len(lst)) if len(lst) &gt; 0 else 0\n    pos = bisect.bisect_left(lst, x)\n    return pos, comparisons\n\n# Lista de algoritmos y sus funciones\nalgorithms: List[Tuple[str, Callable[[List[int], int], Tuple[int, int]]]] = [\n    (\"B0\", sequential_search_B0),\n    (\"Binaria\", binary_search),\n    (\"B1\", unbounded_search_B1),\n    (\"B2\", unbounded_search_B2),\n    (\"SkipList\", skiplist_search),\n]\n\n\n\nprint(\"\\nVerificando contenido de archivos JSON...\\n\")\n\nposting_lists = [cargar_lista_filtrada(os.path.join(ruta_archivos, f)) for f in listas_archivos]\nquery_sets = [cargar_lista_filtrada(os.path.join(ruta_archivos, f)) for f in consultas_archivos]\n\nfor f, lst in zip(listas_archivos, posting_lists):\n    print(f\"{f} → {len(lst)} elementos\")\nfor f, q in zip(consultas_archivos, query_sets):\n    print(f\"{f} → {len(q)} consultas\")\n\nresults = []\n\nfor list_name, plist in zip(listas_archivos, posting_lists):\n    for query_name, queries in zip(consultas_archivos, query_sets):\n        for alg_name, alg_func in algorithms:\n            if not plist or not queries:\n                results.append({\n                    \"Lista\": list_name,\n                    \"Consulta\": query_name,\n                    \"Algoritmo\": alg_name,\n                    \"Comparaciones\": 0,\n                    \"Tiempo\": 0.0\n                })\n                continue\n            total_comparisons = 0\n            start = time.perf_counter()\n            for q in queries:\n                _, comps = alg_func(plist, q)\n                total_comparisons += comps\n            end = time.perf_counter()\n            results.append({\n                \"Lista\": list_name,\n                \"Consulta\": query_name,\n                \"Algoritmo\": alg_name,\n                \"Comparaciones\": total_comparisons,\n                \"Tiempo\": round(end - start, 6)\n            })\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"resultados_busqueda.csv\", index=False)\n\n\n\nif df[\"Comparaciones\"].sum() &gt; 0:\n\n    plt.figure(figsize=(14, 6))\n    sns.barplot(data=df, x=\"Algoritmo\", y=\"Comparaciones\", hue=\"Lista\", errorbar=None)\n    plt.yscale(\"log\")\n    plt.title(\"Comparaciones por Algoritmo y Lista (escala logarítmica)\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    plt.figure(figsize=(14, 6))\n    sns.barplot(data=df, x=\"Algoritmo\", y=\"Tiempo\", hue=\"Lista\", errorbar=None)\n    plt.yscale(\"log\")\n    plt.title(\"Tiempo por Algoritmo y Lista (escala logarítmica)\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    for consulta in df[\"Consulta\"].unique():\n        subset = df[df[\"Consulta\"] == consulta]\n\n        plt.figure(figsize=(14, 6))\n        sns.barplot(data=subset, x=\"Algoritmo\", y=\"Comparaciones\", hue=\"Lista\", errorbar=None)\n        plt.yscale(\"log\")\n        plt.title(f\"Comparaciones por Algoritmo (Consulta: {consulta})\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n        plt.figure(figsize=(14, 6))\n        sns.barplot(data=subset, x=\"Algoritmo\", y=\"Tiempo\", hue=\"Lista\", errorbar=None)\n        plt.yscale(\"log\")\n        plt.title(f\"Tiempo por Algoritmo (Consulta: {consulta})\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n    promedios_consulta = df.groupby([\"Consulta\", \"Algoritmo\"], as_index=False)[[\"Comparaciones\", \"Tiempo\"]].mean()\n    display(promedios_consulta)\n    promedios_consulta.to_csv(\"promedios_por_consulta.csv\", index=False)\nelse:\n    print(\"No se registraron comparaciones. Verifica el contenido de tus archivos.\")"
  },
  {
    "objectID": "project4.html#análisis-de-resultados",
    "href": "project4.html#análisis-de-resultados",
    "title": "Proyecto 4",
    "section": "",
    "text": "En el gráfico se observa el número de comparaciones promedio realizadas por cada algoritmo al ejecutar la consulta consultas-1-listas-posteo.json sobre distintas listas de posteo con perturbaciones. Se evidencia claramente que el algoritmo B0 (búsqueda secuencial) es extremadamente ineficiente, realizando más de 3 millones de comparaciones en todos los casos. Esta ineficiencia se mantiene constante independientemente del nivel de perturbación, lo cual refleja su incapacidad de adaptarse a estructuras parcialmente ordenadas. Por otro lado, los algoritmos Binaria, B1 y B2 muestran un comportamiento mucho más eficiente, con un número de comparaciones considerablemente menor (del orden de cientos de miles o menos), además de una gran estabilidad frente a las distintas listas perturbadas. El algoritmo SkipList, aunque ligeramente más constante en su conteo (180,000 en promedio), mantiene un rendimiento intermedio en términos de comparaciones, destacándose por su regularidad.\n\n\n\nEn el gráfico también se presenta el tiempo promedio de ejecución por algoritmo bajo el mismo escenario. Nuevamente, B0 muestra un tiempo elevado, aunque menos extremo que su número de comparaciones, lo que puede deberse a la simplicidad de su implementación. En cambio, Binaria refleja tiempos de ejecución más altos en relación con B1 y B2, pese a que las comparaciones eran similares o incluso menores, lo cual sugiere que la sobrecarga de su implementación o la forma en que accede a los datos puede afectar su eficiencia temporal. En cuanto a B1 y B2, ambos logran tiempos bajos y bastante consistentes, consolidándose como las alternativas más eficientes tanto en comparaciones como en tiempo. Finalmente, SkipList, aunque no es el más veloz, sí mantiene un tiempo de ejecución muy competitivo y constante, reafirmando su ventaja en estabilidad de desempeño.\n\n\n\n\n\n\nEn el gráfico de comparaciones correspondiente a la consulta consultas-2-listas-posteo.json, se observa que el algoritmo B0 sigue siendo el menos eficiente, superando los 5 millones de comparaciones en todos los casos. Este comportamiento se mantiene constante sin importar el nivel de perturbación en las listas, lo cual evidencia que la búsqueda secuencial no aprovecha el orden parcial de los datos. Por otro lado, los algoritmos Binaria, B1 y B2 presentan un rendimiento mucho más eficiente, con un número de comparaciones cercano a los 170,000, y una variación mínima entre las distintas listas perturbadas. SkipList también muestra un comportamiento constante y predecible, con 180,000 comparaciones en promedio, lo que refuerza su estabilidad.\n\n\n\nRespecto al gráfico de tiempo, nuevamente se observa que B0 tiene un tiempo de ejecución considerablemente superior al del resto de los algoritmos. Binaria mejora notablemente frente a B0, aunque sigue siendo superada por B1, B2 y SkipList en términos de rapidez. B1 y B2 obtienen los tiempos más bajos, cercanos a 1 × 10⁻² segundos, y se comportan de manera uniforme frente a distintas listas. SkipList, por su parte, mantiene los tiempos más reducidos, alrededor de 6 × 10⁻³ segundos, lo cual refuerza su eficiencia y lo posiciona como una alternativa sólida frente a perturbaciones en los datos.\n\n\n\n\n\n\nEl gráfico de comparaciones corresponde a la ejecución de la consulta consultas-3-listas-posteo.json sobre distintas listas de posteo con perturbaciones. En él se observa que el algoritmo B0 vuelve a mostrar un rendimiento extremadamente pobre, realizando más de 10⁸ comparaciones de forma constante, independientemente del nivel de perturbación en los datos. Esto refuerza su incapacidad de aprovechar cualquier tipo de orden o estructura parcial. Por otro lado, los algoritmos Binaria, B1 y B2 presentan un comportamiento mucho más eficiente y estable, con comparaciones en el orden de 2.5 × 10⁵ aproximadamente, sin verse afectados por las variaciones en las listas. SkipList también mantiene su consistencia, con un promedio de 180,000 comparaciones en todos los casos.\n\n\n\nEn cuanto al gráfico de tiempos, también asociado a la consulta consultas-3-listas-posteo.json, B0 registra los valores más altos, superando los 7 segundos para cada lista analizada. Aunque Binaria mejora considerablemente frente a B0, sus tiempos siguen siendo más elevados que los de B1 y B2, los cuales se mantienen en torno a los 0.03 segundos, con gran estabilidad entre listas. SkipList se destaca nuevamente como el algoritmo más rápido, con tiempos cercanos a los 0.007 segundos, consolidando su eficiencia tanto en tiempo como en número de comparaciones.\n\n\n\n\n\n\nEn el gráfico de comparaciones para la consulta consultas-4-listas-posteo.json, el algoritmo B0 vuelve a mostrar un rendimiento extremadamente ineficiente, superando los 9.8 × 10⁸ comparaciones en todos los casos, lo cual lo convierte en el peor evaluado sin importar el nivel de perturbación en las listas. Su comportamiento completamente lineal y sin capacidad de aprovechar el orden lo vuelve inviable para estructuras parcialmente ordenadas. Por el contrario, los algoritmos Binaria, B1 y B2 mantienen un número de comparaciones muy bajo y estable, con valores cercanos a 170,000 y 320,000 dependiendo de la técnica empleada, lo cual demuestra su eficiencia y adaptabilidad. El algoritmo SkipList, nuevamente, se mantiene firme con aproximadamente 180,000 comparaciones, reflejando un buen balance entre consistencia y rendimiento.\n\n\n\nEn el gráfico de tiempo para la misma consulta, B0 también presenta un tiempo de ejecución excesivo, cercano a los 96.8 segundos, lo que reafirma su ineficiencia total. Binaria mejora sustancialmente en comparación, con tiempos en torno a los 0.03 segundos, pero aún se ve superada por B1 y B2, que se ejecutan en alrededor de 0.045 segundos con mucha regularidad. SkipList destaca nuevamente con el mejor tiempo de todos, alrededor de 0.008 segundos, confirmando su capacidad de mantener bajo el tiempo de respuesta incluso frente a altos niveles de perturbación.\n\n\n\n\n\n\nEl gráfico de comparaciones evidencia que el algoritmo B0 es, con diferencia, el menos eficiente frente a todos los niveles de perturbación. En todos los casos, supera consistentemente las 10⁷ comparaciones, lo que demuestra su incapacidad para aprovechar el orden parcial en las listas de posteo. Esta falta de adaptabilidad lo hace inadecuado incluso cuando las perturbaciones son mínimas. Por el contrario, los algoritmos Binaria, B1, B2 y SkipList mantienen un comportamiento muy estable, con comparaciones que oscilan entre 10⁵ y 10⁶, sin mostrar una sensibilidad significativa al aumento de perturbación en los datos. Esto refleja que estos métodos sí aprovechan la estructura de las listas, independientemente del nivel de desorden.\n\n\n\nEn el gráfico de tiempo, B0 nuevamente destaca por su alto costo computacional, con tiempos superiores a 10⁰ segundos, muy por encima del resto. Aunque Binaria mejora en eficiencia temporal, sigue siendo superada por B1, B2 y SkipList, que muestran tiempos por debajo de 10⁻² segundos. Este patrón se mantiene estable a lo largo de todas las listas evaluadas, lo cual indica que estos tres algoritmos no solo son más rápidos, sino también más consistentes y escalables cuando se enfrentan a datos perturbados. En particular, SkipList sobresale por mantener los tiempos más bajos del conjunto, reafirmando su eficiencia general.\n\n\n\n\n\n\n\n\n\n\n\nConsulta\nAlgoritmo\nComparaciones\nTiempo\n\n\n\n\nconsultas-1-listas-posteo.json\nB0\n295284.0\n0.021119 s\n\n\nconsultas-1-listas-posteo.json\nB1\n85296.0\n0.014033 s\n\n\nconsultas-1-listas-posteo.json\nB2\n85296.0\n0.013316 s\n\n\nconsultas-1-listas-posteo.json\nBinaria\n176297.0\n0.025725 s\n\n\nconsultas-1-listas-posteo.json\nSkipList\n180000.0\n0.006500 s\n\n\nconsultas-2-listas-posteo.json\nB0\n5035401.0\n0.389143 s\n\n\nconsultas-2-listas-posteo.json\nB1\n169318.0\n0.022207 s\n\n\nconsultas-2-listas-posteo.json\nB2\n169318.0\n0.022952 s\n\n\nconsultas-2-listas-posteo.json\nBinaria\n176827.0\n0.025777 s\n\n\nconsultas-2-listas-posteo.json\nSkipList\n180000.0\n0.006478 s\n\n\nconsultas-3-listas-posteo.json\nB0\n75757269.0\n7.030850 s\n\n\nconsultas-3-listas-posteo.json\nB1\n248473.0\n0.033025 s\n\n\nconsultas-3-listas-posteo.json\nB2\n248473.0\n0.034482 s\n\n\nconsultas-3-listas-posteo.json\nBinaria\n176385.0\n0.028948 s\n\n\nconsultas-3-listas-posteo.json\nSkipList\n180000.0\n0.007197 s\n\n\nconsultas-4-listas-posteo.json\nB0\n988162924.0\n96.788158 s\n\n\nconsultas-4-listas-posteo.json\nB1\n320738.0\n0.044221 s\n\n\nconsultas-4-listas-posteo.json\nB2\n320738.0\n0.045158 s\n\n\nconsultas-4-listas-posteo.json\nBinaria\n176355.0\n0.032268 s\n\n\nconsultas-4-listas-posteo.json\nSkipList\n180000.0\n0.008281 s\n\n\n\nLos resultados muestran que el algoritmo B0 es consistentemente el menos eficiente, con un pico de casi mil millones de comparaciones y más de 96 segundos de ejecución en la consulta consultas-4-listas-posteo.json. En contraste, B1 y B2 se mantienen como las opciones más equilibradas, con pocas comparaciones (alrededor de 85,000 a 320,000) y tiempos bajos, siempre por debajo de 0.05 segundos.\nBinaria presenta un buen número de comparaciones, cercano a 176,000 en promedio, pero sus tiempos son ligeramente mayores que los de B1 y B2. Por su parte, SkipList destaca por su estabilidad: siempre tiene 180,000 comparaciones y logra los mejores tiempos, entre 0.006 y 0.008 segundos, lo que lo convierte en una opción muy eficiente y constante.\nEl algoritmo B0 tuvo el peor rendimiento en todas las consultas. Su enfoque secuencial genera una enorme cantidad de comparaciones, ya que recorre toda la lista hasta encontrar la posición de inserción. No aprovecha el orden de los datos, lo que explica los tiempos altos y el crecimiento descontrolado en consultas con listas grandes o muy perturbadas.\nEl algoritmo Binaria fue más eficiente que B0 en comparaciones, gracias a su capacidad de dividir el espacio de búsqueda. Sin embargo, sus tiempos fueron ligeramente más altos que los de B1 y B2. Esto se debe posiblemente a una mayor cantidad de operaciones internas, como el manejo de los índices y los saltos de control.\nLos algoritmos B1 y B2, variantes de búsqueda no acotada, lograron un equilibrio ideal entre comparaciones y tiempo. Su estrategia de expansión exponencial permite reducir rápidamente el intervalo de búsqueda sin recorrer toda la lista, lo que explica su excelente rendimiento en listas grandes o parcialmente ordenadas.\nEl algoritmo SkipList mostró una gran regularidad: siempre hizo la misma cantidad de comparaciones y logró los tiempos más bajos. Esto se debe a su estructura multinivel que, aunque no ajusta dinámicamente su comportamiento, permite accesos rápidos similares a los de la búsqueda binaria, con una sobrecarga mínima.\nEn general, cada algoritmo respondió según su diseño. Los que explotan el orden de los datos (Binaria, B1, B2, SkipList) fueron mucho más eficientes que B0. Esto confirma que la eficiencia no solo depende del tipo de algoritmo, sino también de su capacidad de adaptarse a la estructura de los datos."
  },
  {
    "objectID": "project4.html#conclusiones",
    "href": "project4.html#conclusiones",
    "title": "Proyecto 4",
    "section": "",
    "text": "Una de las principales conclusiones del análisis es que el algoritmo B0, basado en búsqueda secuencial, resulta completamente ineficiente para conjuntos de datos ordenados, especialmente cuando se introducen perturbaciones. Su número de comparaciones crece desproporcionadamente y sus tiempos de ejecución son inaceptables incluso en consultas de tamaño moderado, lo que lo descarta como una opción viable en contextos prácticos donde se requiere rendimiento.\nPor otro lado, los algoritmos B1 y B2 demostraron ser las estrategias más equilibradas. No solo mantienen un número reducido de comparaciones en todos los escenarios, sino que además ofrecen tiempos de ejecución muy bajos y constantes, independientemente del tamaño o perturbación de las listas. Esta combinación de eficiencia y estabilidad los convierte en una excelente alternativa cuando se trabaja con datos parcialmente ordenados o de tamaño variable.\nLa búsqueda binaria acotada, aunque conceptualmente eficiente, mostró tiempos de ejecución ligeramente mayores en comparación con B1 y B2. Esto sugiere que, aunque reduce el número de comparaciones, su implementación o la estructura de acceso a los datos podría estar introduciendo una sobrecarga adicional, lo cual debe ser considerado dependiendo del contexto de aplicación.\nSkipList se posiciona como una opción altamente competitiva. Aunque su número de comparaciones se mantiene fijo en 180,000, su gran ventaja radica en sus tiempos de ejecución, que son consistentemente los más bajos de todos los algoritmos evaluados. Esta característica lo convierte en una herramienta valiosa para escenarios en los que el tiempo de respuesta es crítico.\nFinalmente, este estudio confirma que la elección del algoritmo de búsqueda debe estar guiada por el tipo de datos, su orden relativo, y los requisitos de rendimiento. En ambientes dinámicos o con estructuras parcialmente ordenadas, es preferible optar por B1, B2 o SkipList. En cambio, algoritmos como B0 deben evitarse salvo en situaciones controladas con conjuntos pequeños y sin requisitos de eficiencia."
  },
  {
    "objectID": "project4.html#referencias",
    "href": "project4.html#referencias",
    "title": "Proyecto 4",
    "section": "",
    "text": "Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms (3rd ed.).\nSedgewick, R., & Wayne, K. (2011). Algorithms (4th ed.).\nKnuth, D. E. (1998). The Art of Computer Programming, Volume 3: Sorting and Searching (2nd ed.).\nWeiss, M. A. (2014). Data Structures and Algorithm Analysis in C (3rd ed.). Pearson."
  },
  {
    "objectID": "project4.html#cambios-realizados",
    "href": "project4.html#cambios-realizados",
    "title": "Proyecto 4",
    "section": "",
    "text": "En atención a la retroalimentación recibida, se realizó una revisión profunda del enfoque adoptado en la implementación de los algoritmos de búsqueda por comparación. A continuación se detallan los ajustes conceptuales y técnicos aplicados:\n\nSe reconoció que el uso de listas de posteo con perturbaciones generó una interpretación errónea del problema, llevando a implementar algoritmos basados únicamente en igualdad, cuando el problema central requería considerar comparaciones con operadores &lt; o &lt;= para determinar la posición de inserción.\nSe reformularon los algoritmos de búsqueda secuencial y binaria considerando adecuadamente la semántica del problema, que implica la ubicación correcta en listas ordenadas, no la coincidencia exacta.\nSe revisaron las notas del curso y el artículo de Baeza-Yates (B&Y), lo que permitió entender con mayor claridad el modelo de comparación y sus implicaciones para el diseño e interpretación correcta de los algoritmos.\nSe corrigieron errores lógicos en las funciones de búsqueda y se realizaron pruebas con datos estructurados correctamente, evitando distorsiones generadas por entradas mal definidas."
  }
]